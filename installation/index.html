<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Composable distributed training framework built around PyTorch DTensor abstractions"><link href=https://dream3d.ai/trainer/installation/ rel=canonical><link rel=prev href=..><link href=../getting-started/ rel=next><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.15"><title>Installation - dream-trainer</title><link rel=stylesheet href=../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../assets/_mkdocstrings.css><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#installation-guide class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=dream-trainer class="md-header__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> dream-trainer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Installation </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../configuration/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../tutorials/first-trainer.md class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../examples/vision.md class=md-tabs__link> Examples </a> </li> <li class=md-tabs__item> <a href=../api/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../contributing.md class=md-tabs__link> Community </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=dream-trainer class="md-nav__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../assets/logo.png alt=logo> </a> dream-trainer </label> <div class=md-nav__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Installation </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Installation </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#requirements class=md-nav__link> <span class=md-ellipsis> Requirements </span> </a> <nav class=md-nav aria-label=Requirements> <ul class=md-nav__list> <li class=md-nav__item> <a href=#python-version-requirements class=md-nav__link> <span class=md-ellipsis> Python Version Requirements </span> </a> </li> <li class=md-nav__item> <a href=#system-requirements class=md-nav__link> <span class=md-ellipsis> System Requirements </span> </a> <nav class=md-nav aria-label="System Requirements"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#minimum-requirements class=md-nav__link> <span class=md-ellipsis> Minimum Requirements </span> </a> </li> <li class=md-nav__item> <a href=#recommended-requirements class=md-nav__link> <span class=md-ellipsis> Recommended Requirements </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-and-cuda-compatibility class=md-nav__link> <span class=md-ellipsis> PyTorch and CUDA Compatibility </span> </a> <nav class=md-nav aria-label="PyTorch and CUDA Compatibility"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cuda-compatibility-table class=md-nav__link> <span class=md-ellipsis> CUDA Compatibility Table </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#installation-methods class=md-nav__link> <span class=md-ellipsis> Installation Methods </span> </a> <nav class=md-nav aria-label="Installation Methods"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-basic-installation class=md-nav__link> <span class=md-ellipsis> 1. Basic Installation </span> </a> </li> <li class=md-nav__item> <a href=#2-feature-specific-installation class=md-nav__link> <span class=md-ellipsis> 2. Feature-Specific Installation </span> </a> </li> <li class=md-nav__item> <a href=#3-development-installation class=md-nav__link> <span class=md-ellipsis> 3. Development Installation </span> </a> </li> <li class=md-nav__item> <a href=#4-docker-installation class=md-nav__link> <span class=md-ellipsis> 4. Docker Installation </span> </a> <nav class=md-nav aria-label="4. Docker Installation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#using-pre-built-images class=md-nav__link> <span class=md-ellipsis> Using Pre-built Images </span> </a> </li> <li class=md-nav__item> <a href=#building-custom-image class=md-nav__link> <span class=md-ellipsis> Building Custom Image </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-cluster-specific-installations class=md-nav__link> <span class=md-ellipsis> 5. Cluster-Specific Installations </span> </a> <nav class=md-nav aria-label="5. Cluster-Specific Installations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#slurm-clusters class=md-nav__link> <span class=md-ellipsis> SLURM Clusters </span> </a> </li> <li class=md-nav__item> <a href=#kubernetes-deployment class=md-nav__link> <span class=md-ellipsis> Kubernetes Deployment </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#verification class=md-nav__link> <span class=md-ellipsis> Verification </span> </a> <nav class=md-nav aria-label=Verification> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-basic-verification class=md-nav__link> <span class=md-ellipsis> 1. Basic Verification </span> </a> </li> <li class=md-nav__item> <a href=#2-performance-verification class=md-nav__link> <span class=md-ellipsis> 2. Performance Verification </span> </a> </li> <li class=md-nav__item> <a href=#3-multi-gpu-verification class=md-nav__link> <span class=md-ellipsis> 3. Multi-GPU Verification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#troubleshooting class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> <nav class=md-nav aria-label=Troubleshooting> <ul class=md-nav__list> <li class=md-nav__item> <a href=#common-installation-issues class=md-nav__link> <span class=md-ellipsis> Common Installation Issues </span> </a> <nav class=md-nav aria-label="Common Installation Issues"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-cudapytorch-mismatch class=md-nav__link> <span class=md-ellipsis> 1. CUDA/PyTorch Mismatch </span> </a> </li> <li class=md-nav__item> <a href=#2-missing-system-libraries class=md-nav__link> <span class=md-ellipsis> 2. Missing System Libraries </span> </a> </li> <li class=md-nav__item> <a href=#3-memory-issues-during-installation class=md-nav__link> <span class=md-ellipsis> 3. Memory Issues During Installation </span> </a> </li> <li class=md-nav__item> <a href=#4-distributed-training-issues class=md-nav__link> <span class=md-ellipsis> 4. Distributed Training Issues </span> </a> </li> <li class=md-nav__item> <a href=#5-import-errors-after-installation class=md-nav__link> <span class=md-ellipsis> 5. Import Errors After Installation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#performance-optimization-tips class=md-nav__link> <span class=md-ellipsis> Performance Optimization Tips </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#next-steps class=md-nav__link> <span class=md-ellipsis> Next Steps </span> </a> </li> <li class=md-nav__item> <a href=#getting-help class=md-nav__link> <span class=md-ellipsis> Getting Help </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../getting-started/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../core-concepts/ class=md-nav__link> <span class=md-ellipsis> Core Concepts </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../configuration/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../tutorials/first-trainer.md class=md-nav__link> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../examples/vision.md class=md-nav__link> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../api/ class=md-nav__link> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../contributing.md class=md-nav__link> <span class=md-ellipsis> Community </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dream3d/dream-trainer/edit/main/dream-trainer/pages/docs/installation.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dream3d/dream-trainer/raw/main/dream-trainer/pages/docs/installation.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=installation-guide>Installation Guide<a class=headerlink href=#installation-guide title="Permanent link">&para;</a></h1> <p>This comprehensive guide covers all aspects of installing Dream Trainer, from basic setup to production deployment.</p> <h2 id=requirements>Requirements<a class=headerlink href=#requirements title="Permanent link">&para;</a></h2> <h3 id=python-version-requirements>Python Version Requirements<a class=headerlink href=#python-version-requirements title="Permanent link">&para;</a></h3> <p>Dream Trainer requires Python 3.10 or later. Here's the compatibility matrix:</p> <table> <thead> <tr> <th>Dream Trainer Version</th> <th>Python Versions</th> <th>PyTorch Versions</th> <th>CUDA Versions</th> </tr> </thead> <tbody> <tr> <td>0.1.x</td> <td>3.10 - 3.12</td> <td>2.7.1+</td> <td>11.8, 12.1, 12.4</td> </tr> </tbody> </table> <h3 id=system-requirements>System Requirements<a class=headerlink href=#system-requirements title="Permanent link">&para;</a></h3> <h4 id=minimum-requirements>Minimum Requirements<a class=headerlink href=#minimum-requirements title="Permanent link">&para;</a></h4> <ul> <li><strong>CPU</strong>: x86_64 or ARM64 processor</li> <li><strong>RAM</strong>: 8GB (for basic usage)</li> <li><strong>Storage</strong>: 2GB free space</li> <li><strong>OS</strong>: Linux, macOS, or Windows (WSL2 recommended)</li> </ul> <h4 id=recommended-requirements>Recommended Requirements<a class=headerlink href=#recommended-requirements title="Permanent link">&para;</a></h4> <ul> <li><strong>GPU</strong>: NVIDIA GPU with CUDA capability 7.0+ (V100, A100, H100, RTX 3090+)</li> <li><strong>RAM</strong>: 32GB+ (for multi-GPU training)</li> <li><strong>Storage</strong>: 50GB+ free space (for datasets and checkpoints)</li> <li><strong>Network</strong>: High-speed interconnect for multi-node training (InfiniBand preferred)</li> </ul> <h3 id=pytorch-and-cuda-compatibility>PyTorch and CUDA Compatibility<a class=headerlink href=#pytorch-and-cuda-compatibility title="Permanent link">&para;</a></h3> <p>Dream Trainer builds on PyTorch's distributed training capabilities. Ensure your PyTorch installation matches your CUDA version:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># Check your CUDA version</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>nvidia-smi
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=c1># Check PyTorch and CUDA compatibility</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>python<span class=w> </span>-c<span class=w> </span><span class=s2>&quot;import torch; print(f&#39;PyTorch: {torch.__version__}&#39;); print(f&#39;CUDA available: {torch.cuda.is_available()}&#39;); print(f&#39;CUDA version: {torch.version.cuda}&#39;)&quot;</span>
</span></code></pre></div> <h4 id=cuda-compatibility-table>CUDA Compatibility Table<a class=headerlink href=#cuda-compatibility-table title="Permanent link">&para;</a></h4> <table> <thead> <tr> <th>CUDA Version</th> <th>PyTorch Install Command</th> </tr> </thead> <tbody> <tr> <td>CUDA 11.8</td> <td><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</code></td> </tr> <tr> <td>CUDA 12.1</td> <td><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</code></td> </tr> <tr> <td>CUDA 12.4+</td> <td><code>pip install torch torchvision torchaudio</code></td> </tr> <tr> <td>CPU only</td> <td><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu</code></td> </tr> </tbody> </table> <h2 id=installation-methods>Installation Methods<a class=headerlink href=#installation-methods title="Permanent link">&para;</a></h2> <h3 id=1-basic-installation>1. Basic Installation<a class=headerlink href=#1-basic-installation title="Permanent link">&para;</a></h3> <p>The simplest way to install Dream Trainer:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>pip<span class=w> </span>install<span class=w> </span>dream-trainer
</span></code></pre></div> <p>This installs the core framework with minimal dependencies: - PyTorch (&gt;= 2.7.1) - loguru (for logging) - tqdm (for progress bars) - dist-util (distributed utilities)</p> <h3 id=2-feature-specific-installation>2. Feature-Specific Installation<a class=headerlink href=#2-feature-specific-installation title="Permanent link">&para;</a></h3> <p>Dream Trainer uses optional dependencies to keep the core lightweight. Install only what you need:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Weights &amp; Biases Integration</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=c1># Includes: wandb with media logging support</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[wandb]&quot;</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=c1># TorchMetrics Integration</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=c1># Includes: torchmetrics for standardized metric computation</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[metrics]&quot;</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=c1># Quantization Support</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=c1># Includes: torchao for FP8/INT8 quantization</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[torchao]&quot;</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=c1># Fault Tolerance</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=c1># Includes: torchft for automatic failure recovery</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[torchft]&quot;</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a><span class=c1># Enhanced CLI Output</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a><span class=c1># Includes: rich for better terminal formatting</span>
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[rich]&quot;</span>
</span><span id=__span-2-20><a id=__codelineno-2-20 name=__codelineno-2-20 href=#__codelineno-2-20></a>
</span><span id=__span-2-21><a id=__codelineno-2-21 name=__codelineno-2-21 href=#__codelineno-2-21></a><span class=c1># Multiple features</span>
</span><span id=__span-2-22><a id=__codelineno-2-22 name=__codelineno-2-22 href=#__codelineno-2-22></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[wandb,metrics,torchao]&quot;</span>
</span><span id=__span-2-23><a id=__codelineno-2-23 name=__codelineno-2-23 href=#__codelineno-2-23></a>
</span><span id=__span-2-24><a id=__codelineno-2-24 name=__codelineno-2-24 href=#__codelineno-2-24></a><span class=c1># All features</span>
</span><span id=__span-2-25><a id=__codelineno-2-25 name=__codelineno-2-25 href=#__codelineno-2-25></a>pip<span class=w> </span>install<span class=w> </span><span class=s2>&quot;dream-trainer[all]&quot;</span>
</span></code></pre></div> <h3 id=3-development-installation>3. Development Installation<a class=headerlink href=#3-development-installation title="Permanent link">&para;</a></h3> <p>For contributing or customizing Dream Trainer:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Clone the repository</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>git<span class=w> </span>clone<span class=w> </span>https://github.com/dream3d-ai/dream-trainer.git
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=nb>cd</span><span class=w> </span>dream-trainer
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=c1># Create a virtual environment (recommended)</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>python<span class=w> </span>-m<span class=w> </span>venv<span class=w> </span>venv
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=nb>source</span><span class=w> </span>venv/bin/activate<span class=w>  </span><span class=c1># On Windows: venv\Scripts\activate</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=c1># Install in editable mode with dev dependencies</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>pip<span class=w> </span>install<span class=w> </span>-e<span class=w> </span><span class=s2>&quot;.[dev]&quot;</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a><span class=c1># Install pre-commit hooks (optional)</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>pip<span class=w> </span>install<span class=w> </span>pre-commit
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>pre-commit<span class=w> </span>install
</span></code></pre></div> <h3 id=4-docker-installation>4. Docker Installation<a class=headerlink href=#4-docker-installation title="Permanent link">&para;</a></h3> <p>For reproducible environments and cluster deployment:</p> <h4 id=using-pre-built-images>Using Pre-built Images<a class=headerlink href=#using-pre-built-images title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Pull the latest image</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>docker<span class=w> </span>pull<span class=w> </span>dream3d/dream-trainer:latest
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=c1># Run with GPU support</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>docker<span class=w> </span>run<span class=w> </span>--gpus<span class=w> </span>all<span class=w> </span>-it<span class=w> </span>dream3d/dream-trainer:latest
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=c1># With specific CUDA version</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>docker<span class=w> </span>pull<span class=w> </span>dream3d/dream-trainer:cuda12.1-pytorch2.7
</span></code></pre></div> <h4 id=building-custom-image>Building Custom Image<a class=headerlink href=#building-custom-image title="Permanent link">&para;</a></h4> <p>Create a <code>Dockerfile</code>:</p> <div class="language-dockerfile highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c># Base image with CUDA and PyTorch</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=k>FROM</span><span class=w> </span><span class=s>pytorch/pytorch:2.7.1-cuda12.4-cudnn9-runtime</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=c># Install system dependencies</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=k>RUN</span><span class=w> </span>apt-get<span class=w> </span>update<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span>apt-get<span class=w> </span>install<span class=w> </span>-y<span class=w> </span><span class=se>\</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=w>    </span>git<span class=w> </span><span class=se>\</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=w>    </span>build-essential<span class=w> </span><span class=se>\</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=w>    </span><span class=o>&amp;&amp;</span><span class=w> </span>rm<span class=w> </span>-rf<span class=w> </span>/var/lib/apt/lists/*
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=c># Install Dream Trainer</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=k>RUN</span><span class=w> </span>pip<span class=w> </span>install<span class=w> </span>dream-trainer<span class=o>[</span>all<span class=o>]</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=c># Optional: Install your project dependencies</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a><span class=k>COPY</span><span class=w> </span>requirements.txt<span class=w> </span>.
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=k>RUN</span><span class=w> </span>pip<span class=w> </span>install<span class=w> </span>-r<span class=w> </span>requirements.txt
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a><span class=c># Set working directory</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a><span class=k>WORKDIR</span><span class=w> </span><span class=s>/workspace</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a><span class=c># Default command</span>
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a><span class=k>CMD</span><span class=w> </span><span class=p>[</span><span class=s2>&quot;python&quot;</span><span class=p>]</span>
</span></code></pre></div> <p>Build and run:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a>docker<span class=w> </span>build<span class=w> </span>-t<span class=w> </span>my-dream-trainer<span class=w> </span>.
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>docker<span class=w> </span>run<span class=w> </span>--gpus<span class=w> </span>all<span class=w> </span>-v<span class=w> </span><span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>:/workspace<span class=w> </span>-it<span class=w> </span>my-dream-trainer
</span></code></pre></div> <h3 id=5-cluster-specific-installations>5. Cluster-Specific Installations<a class=headerlink href=#5-cluster-specific-installations title="Permanent link">&para;</a></h3> <h4 id=slurm-clusters>SLURM Clusters<a class=headerlink href=#slurm-clusters title="Permanent link">&para;</a></h4> <p>Create a module file or use a shared environment:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># Load required modules</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>module<span class=w> </span>load<span class=w> </span>python/3.11
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>module<span class=w> </span>load<span class=w> </span>cuda/12.1
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>module<span class=w> </span>load<span class=w> </span>gcc/11.2
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=c1># Create shared environment</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>python<span class=w> </span>-m<span class=w> </span>venv<span class=w> </span>/shared/envs/dream-trainer
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=nb>source</span><span class=w> </span>/shared/envs/dream-trainer/bin/activate
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Install with MPI support</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>pip<span class=w> </span>install<span class=w> </span>dream-trainer<span class=o>[</span>all<span class=o>]</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>pip<span class=w> </span>install<span class=w> </span>mpi4py<span class=w>  </span><span class=c1># For MPI-based launchers</span>
</span></code></pre></div> <p>Example SLURM job script:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=c1>#SBATCH --job-name=dream-trainer</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=c1>#SBATCH --nodes=4</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=c1>#SBATCH --ntasks-per-node=8</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=c1>#SBATCH --gpus-per-node=8</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=c1>#SBATCH --time=24:00:00</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=c1># Load environment</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=nb>source</span><span class=w> </span>/shared/envs/dream-trainer/bin/activate
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=c1># Run training</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>srun<span class=w> </span>python<span class=w> </span>train.py
</span></code></pre></div> <h4 id=kubernetes-deployment>Kubernetes Deployment<a class=headerlink href=#kubernetes-deployment title="Permanent link">&para;</a></h4> <p>Create a Kubernetes manifest:</p> <div class="language-yaml highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">batch/v1</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">Job</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=nt>metadata</span><span class=p>:</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">dream-trainer-job</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=nt>spec</span><span class=p>:</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=w>  </span><span class=nt>parallelism</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=w>  </span><span class=nt>template</span><span class=p>:</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a><span class=w>    </span><span class=nt>spec</span><span class=p>:</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=w>      </span><span class=nt>containers</span><span class=p>:</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a><span class=w>      </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">trainer</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">dream3d/dream-trainer:latest</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=w>        </span><span class=nt>resources</span><span class=p>:</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a><span class=w>          </span><span class=nt>limits</span><span class=p>:</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a><span class=w>            </span><span class=nt>nvidia.com/gpu</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a><span class=w>        </span><span class=nt>volumeMounts</span><span class=p>:</span>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a><span class=w>        </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">data</span>
</span><span id=__span-9-17><a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">/data</span>
</span><span id=__span-9-18><a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a><span class=w>        </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">checkpoints</span>
</span><span id=__span-9-19><a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">/checkpoints</span>
</span><span id=__span-9-20><a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a><span class=w>        </span><span class=nt>env</span><span class=p>:</span>
</span><span id=__span-9-21><a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a><span class=w>        </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">MASTER_ADDR</span>
</span><span id=__span-9-22><a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s>&quot;dream-trainer-master&quot;</span>
</span><span id=__span-9-23><a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a><span class=w>        </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">MASTER_PORT</span>
</span><span id=__span-9-24><a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s>&quot;29500&quot;</span>
</span><span id=__span-9-25><a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a><span class=w>        </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class="p p-Indicator">[</span><span class=s>&quot;python&quot;</span><span class="p p-Indicator">,</span><span class=w> </span><span class=s>&quot;train.py&quot;</span><span class="p p-Indicator">]</span>
</span><span id=__span-9-26><a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span>
</span><span id=__span-9-27><a id=__codelineno-9-27 name=__codelineno-9-27 href=#__codelineno-9-27></a><span class=w>      </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">data</span>
</span><span id=__span-9-28><a id=__codelineno-9-28 name=__codelineno-9-28 href=#__codelineno-9-28></a><span class=w>        </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span>
</span><span id=__span-9-29><a id=__codelineno-9-29 name=__codelineno-9-29 href=#__codelineno-9-29></a><span class=w>          </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">training-data</span>
</span><span id=__span-9-30><a id=__codelineno-9-30 name=__codelineno-9-30 href=#__codelineno-9-30></a><span class=w>      </span><span class="p p-Indicator">-</span><span class=w> </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">checkpoints</span>
</span><span id=__span-9-31><a id=__codelineno-9-31 name=__codelineno-9-31 href=#__codelineno-9-31></a><span class=w>        </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span>
</span><span id=__span-9-32><a id=__codelineno-9-32 name=__codelineno-9-32 href=#__codelineno-9-32></a><span class=w>          </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">model-checkpoints</span>
</span></code></pre></div> <h2 id=verification>Verification<a class=headerlink href=#verification title="Permanent link">&para;</a></h2> <h3 id=1-basic-verification>1. Basic Verification<a class=headerlink href=#1-basic-verification title="Permanent link">&para;</a></h3> <p>Verify your installation is working correctly:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># verify_installation.py</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=kn>import</span><span class=w> </span><span class=nn>dream_trainer</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=kn>import</span><span class=w> </span><span class=nn>sys</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=k>def</span><span class=w> </span><span class=nf>check_installation</span><span class=p>():</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Comprehensive installation check&quot;&quot;&quot;</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Python version: </span><span class=si>{</span><span class=n>sys</span><span class=o>.</span><span class=n>version</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Dream Trainer version: </span><span class=si>{</span><span class=n>dream_trainer</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;PyTorch version: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=c1># Check CUDA availability</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>CUDA available: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CUDA version: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPU count: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()):</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  GPU </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=n>i</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>    <span class=c1># Check optional features</span>
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a>    <span class=n>features</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>        <span class=s2>&quot;wandb&quot;</span><span class=p>:</span> <span class=s2>&quot;wandb&quot;</span><span class=p>,</span>
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>        <span class=s2>&quot;torchmetrics&quot;</span><span class=p>:</span> <span class=s2>&quot;torchmetrics&quot;</span><span class=p>,</span> 
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>        <span class=s2>&quot;torchao&quot;</span><span class=p>:</span> <span class=s2>&quot;torchao&quot;</span><span class=p>,</span>
</span><span id=__span-10-25><a id=__codelineno-10-25 name=__codelineno-10-25 href=#__codelineno-10-25></a>        <span class=s2>&quot;torchft&quot;</span><span class=p>:</span> <span class=s2>&quot;torchft&quot;</span><span class=p>,</span>
</span><span id=__span-10-26><a id=__codelineno-10-26 name=__codelineno-10-26 href=#__codelineno-10-26></a>        <span class=s2>&quot;rich&quot;</span><span class=p>:</span> <span class=s2>&quot;rich&quot;</span>
</span><span id=__span-10-27><a id=__codelineno-10-27 name=__codelineno-10-27 href=#__codelineno-10-27></a>    <span class=p>}</span>
</span><span id=__span-10-28><a id=__codelineno-10-28 name=__codelineno-10-28 href=#__codelineno-10-28></a>
</span><span id=__span-10-29><a id=__codelineno-10-29 name=__codelineno-10-29 href=#__codelineno-10-29></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Optional features:&quot;</span><span class=p>)</span>
</span><span id=__span-10-30><a id=__codelineno-10-30 name=__codelineno-10-30 href=#__codelineno-10-30></a>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>module</span> <span class=ow>in</span> <span class=n>features</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-10-31><a id=__codelineno-10-31 name=__codelineno-10-31 href=#__codelineno-10-31></a>        <span class=k>try</span><span class=p>:</span>
</span><span id=__span-10-32><a id=__codelineno-10-32 name=__codelineno-10-32 href=#__codelineno-10-32></a>            <span class=nb>__import__</span><span class=p>(</span><span class=n>module</span><span class=p>)</span>
</span><span id=__span-10-33><a id=__codelineno-10-33 name=__codelineno-10-33 href=#__codelineno-10-33></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-34><a id=__codelineno-10-34 name=__codelineno-10-34 href=#__codelineno-10-34></a>        <span class=k>except</span> <span class=ne>ImportError</span><span class=p>:</span>
</span><span id=__span-10-35><a id=__codelineno-10-35 name=__codelineno-10-35 href=#__codelineno-10-35></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2> (install with: pip install dream-trainer[</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>])&quot;</span><span class=p>)</span>
</span><span id=__span-10-36><a id=__codelineno-10-36 name=__codelineno-10-36 href=#__codelineno-10-36></a>
</span><span id=__span-10-37><a id=__codelineno-10-37 name=__codelineno-10-37 href=#__codelineno-10-37></a>    <span class=c1># Test basic functionality</span>
</span><span id=__span-10-38><a id=__codelineno-10-38 name=__codelineno-10-38 href=#__codelineno-10-38></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Testing basic trainer creation...&quot;</span><span class=p>)</span>
</span><span id=__span-10-39><a id=__codelineno-10-39 name=__codelineno-10-39 href=#__codelineno-10-39></a>    <span class=k>try</span><span class=p>:</span>
</span><span id=__span-10-40><a id=__codelineno-10-40 name=__codelineno-10-40 href=#__codelineno-10-40></a>        <span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>BaseTrainerConfig</span>
</span><span id=__span-10-41><a id=__codelineno-10-41 name=__codelineno-10-41 href=#__codelineno-10-41></a>        <span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.trainer.mixins</span><span class=w> </span><span class=kn>import</span> <span class=n>SetupMixin</span>
</span><span id=__span-10-42><a id=__codelineno-10-42 name=__codelineno-10-42 href=#__codelineno-10-42></a>
</span><span id=__span-10-43><a id=__codelineno-10-43 name=__codelineno-10-43 href=#__codelineno-10-43></a>        <span class=k>class</span><span class=w> </span><span class=nc>TestTrainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>):</span>
</span><span id=__span-10-44><a id=__codelineno-10-44 name=__codelineno-10-44 href=#__codelineno-10-44></a>            <span class=k>def</span><span class=w> </span><span class=nf>configure_models</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-10-45><a id=__codelineno-10-45 name=__codelineno-10-45 href=#__codelineno-10-45></a>                <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span><span id=__span-10-46><a id=__codelineno-10-46 name=__codelineno-10-46 href=#__codelineno-10-46></a>            <span class=k>def</span><span class=w> </span><span class=nf>configure_optimizers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-10-47><a id=__codelineno-10-47 name=__codelineno-10-47 href=#__codelineno-10-47></a>                <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
</span><span id=__span-10-48><a id=__codelineno-10-48 name=__codelineno-10-48 href=#__codelineno-10-48></a>            <span class=k>def</span><span class=w> </span><span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-10-49><a id=__codelineno-10-49 name=__codelineno-10-49 href=#__codelineno-10-49></a>                <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;loss&quot;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=mf>1.0</span><span class=p>)}</span>
</span><span id=__span-10-50><a id=__codelineno-10-50 name=__codelineno-10-50 href=#__codelineno-10-50></a>
</span><span id=__span-10-51><a id=__codelineno-10-51 name=__codelineno-10-51 href=#__codelineno-10-51></a>        <span class=n>config</span> <span class=o>=</span> <span class=n>BaseTrainerConfig</span><span class=p>(</span><span class=n>training_parameters</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;n_epochs&quot;</span><span class=p>:</span> <span class=mi>1</span><span class=p>})</span>
</span><span id=__span-10-52><a id=__codelineno-10-52 name=__codelineno-10-52 href=#__codelineno-10-52></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;   Trainer creation successful&quot;</span><span class=p>)</span>
</span><span id=__span-10-53><a id=__codelineno-10-53 name=__codelineno-10-53 href=#__codelineno-10-53></a>
</span><span id=__span-10-54><a id=__codelineno-10-54 name=__codelineno-10-54 href=#__codelineno-10-54></a>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span><span id=__span-10-55><a id=__codelineno-10-55 name=__codelineno-10-55 href=#__codelineno-10-55></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Trainer creation failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-56><a id=__codelineno-10-56 name=__codelineno-10-56 href=#__codelineno-10-56></a>
</span><span id=__span-10-57><a id=__codelineno-10-57 name=__codelineno-10-57 href=#__codelineno-10-57></a>    <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-10-58><a id=__codelineno-10-58 name=__codelineno-10-58 href=#__codelineno-10-58></a>
</span><span id=__span-10-59><a id=__codelineno-10-59 name=__codelineno-10-59 href=#__codelineno-10-59></a><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
</span><span id=__span-10-60><a id=__codelineno-10-60 name=__codelineno-10-60 href=#__codelineno-10-60></a>    <span class=n>check_installation</span><span class=p>()</span>
</span></code></pre></div> <p>Run the verification script (available in <code>examples/verify_installation.py</code>):</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a>python<span class=w> </span>examples/verify_installation.py
</span></code></pre></div> <h3 id=2-performance-verification>2. Performance Verification<a class=headerlink href=#2-performance-verification title="Permanent link">&para;</a></h3> <p>Test that your GPU setup is performing optimally using the provided benchmark script:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a>python<span class=w> </span>examples/benchmark_gpu.py
</span></code></pre></div> <p>Or use the code below for a custom benchmark:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># benchmark.py</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=kn>import</span><span class=w> </span><span class=nn>time</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>get_rank</span><span class=p>,</span> <span class=n>get_world_size</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=k>def</span><span class=w> </span><span class=nf>benchmark_gpu</span><span class=p>():</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Simple GPU benchmark&quot;&quot;&quot;</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;No GPU available for benchmarking&quot;</span><span class=p>)</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>        <span class=k>return</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>()</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Benchmarking GPU </span><span class=si>{</span><span class=n>device</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=n>device</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>    <span class=c1># Test different sizes</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a>    <span class=n>sizes</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>2048</span><span class=p>,</span> <span class=mi>4096</span><span class=p>,</span> <span class=mi>8192</span><span class=p>]</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>    <span class=k>for</span> <span class=n>size</span> <span class=ow>in</span> <span class=n>sizes</span><span class=p>:</span>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a>        <span class=c1># Create random matrices</span>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a>        <span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a>        <span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a>        <span class=c1># Warmup</span>
</span><span id=__span-13-24><a id=__codelineno-13-24 name=__codelineno-13-24 href=#__codelineno-13-24></a>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span><span id=__span-13-25><a id=__codelineno-13-25 name=__codelineno-13-25 href=#__codelineno-13-25></a>            <span class=n>c</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span><span id=__span-13-26><a id=__codelineno-13-26 name=__codelineno-13-26 href=#__codelineno-13-26></a>        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-13-27><a id=__codelineno-13-27 name=__codelineno-13-27 href=#__codelineno-13-27></a>
</span><span id=__span-13-28><a id=__codelineno-13-28 name=__codelineno-13-28 href=#__codelineno-13-28></a>        <span class=c1># Benchmark</span>
</span><span id=__span-13-29><a id=__codelineno-13-29 name=__codelineno-13-29 href=#__codelineno-13-29></a>        <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-13-30><a id=__codelineno-13-30 name=__codelineno-13-30 href=#__codelineno-13-30></a>        <span class=n>iterations</span> <span class=o>=</span> <span class=mi>100</span>
</span><span id=__span-13-31><a id=__codelineno-13-31 name=__codelineno-13-31 href=#__codelineno-13-31></a>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>iterations</span><span class=p>):</span>
</span><span id=__span-13-32><a id=__codelineno-13-32 name=__codelineno-13-32 href=#__codelineno-13-32></a>            <span class=n>c</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span><span id=__span-13-33><a id=__codelineno-13-33 name=__codelineno-13-33 href=#__codelineno-13-33></a>        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-13-34><a id=__codelineno-13-34 name=__codelineno-13-34 href=#__codelineno-13-34></a>        <span class=n>end</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-13-35><a id=__codelineno-13-35 name=__codelineno-13-35 href=#__codelineno-13-35></a>
</span><span id=__span-13-36><a id=__codelineno-13-36 name=__codelineno-13-36 href=#__codelineno-13-36></a>        <span class=c1># Calculate TFLOPS</span>
</span><span id=__span-13-37><a id=__codelineno-13-37 name=__codelineno-13-37 href=#__codelineno-13-37></a>        <span class=n>flops</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>size</span> <span class=o>**</span> <span class=mi>3</span> <span class=o>*</span> <span class=n>iterations</span>
</span><span id=__span-13-38><a id=__codelineno-13-38 name=__codelineno-13-38 href=#__codelineno-13-38></a>        <span class=n>duration</span> <span class=o>=</span> <span class=n>end</span> <span class=o>-</span> <span class=n>start</span>
</span><span id=__span-13-39><a id=__codelineno-13-39 name=__codelineno-13-39 href=#__codelineno-13-39></a>        <span class=n>tflops</span> <span class=o>=</span> <span class=n>flops</span> <span class=o>/</span> <span class=n>duration</span> <span class=o>/</span> <span class=mf>1e12</span>
</span><span id=__span-13-40><a id=__codelineno-13-40 name=__codelineno-13-40 href=#__codelineno-13-40></a>
</span><span id=__span-13-41><a id=__codelineno-13-41 name=__codelineno-13-41 href=#__codelineno-13-41></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Matrix size </span><span class=si>{</span><span class=n>size</span><span class=si>}</span><span class=s2>x</span><span class=si>{</span><span class=n>size</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>tflops</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> TFLOPS&quot;</span><span class=p>)</span>
</span><span id=__span-13-42><a id=__codelineno-13-42 name=__codelineno-13-42 href=#__codelineno-13-42></a>
</span><span id=__span-13-43><a id=__codelineno-13-43 name=__codelineno-13-43 href=#__codelineno-13-43></a>    <span class=c1># Test distributed communication if available</span>
</span><span id=__span-13-44><a id=__codelineno-13-44 name=__codelineno-13-44 href=#__codelineno-13-44></a>    <span class=k>if</span> <span class=n>get_world_size</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
</span><span id=__span-13-45><a id=__codelineno-13-45 name=__codelineno-13-45 href=#__codelineno-13-45></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Distributed setup detected: rank </span><span class=si>{</span><span class=n>get_rank</span><span class=p>()</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>get_world_size</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-13-46><a id=__codelineno-13-46 name=__codelineno-13-46 href=#__codelineno-13-46></a>        <span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span><span id=__span-13-47><a id=__codelineno-13-47 name=__codelineno-13-47 href=#__codelineno-13-47></a>        <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-13-48><a id=__codelineno-13-48 name=__codelineno-13-48 href=#__codelineno-13-48></a>        <span class=n>torch</span><span class=o>.</span><span class=n>distributed</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
</span><span id=__span-13-49><a id=__codelineno-13-49 name=__codelineno-13-49 href=#__codelineno-13-49></a>        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
</span><span id=__span-13-50><a id=__codelineno-13-50 name=__codelineno-13-50 href=#__codelineno-13-50></a>        <span class=n>duration</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>
</span><span id=__span-13-51><a id=__codelineno-13-51 name=__codelineno-13-51 href=#__codelineno-13-51></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  All-reduce latency: </span><span class=si>{</span><span class=n>duration</span><span class=o>*</span><span class=mi>1000</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-13-52><a id=__codelineno-13-52 name=__codelineno-13-52 href=#__codelineno-13-52></a>
</span><span id=__span-13-53><a id=__codelineno-13-53 name=__codelineno-13-53 href=#__codelineno-13-53></a><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
</span><span id=__span-13-54><a id=__codelineno-13-54 name=__codelineno-13-54 href=#__codelineno-13-54></a>    <span class=n>benchmark_gpu</span><span class=p>()</span>
</span></code></pre></div> <h3 id=3-multi-gpu-verification>3. Multi-GPU Verification<a class=headerlink href=#3-multi-gpu-verification title="Permanent link">&para;</a></h3> <p>Test distributed training setup:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># Single node, multiple GPUs</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>torchrun<span class=w> </span>--nproc_per_node<span class=o>=</span><span class=m>2</span><span class=w> </span>verify_distributed.py
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=c1># Multiple nodes (replace with your hostnames)</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>torchrun<span class=w> </span>--nproc_per_node<span class=o>=</span><span class=m>8</span><span class=w> </span>--nnodes<span class=o>=</span><span class=m>2</span><span class=w> </span>--node_rank<span class=o>=</span><span class=m>0</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a><span class=w>    </span>--master_addr<span class=o>=</span>node1<span class=w> </span>--master_port<span class=o>=</span><span class=m>29500</span><span class=w> </span>verify_distributed.py
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># verify_distributed.py</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.distributed</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>dist</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>DreamTrainer</span><span class=p>,</span> <span class=n>DreamTrainerConfig</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a><span class=k>def</span><span class=w> </span><span class=nf>verify_distributed</span><span class=p>():</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Verify distributed training setup&quot;&quot;&quot;</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>dist</span><span class=o>.</span><span class=n>is_initialized</span><span class=p>():</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Distributed not initialized!&quot;</span><span class=p>)</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>        <span class=k>return</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a>    <span class=n>rank</span> <span class=o>=</span> <span class=n>dist</span><span class=o>.</span><span class=n>get_rank</span><span class=p>()</span>
</span><span id=__span-15-13><a id=__codelineno-15-13 name=__codelineno-15-13 href=#__codelineno-15-13></a>    <span class=n>world_size</span> <span class=o>=</span> <span class=n>dist</span><span class=o>.</span><span class=n>get_world_size</span><span class=p>()</span>
</span><span id=__span-15-14><a id=__codelineno-15-14 name=__codelineno-15-14 href=#__codelineno-15-14></a>
</span><span id=__span-15-15><a id=__codelineno-15-15 name=__codelineno-15-15 href=#__codelineno-15-15></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Rank </span><span class=si>{</span><span class=n>rank</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>world_size</span><span class=si>}</span><span class=s2> initialized successfully&quot;</span><span class=p>)</span>
</span><span id=__span-15-16><a id=__codelineno-15-16 name=__codelineno-15-16 href=#__codelineno-15-16></a>
</span><span id=__span-15-17><a id=__codelineno-15-17 name=__codelineno-15-17 href=#__codelineno-15-17></a>    <span class=c1># Test all-reduce</span>
</span><span id=__span-15-18><a id=__codelineno-15-18 name=__codelineno-15-18 href=#__codelineno-15-18></a>    <span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>rank</span>
</span><span id=__span-15-19><a id=__codelineno-15-19 name=__codelineno-15-19 href=#__codelineno-15-19></a>    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span><span id=__span-15-20><a id=__codelineno-15-20 name=__codelineno-15-20 href=#__codelineno-15-20></a>        <span class=n>tensor</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span><span id=__span-15-21><a id=__codelineno-15-21 name=__codelineno-15-21 href=#__codelineno-15-21></a>
</span><span id=__span-15-22><a id=__codelineno-15-22 name=__codelineno-15-22 href=#__codelineno-15-22></a>    <span class=n>dist</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
</span><span id=__span-15-23><a id=__codelineno-15-23 name=__codelineno-15-23 href=#__codelineno-15-23></a>    <span class=n>expected</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>world_size</span><span class=p>))</span>
</span><span id=__span-15-24><a id=__codelineno-15-24 name=__codelineno-15-24 href=#__codelineno-15-24></a>
</span><span id=__span-15-25><a id=__codelineno-15-25 name=__codelineno-15-25 href=#__codelineno-15-25></a>    <span class=k>if</span> <span class=n>tensor</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=o>==</span> <span class=n>expected</span><span class=p>:</span>
</span><span id=__span-15-26><a id=__codelineno-15-26 name=__codelineno-15-26 href=#__codelineno-15-26></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Rank </span><span class=si>{</span><span class=n>rank</span><span class=si>}</span><span class=s2>: All-reduce test PASSED&quot;</span><span class=p>)</span>
</span><span id=__span-15-27><a id=__codelineno-15-27 name=__codelineno-15-27 href=#__codelineno-15-27></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-15-28><a id=__codelineno-15-28 name=__codelineno-15-28 href=#__codelineno-15-28></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Rank </span><span class=si>{</span><span class=n>rank</span><span class=si>}</span><span class=s2>: All-reduce test FAILED (got </span><span class=si>{</span><span class=n>tensor</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s2>, expected </span><span class=si>{</span><span class=n>expected</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</span><span id=__span-15-29><a id=__codelineno-15-29 name=__codelineno-15-29 href=#__codelineno-15-29></a>
</span><span id=__span-15-30><a id=__codelineno-15-30 name=__codelineno-15-30 href=#__codelineno-15-30></a><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
</span><span id=__span-15-31><a id=__codelineno-15-31 name=__codelineno-15-31 href=#__codelineno-15-31></a>    <span class=c1># Initialize distributed</span>
</span><span id=__span-15-32><a id=__codelineno-15-32 name=__codelineno-15-32 href=#__codelineno-15-32></a>    <span class=n>torch</span><span class=o>.</span><span class=n>distributed</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>backend</span><span class=o>=</span><span class=s2>&quot;nccl&quot;</span><span class=p>)</span>
</span><span id=__span-15-33><a id=__codelineno-15-33 name=__codelineno-15-33 href=#__codelineno-15-33></a>    <span class=n>verify_distributed</span><span class=p>()</span>
</span></code></pre></div> <h2 id=troubleshooting>Troubleshooting<a class=headerlink href=#troubleshooting title="Permanent link">&para;</a></h2> <h3 id=common-installation-issues>Common Installation Issues<a class=headerlink href=#common-installation-issues title="Permanent link">&para;</a></h3> <h4 id=1-cudapytorch-mismatch>1. CUDA/PyTorch Mismatch<a class=headerlink href=#1-cudapytorch-mismatch title="Permanent link">&para;</a></h4> <p><strong>Problem</strong>: <code>RuntimeError: CUDA error: no kernel image is available</code></p> <p><strong>Solution</strong>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># Uninstall existing PyTorch</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>pip<span class=w> </span>uninstall<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a><span class=c1># Reinstall with correct CUDA version</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>pip<span class=w> </span>install<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio<span class=w> </span>--index-url<span class=w> </span>https://download.pytorch.org/whl/cu121
</span></code></pre></div></p> <h4 id=2-missing-system-libraries>2. Missing System Libraries<a class=headerlink href=#2-missing-system-libraries title="Permanent link">&para;</a></h4> <p><strong>Problem</strong>: <code>ImportError: libcudnn.so.8: cannot open shared object file</code></p> <p><strong>Solution</strong>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=c1># On Ubuntu/Debian</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>sudo<span class=w> </span>apt-get<span class=w> </span>update
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>sudo<span class=w> </span>apt-get<span class=w> </span>install<span class=w> </span>-y<span class=w> </span>libcudnn8
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a><span class=c1># Or use conda</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>conda<span class=w> </span>install<span class=w> </span>-c<span class=w> </span>conda-forge<span class=w> </span>cudnn
</span></code></pre></div></p> <h4 id=3-memory-issues-during-installation>3. Memory Issues During Installation<a class=headerlink href=#3-memory-issues-during-installation title="Permanent link">&para;</a></h4> <p><strong>Problem</strong>: <code>MemoryError</code> or killed process during pip install</p> <p><strong>Solution</strong>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=c1># Use --no-cache-dir to reduce memory usage</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a>pip<span class=w> </span>install<span class=w> </span>--no-cache-dir<span class=w> </span>dream-trainer
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=c1># Or increase swap space</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a>sudo<span class=w> </span>fallocate<span class=w> </span>-l<span class=w> </span>8G<span class=w> </span>/swapfile
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a>sudo<span class=w> </span>chmod<span class=w> </span><span class=m>600</span><span class=w> </span>/swapfile
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a>sudo<span class=w> </span>mkswap<span class=w> </span>/swapfile
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a>sudo<span class=w> </span>swapon<span class=w> </span>/swapfile
</span></code></pre></div></p> <h4 id=4-distributed-training-issues>4. Distributed Training Issues<a class=headerlink href=#4-distributed-training-issues title="Permanent link">&para;</a></h4> <p><strong>Problem</strong>: <code>torch.distributed.DistNetworkError</code></p> <p><strong>Solution</strong>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=c1># Check network connectivity</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>ping<span class=w> </span>&lt;other-node-hostname&gt;
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a><span class=c1># Check firewall rules (allow PyTorch&#39;s default port)</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a>sudo<span class=w> </span>ufw<span class=w> </span>allow<span class=w> </span><span class=m>29500</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a><span class=c1># Test with different backend</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a><span class=nb>export</span><span class=w> </span><span class=nv>TORCH_DISTRIBUTED_DEBUG</span><span class=o>=</span>DETAIL
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a>python<span class=w> </span>train.py<span class=w>  </span><span class=c1># Will show detailed error messages</span>
</span></code></pre></div></p> <h4 id=5-import-errors-after-installation>5. Import Errors After Installation<a class=headerlink href=#5-import-errors-after-installation title="Permanent link">&para;</a></h4> <p><strong>Problem</strong>: <code>ModuleNotFoundError: No module named 'dream_trainer'</code></p> <p><strong>Solution</strong>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=c1># Ensure you&#39;re in the correct environment</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a>which<span class=w> </span>python
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a>pip<span class=w> </span>list<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>dream-trainer
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a><span class=c1># If using conda/venv, activate it</span>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a>conda<span class=w> </span>activate<span class=w> </span>myenv<span class=w>  </span><span class=c1># or</span>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a><span class=nb>source</span><span class=w> </span>venv/bin/activate
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a>
</span><span id=__span-20-9><a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a><span class=c1># Verify Python path</span>
</span><span id=__span-20-10><a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a>python<span class=w> </span>-c<span class=w> </span><span class=s2>&quot;import sys; print(sys.path)&quot;</span>
</span></code></pre></div></p> <h3 id=performance-optimization-tips>Performance Optimization Tips<a class=headerlink href=#performance-optimization-tips title="Permanent link">&para;</a></h3> <ol> <li> <p><strong>Enable NVIDIA Apex</strong> (if available): <div class="language-bash highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>pip<span class=w> </span>install<span class=w> </span>-v<span class=w> </span>--disable-pip-version-check<span class=w> </span>--no-cache-dir<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a><span class=w>    </span>--global-option<span class=o>=</span><span class=s2>&quot;--cpp_ext&quot;</span><span class=w> </span>--global-option<span class=o>=</span><span class=s2>&quot;--cuda_ext&quot;</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a><span class=w>    </span>git+https://github.com/NVIDIA/apex
</span></code></pre></div></p> </li> <li> <p><strong>Set optimal environment variables</strong>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=c1># Optimize NCCL performance</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a><span class=nb>export</span><span class=w> </span><span class=nv>NCCL_IB_DISABLE</span><span class=o>=</span><span class=m>0</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a><span class=nb>export</span><span class=w> </span><span class=nv>NCCL_IB_GID_INDEX</span><span class=o>=</span><span class=m>3</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a><span class=nb>export</span><span class=w> </span><span class=nv>NCCL_SOCKET_IFNAME</span><span class=o>=</span>eth0
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a><span class=nb>export</span><span class=w> </span><span class=nv>NCCL_DEBUG</span><span class=o>=</span>INFO
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a><span class=c1># PyTorch optimizations</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a><span class=nb>export</span><span class=w> </span><span class=nv>PYTORCH_CUDA_ALLOC_CONF</span><span class=o>=</span>expandable_segments:True
</span><span id=__span-22-9><a id=__codelineno-22-9 name=__codelineno-22-9 href=#__codelineno-22-9></a><span class=nb>export</span><span class=w> </span><span class=nv>TORCH_CUDNN_V8_API_ENABLED</span><span class=o>=</span><span class=m>1</span>
</span></code></pre></div></p> </li> <li> <p><strong>Verify GPU-Direct RDMA</strong> (for multi-node): <div class="language-bash highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=c1># Check if available</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>nvidia-smi<span class=w> </span>topo<span class=w> </span>-m
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a><span class=c1># Enable P2P access</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>sudo<span class=w> </span>nvidia-smi<span class=w> </span>-pm<span class=w> </span><span class=m>1</span>
</span></code></pre></div></p> </li> </ol> <h2 id=next-steps>Next Steps<a class=headerlink href=#next-steps title="Permanent link">&para;</a></h2> <p>After successful installation:</p> <ol> <li><strong>Follow the Getting Started Guide</strong>: Learn the basics of Dream Trainer</li> <li><strong>Explore Examples</strong>: Check out the <code>examples/</code> directory</li> <li><strong>Read the API Documentation</strong>: Understand the framework components</li> <li><strong>Join the Community</strong>: Get help and share experiences</li> </ol> <h2 id=getting-help>Getting Help<a class=headerlink href=#getting-help title="Permanent link">&para;</a></h2> <p>If you encounter issues not covered here:</p> <ol> <li>Check the <a href=/faq>FAQ</a></li> <li>Search <a href=https://github.com/dream3d-ai/dream-trainer/issues>GitHub Issues</a></li> <li>Join our <a href=https://discord.gg/dream-trainer>Discord Community</a></li> <li>Create a <a href=https://github.com/dream3d-ai/dream-trainer/issues/new>new issue</a> with:</li> <li>Your system information (OS, Python, PyTorch, CUDA versions)</li> <li>Complete error messages</li> <li>Minimal reproduction code </li> </ol> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=.. class="md-footer__link md-footer__link--prev" aria-label="Previous: Home"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Home </div> </div> </a> <a href=../getting-started/ class="md-footer__link md-footer__link--next" aria-label="Next: Quick Start"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Quick Start </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dream3d/dream-trainer target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://discord.gg/dream-trainer target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> <a href=https://twitter.com/dream3d_ai target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.prune", "navigation.indexes", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.action.edit", "content.action.view", "content.tooltips", "toc.follow", "toc.integrate"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "stable", "provider": "mike"}}</script> <script src=../assets/javascripts/bundle.56ea9cef.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> <script src=../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>