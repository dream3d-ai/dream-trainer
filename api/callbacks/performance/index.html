<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Composable distributed training framework built around PyTorch DTensor abstractions"><link href=https://dream3d.ai/trainer/api/callbacks/performance/ rel=canonical><link href=../monitoring/ rel=prev><link href=../../configuration/parameters/ rel=next><link rel=icon href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.15"><title>Performance Callbacks - dream-trainer</title><link rel=stylesheet href=../../../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../../../css/timeago.css><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#performance-callbacks class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title=dream-trainer class="md-header__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> dream-trainer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Performance Callbacks </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../installation/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../../configuration/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../../tutorials/first-trainer.md class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../../examples/vision.md class=md-tabs__link> Examples </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../../contributing.md class=md-tabs__link> Community </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=dream-trainer class="md-nav__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> dream-trainer </label> <div class=md-nav__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../installation/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../configuration/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../tutorials/first-trainer.md class=md-nav__link> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../examples/vision.md class=md-nav__link> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> API Reference </span> </a> <label class="md-nav__link " for=__nav_6 id=__nav_6_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=true> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_2> <label class=md-nav__link for=__nav_6_2 id=__nav_6_2_label tabindex> <span class=md-ellipsis> Trainers </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> Trainers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../trainers/abstract/ class=md-nav__link> <span class=md-ellipsis> AbstractTrainer </span> </a> </li> <li class=md-nav__item> <a href=../../trainers/base/ class=md-nav__link> <span class=md-ellipsis> BaseTrainer </span> </a> </li> <li class=md-nav__item> <a href=../../trainers/dream/ class=md-nav__link> <span class=md-ellipsis> DreamTrainer </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_3> <label class=md-nav__link for=__nav_6_3 id=__nav_6_3_label tabindex> <span class=md-ellipsis> Mixins </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> Mixins </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../mixins/setup/ class=md-nav__link> <span class=md-ellipsis> Setup Mixins </span> </a> </li> <li class=md-nav__item> <a href=../../mixins/eval_metric/ class=md-nav__link> <span class=md-ellipsis> Evaluation Mixins </span> </a> </li> <li class=md-nav__item> <a href=../../mixins/loggers/ class=md-nav__link> <span class=md-ellipsis> Logger Mixins </span> </a> </li> <li class=md-nav__item> <a href=../../mixins/quantize/ class=md-nav__link> <span class=md-ellipsis> Quantization Mixins </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4 checked> <label class=md-nav__link for=__nav_6_4 id=__nav_6_4_label tabindex> <span class=md-ellipsis> Callbacks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_4_label aria-expanded=true> <label class=md-nav__title for=__nav_6_4> <span class="md-nav__icon md-icon"></span> Callbacks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../base/ class=md-nav__link> <span class=md-ellipsis> Callback Base </span> </a> </li> <li class=md-nav__item> <a href=../checkpoint/ class=md-nav__link> <span class=md-ellipsis> Checkpoint Callbacks </span> </a> </li> <li class=md-nav__item> <a href=../monitoring/ class=md-nav__link> <span class=md-ellipsis> Monitoring Callbacks </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Performance Callbacks </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Performance Callbacks </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#profilecallback class=md-nav__link> <span class=md-ellipsis> ProfileCallback </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.ProfileCallback class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ProfileCallback </span> </a> <nav class=md-nav aria-label= ProfileCallback> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.ProfileCallback-functions class=md-nav__link> <span class=md-ellipsis> Functions </span> </a> <nav class=md-nav aria-label=Functions> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.ProfileCallback.pre_fit class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_fit </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#usage class=md-nav__link> <span class=md-ellipsis> Usage </span> </a> </li> <li class=md-nav__item> <a href=#analyzing-results class=md-nav__link> <span class=md-ellipsis> Analyzing Results </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#findgraphbreakscallback class=md-nav__link> <span class=md-ellipsis> FindGraphBreaksCallback </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FindGraphBreaksCallback </span> </a> <nav class=md-nav aria-label= FindGraphBreaksCallback> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback-functions class=md-nav__link> <span class=md-ellipsis> Functions </span> </a> <nav class=md-nav aria-label=Functions> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback.pre_launch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_launch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback.pre_train_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_train_step </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#usage_1 class=md-nav__link> <span class=md-ellipsis> Usage </span> </a> </li> <li class=md-nav__item> <a href=#example-output class=md-nav__link> <span class=md-ellipsis> Example Output </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimizefsdp class=md-nav__link> <span class=md-ellipsis> OptimizeFSDP </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.OptimizeFSDP class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;OptimizeFSDP </span> </a> <nav class=md-nav aria-label= OptimizeFSDP> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.OptimizeFSDP-functions class=md-nav__link> <span class=md-ellipsis> Functions </span> </a> <nav class=md-nav aria-label=Functions> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.OptimizeFSDP.pre_train_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_train_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.OptimizeFSDP.post_train_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_train_step </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#usage_2 class=md-nav__link> <span class=md-ellipsis> Usage </span> </a> </li> <li class=md-nav__item> <a href=#how-it-works class=md-nav__link> <span class=md-ellipsis> How It Works </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#faulttolerancecallback class=md-nav__link> <span class=md-ellipsis> FaultToleranceCallback </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.FaultToleranceCallback class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FaultToleranceCallback </span> </a> <nav class=md-nav aria-label= FaultToleranceCallback> <ul class=md-nav__list> <li class=md-nav__item> <a href=#usage_3 class=md-nav__link> <span class=md-ellipsis> Usage </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#fp8quantization class=md-nav__link> <span class=md-ellipsis> Fp8Quantization </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Fp8Quantization class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;Fp8Quantization </span> </a> <nav class=md-nav aria-label= Fp8Quantization> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Fp8Quantization-functions class=md-nav__link> <span class=md-ellipsis> Functions </span> </a> <nav class=md-nav aria-label=Functions> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Fp8Quantization.post_optimizer_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_optimizer_step </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#usage_4 class=md-nav__link> <span class=md-ellipsis> Usage </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#creating-custom-performance-callbacks class=md-nav__link> <span class=md-ellipsis> Creating Custom Performance Callbacks </span> </a> <nav class=md-nav aria-label="Creating Custom Performance Callbacks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#throughput-monitor class=md-nav__link> <span class=md-ellipsis> Throughput Monitor </span> </a> </li> <li class=md-nav__item> <a href=#compilation-monitor class=md-nav__link> <span class=md-ellipsis> Compilation Monitor </span> </a> </li> <li class=md-nav__item> <a href=#memory-profiler class=md-nav__link> <span class=md-ellipsis> Memory Profiler </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#performance-optimization-strategies class=md-nav__link> <span class=md-ellipsis> Performance Optimization Strategies </span> </a> <nav class=md-nav aria-label="Performance Optimization Strategies"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-profiling-strategy class=md-nav__link> <span class=md-ellipsis> 1. Profiling Strategy </span> </a> </li> <li class=md-nav__item> <a href=#2-fsdp-optimization class=md-nav__link> <span class=md-ellipsis> 2. FSDP Optimization </span> </a> </li> <li class=md-nav__item> <a href=#3-debugging-compilation class=md-nav__link> <span class=md-ellipsis> 3. Debugging Compilation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#analyzing-performance class=md-nav__link> <span class=md-ellipsis> Analyzing Performance </span> </a> <nav class=md-nav aria-label="Analyzing Performance"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#using-tensorboard class=md-nav__link> <span class=md-ellipsis> Using TensorBoard </span> </a> </li> <li class=md-nav__item> <a href=#creating-reports class=md-nav__link> <span class=md-ellipsis> Creating Reports </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#best-practices class=md-nav__link> <span class=md-ellipsis> Best Practices </span> </a> <nav class=md-nav aria-label="Best Practices"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-profile-in-stages class=md-nav__link> <span class=md-ellipsis> 1. Profile in Stages </span> </a> </li> <li class=md-nav__item> <a href=#2-use-appropriate-tools class=md-nav__link> <span class=md-ellipsis> 2. Use Appropriate Tools </span> </a> </li> <li class=md-nav__item> <a href=#3-automate-analysis class=md-nav__link> <span class=md-ellipsis> 3. Automate Analysis </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#see-also class=md-nav__link> <span class=md-ellipsis> See Also </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_5> <label class=md-nav__link for=__nav_6_5 id=__nav_6_5_label tabindex> <span class=md-ellipsis> Configuration </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_5_label aria-expanded=false> <label class=md-nav__title for=__nav_6_5> <span class="md-nav__icon md-icon"></span> Configuration </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../configuration/parameters/ class=md-nav__link> <span class=md-ellipsis> Parameter Classes </span> </a> </li> <li class=md-nav__item> <a href=../../configuration/device/ class=md-nav__link> <span class=md-ellipsis> Device Config </span> </a> </li> <li class=md-nav__item> <a href=../../configuration/training/ class=md-nav__link> <span class=md-ellipsis> Training Config </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_6> <label class=md-nav__link for=__nav_6_6 id=__nav_6_6_label tabindex> <span class=md-ellipsis> Utilities </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6_6> <span class="md-nav__icon md-icon"></span> Utilities </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../utilities/world/ class=md-nav__link> <span class=md-ellipsis> World Management </span> </a> </li> <li class=md-nav__item> <a href=../../utilities/data/ class=md-nav__link> <span class=md-ellipsis> Data Utilities </span> </a> </li> <li class=md-nav__item> <a href=../../utilities/common.md class=md-nav__link> <span class=md-ellipsis> Common Utilities </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../contributing.md class=md-nav__link> <span class=md-ellipsis> Community </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dream3d/dream-trainer/edit/main/dream-trainer/pages/docs/api/callbacks/performance.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dream3d/dream-trainer/raw/main/dream-trainer/pages/docs/api/callbacks/performance.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=performance-callbacks>Performance Callbacks<a class=headerlink href=#performance-callbacks title="Permanent link">&para;</a></h1> <p>Dream Trainer provides callbacks for profiling, optimizing, and debugging training performance.</p> <h2 id=profilecallback>ProfileCallback<a class=headerlink href=#profilecallback title="Permanent link">&para;</a></h2> <p>Profile training performance using PyTorch's profiler:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.ProfileCallback class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ProfileCallback</span> <a href=#dream_trainer.callbacks.ProfileCallback class=headerlink title="Permanent link">&para;</a></h2> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>ProfileCallback</span><span class=p>(</span><span class=n>profiler</span><span class=p>:</span> <span class=n>profile</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents first"> <p>Profiles the trainer's training step</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/profile.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-37>37</a></span>
<span class=normal><a href=#__codelineno-0-38>38</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-37><a id=__codelineno-0-37 name=__codelineno-0-37></a><span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>profiler</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>profile</span><span class=p>):</span>
</span><span id=__span-0-38><a id=__codelineno-0-38 name=__codelineno-0-38></a>    <span class=bp>self</span><span class=o>.</span><span class=n>profiler</span> <span class=o>=</span> <span class=n>profiler</span>
</span></code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <h3 id=dream_trainer.callbacks.ProfileCallback-functions>Functions<a href=#dream_trainer.callbacks.ProfileCallback-functions class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.ProfileCallback.pre_fit class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_fit</span> <a href=#dream_trainer.callbacks.ProfileCallback.pre_fit class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_fit</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/profile.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-40>40</a></span>
<span class=normal><a href=#__codelineno-0-41>41</a></span>
<span class=normal><a href=#__codelineno-0-42>42</a></span>
<span class=normal><a href=#__codelineno-0-43>43</a></span>
<span class=normal><a href=#__codelineno-0-44>44</a></span>
<span class=normal><a href=#__codelineno-0-45>45</a></span>
<span class=normal><a href=#__codelineno-0-46>46</a></span>
<span class=normal><a href=#__codelineno-0-47>47</a></span>
<span class=normal><a href=#__codelineno-0-48>48</a></span>
<span class=normal><a href=#__codelineno-0-49>49</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-40><a id=__codelineno-0-40 name=__codelineno-0-40></a><span class=nd>@override</span>
</span><span id=__span-0-41><a id=__codelineno-0-41 name=__codelineno-0-41></a><span class=k>def</span><span class=w> </span><span class=nf>pre_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-42><a id=__codelineno-0-42 name=__codelineno-0-42></a>    <span class=n>original_training_step</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>training_step</span>
</span><span id=__span-0-43><a id=__codelineno-0-43 name=__codelineno-0-43></a>
</span><span id=__span-0-44><a id=__codelineno-0-44 name=__codelineno-0-44></a>    <span class=k>def</span><span class=w> </span><span class=nf>profiled_training_step</span><span class=p>(</span><span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span><span id=__span-0-45><a id=__codelineno-0-45 name=__codelineno-0-45></a>        <span class=n>out</span> <span class=o>=</span> <span class=n>original_training_step</span><span class=p>(</span><span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span><span id=__span-0-46><a id=__codelineno-0-46 name=__codelineno-0-46></a>        <span class=bp>self</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-0-47><a id=__codelineno-0-47 name=__codelineno-0-47></a>        <span class=k>return</span> <span class=n>out</span>
</span><span id=__span-0-48><a id=__codelineno-0-48 name=__codelineno-0-48></a>
</span><span id=__span-0-49><a id=__codelineno-0-49 name=__codelineno-0-49></a>    <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>training_step</span> <span class=o>=</span> <span class=n>profiled_training_step</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div><h3 id=usage>Usage<a class=headerlink href=#usage title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.profiler</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>ProfileCallback</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=c1># Create profiler</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=n>profiler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>profile</span><span class=p>(</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>    <span class=n>activities</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>        <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CPU</span><span class=p>,</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>        <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CUDA</span><span class=p>,</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    <span class=p>],</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=n>schedule</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>schedule</span><span class=p>(</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>        <span class=n>wait</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>        <span class=n>warmup</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>        <span class=n>active</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>        <span class=n>repeat</span><span class=o>=</span><span class=mi>2</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>    <span class=p>),</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>    <span class=n>on_trace_ready</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>tensorboard_trace_handler</span><span class=p>(</span><span class=s1>&#39;./logs&#39;</span><span class=p>),</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>    <span class=n>record_shapes</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>    <span class=n>profile_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>    <span class=n>with_stack</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=p>)</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=c1># Add to callbacks</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=n>callback</span> <span class=o>=</span> <span class=n>ProfileCallback</span><span class=p>(</span><span class=n>profiler</span><span class=p>)</span>
</span></code></pre></div> <h3 id=analyzing-results>Analyzing Results<a class=headerlink href=#analyzing-results title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># View in TensorBoard</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=c1># tensorboard --logdir=./logs</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=c1># Or analyze programmatically</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>profiler</span><span class=o>.</span><span class=n>export_chrome_trace</span><span class=p>(</span><span class=s2>&quot;trace.json&quot;</span><span class=p>)</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=nb>print</span><span class=p>(</span><span class=n>profiler</span><span class=o>.</span><span class=n>key_averages</span><span class=p>()</span><span class=o>.</span><span class=n>table</span><span class=p>(</span><span class=n>sort_by</span><span class=o>=</span><span class=s2>&quot;cuda_time_total&quot;</span><span class=p>))</span>
</span></code></pre></div> <h2 id=findgraphbreakscallback>FindGraphBreaksCallback<a class=headerlink href=#findgraphbreakscallback title="Permanent link">&para;</a></h2> <p>Debug torch.compile graph breaks:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.FindGraphBreaksCallback class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">FindGraphBreaksCallback</span> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback class=headerlink title="Permanent link">&para;</a></h2> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>FindGraphBreaksCallback</span><span class=p>(</span><span class=n>log_file</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s1>&#39;graph_breaks.log&#39;</span><span class=p>,</span> <span class=n>skip</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>fullgraph</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents first"> <p>Find graph breaks in the trainer. This will check every compiled function in the trainer and write all the graph breaks to a file.</p> <p>NOTE: We only check for graph breaks in training steps.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>log_file</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>File to write graph breaks to.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=str>str</span></code> </span> <span class=doc-param-default> <b>DEFAULT:</b> <code>&#39;graph_breaks.log&#39;</code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>skip</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>Number of steps to skip before finding graph breaks.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> <span class=doc-param-default> <b>DEFAULT:</b> <code>0</code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/graph_breaks.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-156>156</a></span>
<span class=normal><a href=#__codelineno-0-157>157</a></span>
<span class=normal><a href=#__codelineno-0-158>158</a></span>
<span class=normal><a href=#__codelineno-0-159>159</a></span>
<span class=normal><a href=#__codelineno-0-160>160</a></span>
<span class=normal><a href=#__codelineno-0-161>161</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-156><a id=__codelineno-0-156 name=__codelineno-0-156></a><span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
</span><span id=__span-0-157><a id=__codelineno-0-157 name=__codelineno-0-157></a>    <span class=bp>self</span><span class=p>,</span> <span class=n>log_file</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;graph_breaks.log&quot;</span><span class=p>,</span> <span class=n>skip</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=n>fullgraph</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span>
</span><span id=__span-0-158><a id=__codelineno-0-158 name=__codelineno-0-158></a><span class=p>):</span>
</span><span id=__span-0-159><a id=__codelineno-0-159 name=__codelineno-0-159></a>    <span class=bp>self</span><span class=o>.</span><span class=n>log_file</span> <span class=o>=</span> <span class=n>log_file</span>
</span><span id=__span-0-160><a id=__codelineno-0-160 name=__codelineno-0-160></a>    <span class=bp>self</span><span class=o>.</span><span class=n>skip</span> <span class=o>=</span> <span class=n>skip</span>
</span><span id=__span-0-161><a id=__codelineno-0-161 name=__codelineno-0-161></a>    <span class=bp>self</span><span class=o>.</span><span class=n>full_graph</span> <span class=o>=</span> <span class=n>fullgraph</span>
</span></code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <h3 id=dream_trainer.callbacks.FindGraphBreaksCallback-functions>Functions<a href=#dream_trainer.callbacks.FindGraphBreaksCallback-functions class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.FindGraphBreaksCallback.pre_launch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_launch</span> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback.pre_launch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_launch</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/graph_breaks.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-163>163</a></span>
<span class=normal><a href=#__codelineno-0-164>164</a></span>
<span class=normal><a href=#__codelineno-0-165>165</a></span>
<span class=normal><a href=#__codelineno-0-166>166</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-163><a id=__codelineno-0-163 name=__codelineno-0-163></a><span class=nd>@override</span>
</span><span id=__span-0-164><a id=__codelineno-0-164 name=__codelineno-0-164></a><span class=k>def</span><span class=w> </span><span class=nf>pre_launch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-165><a id=__codelineno-0-165 name=__codelineno-0-165></a>    <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>device_parameters</span><span class=o>.</span><span class=n>compile_model</span> <span class=o>=</span> <span class=kc>False</span>
</span><span id=__span-0-166><a id=__codelineno-0-166 name=__codelineno-0-166></a>    <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>training_parameters</span><span class=o>.</span><span class=n>num_sanity_val_steps</span> <span class=o>=</span> <span class=mi>0</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.FindGraphBreaksCallback.pre_train_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_train_step</span> <a href=#dream_trainer.callbacks.FindGraphBreaksCallback.pre_train_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_train_step</span><span class=p>(</span><span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/graph_breaks.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-168>168</a></span>
<span class=normal><a href=#__codelineno-0-169>169</a></span>
<span class=normal><a href=#__codelineno-0-170>170</a></span>
<span class=normal><a href=#__codelineno-0-171>171</a></span>
<span class=normal><a href=#__codelineno-0-172>172</a></span>
<span class=normal><a href=#__codelineno-0-173>173</a></span>
<span class=normal><a href=#__codelineno-0-174>174</a></span>
<span class=normal><a href=#__codelineno-0-175>175</a></span>
<span class=normal><a href=#__codelineno-0-176>176</a></span>
<span class=normal><a href=#__codelineno-0-177>177</a></span>
<span class=normal><a href=#__codelineno-0-178>178</a></span>
<span class=normal><a href=#__codelineno-0-179>179</a></span>
<span class=normal><a href=#__codelineno-0-180>180</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-168><a id=__codelineno-0-168 name=__codelineno-0-168></a><span class=nd>@override</span>
</span><span id=__span-0-169><a id=__codelineno-0-169 name=__codelineno-0-169></a><span class=k>def</span><span class=w> </span><span class=nf>pre_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-170><a id=__codelineno-0-170 name=__codelineno-0-170></a>    <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>skip</span><span class=p>:</span>
</span><span id=__span-0-171><a id=__codelineno-0-171 name=__codelineno-0-171></a>        <span class=k>return</span>
</span><span id=__span-0-172><a id=__codelineno-0-172 name=__codelineno-0-172></a>
</span><span id=__span-0-173><a id=__codelineno-0-173 name=__codelineno-0-173></a>    <span class=n>please_find_graph_breaks</span><span class=p>(</span>
</span><span id=__span-0-174><a id=__codelineno-0-174 name=__codelineno-0-174></a>        <span class=n>trainer</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=p>,</span>
</span><span id=__span-0-175><a id=__codelineno-0-175 name=__codelineno-0-175></a>        <span class=n>batch</span><span class=o>=</span><span class=n>batch</span><span class=p>,</span>
</span><span id=__span-0-176><a id=__codelineno-0-176 name=__codelineno-0-176></a>        <span class=n>batch_idx</span><span class=o>=</span><span class=n>batch_idx</span><span class=p>,</span>
</span><span id=__span-0-177><a id=__codelineno-0-177 name=__codelineno-0-177></a>        <span class=n>path</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>log_file</span><span class=p>,</span>
</span><span id=__span-0-178><a id=__codelineno-0-178 name=__codelineno-0-178></a>        <span class=n>fullgraph</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>full_graph</span><span class=p>,</span>
</span><span id=__span-0-179><a id=__codelineno-0-179 name=__codelineno-0-179></a>    <span class=p>)</span>
</span><span id=__span-0-180><a id=__codelineno-0-180 name=__codelineno-0-180></a>    <span class=n>exit</span><span class=p>()</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div><h3 id=usage_1>Usage<a class=headerlink href=#usage_1 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>FindGraphBreaksCallback</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=c1># Find all graph breaks</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=n>graph_breaks</span> <span class=o>=</span> <span class=n>FindGraphBreaksCallback</span><span class=p>(</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>    <span class=n>log_file</span><span class=o>=</span><span class=s2>&quot;graph_breaks.log&quot;</span><span class=p>,</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>    <span class=n>skip</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>  <span class=c1># Skip no steps</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>    <span class=n>fullgraph</span><span class=o>=</span><span class=kc>False</span>  <span class=c1># Test without fullgraph</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=p>)</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=c1># Test if model can compile with fullgraph=True</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=n>fullgraph_test</span> <span class=o>=</span> <span class=n>FindGraphBreaksCallback</span><span class=p>(</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>    <span class=n>log_file</span><span class=o>=</span><span class=s2>&quot;fullgraph_test.log&quot;</span><span class=p>,</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>    <span class=n>skip</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>    <span class=n>fullgraph</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a><span class=p>)</span>
</span></code></pre></div> <h3 id=example-output>Example Output<a class=headerlink href=#example-output title="Permanent link">&para;</a></h3> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>================================================================================
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>model.encoder.attention
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>/path/to/model.py:45 - Graph break due to:
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>  - Dynamic control flow (if statement depending on tensor value)
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>  - Suggested fix: Use torch.where or masked operations
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>================================================================================
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>model.decoder.generate
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>/path/to/model.py:123 - Graph break due to:
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>  - Python builtin not supported in graph
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>  - Suggested fix: Use torch operations instead of Python list comprehension
</span></code></pre></div> <h2 id=optimizefsdp>OptimizeFSDP<a class=headerlink href=#optimizefsdp title="Permanent link">&para;</a></h2> <p>Optimize FSDP performance with advanced prefetching:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.OptimizeFSDP class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">OptimizeFSDP</span> <a href=#dream_trainer.callbacks.OptimizeFSDP class=headerlink title="Permanent link">&para;</a></h2> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>OptimizeFSDP</span><span class=p>(</span><span class=n>prefetch</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span> <span class=n>display</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents first"> <p>FSDP optimization callback that improves training performance through intelligent prefetching.</p> <p>This callback optimizes Fully Sharded Data Parallel (FSDP) training by: 1. Tracing the execution order of FSDP modules during the first training step 2. Setting up prefetching for both forward and backward passes based on the traced order 3. Unsharding models asynchronously before each training step</p> <p>The prefetching mechanism overlaps data movement with computation, reducing idle time and improving overall training throughput.</p> <p>Prefetch Behavior: - prefetch=1: Uses singleton lists, providing the same all-gather overlap as default behavior but issues prefetched all-gathers earlier from the CPU - prefetch&gt;=2: Enables more aggressive overlap with higher memory usage due to additional reserved memory for prefetched modules</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>prefetch</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>Number of modules to prefetch ahead. Higher values increase memory usage but may improve performance. Must be &gt;= 1. Defaults to 1.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> <span class=doc-param-default> <b>DEFAULT:</b> <code>1</code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>display</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>Whether to display the tree of FSDP modules after construction. Defaults to True.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=bool>bool</span></code> </span> <span class=doc-param-default> <b>DEFAULT:</b> <code>False</code> </span> </p> </td> </tr> </tbody> </table> <table> <thead> <tr> <th><span class=doc-section-title>ATTRIBUTE</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=dream_trainer.callbacks.OptimizeFSDP.prefetch>prefetch</span></code></td> <td class=doc-attribute-details> <div class=doc-md-description> <p>The number of modules to prefetch ahead.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> </p> </td> </tr> <tr class=doc-section-item> <td><code><span title=dream_trainer.callbacks.OptimizeFSDP.stack>stack</span></code></td> <td class=doc-attribute-details> <div class=doc-md-description> <p>List of (module_name, requires_grad) tuples tracking execution order.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-attribute-annotation> <b>TYPE:</b> <code><span title=list>list</span>[<span title=tuple>tuple</span>[<span title=str>str</span>, <span title=bool>bool</span>, <span title=typing.Literal>Literal</span>[&#39;pre_forward_call&#39;, &#39;post_forward_call&#39;, &#39;prefetch&#39;]]]</code> </span> </p> </td> </tr> <tr class=doc-section-item> <td><code><span title=dream_trainer.callbacks.OptimizeFSDP.hooks>hooks</span></code></td> <td class=doc-attribute-details> <div class=doc-md-description> <p>List of registered forward hooks for tracing module execution.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-attribute-annotation> <b>TYPE:</b> <code><span title=list>list</span>[<span title=torch.utils.hooks.RemovableHandle>RemovableHandle</span>]</code> </span> </p> </td> </tr> </tbody> </table> <p>Initialize the FSDP optimization callback.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>prefetch</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>Number of modules to prefetch ahead. Must be &gt;= 1. Values &gt;= 2 enable more aggressive overlap but use more memory.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> <span class=doc-param-default> <b>DEFAULT:</b> <code>1</code> </span> </p> </td> </tr> </tbody> </table> <table> <thead> <tr> <th><span class=doc-section-title>RAISES</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <span class=doc-raises-annotation> <code><span title=ValueError>ValueError</span></code> </span> </td> <td class=doc-raises-details> <div class=doc-md-description> <p>If prefetch is less than 1.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/optimize_fsdp.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-119>119</a></span>
<span class=normal><a href=#__codelineno-0-120>120</a></span>
<span class=normal><a href=#__codelineno-0-121>121</a></span>
<span class=normal><a href=#__codelineno-0-122>122</a></span>
<span class=normal><a href=#__codelineno-0-123>123</a></span>
<span class=normal><a href=#__codelineno-0-124>124</a></span>
<span class=normal><a href=#__codelineno-0-125>125</a></span>
<span class=normal><a href=#__codelineno-0-126>126</a></span>
<span class=normal><a href=#__codelineno-0-127>127</a></span>
<span class=normal><a href=#__codelineno-0-128>128</a></span>
<span class=normal><a href=#__codelineno-0-129>129</a></span>
<span class=normal><a href=#__codelineno-0-130>130</a></span>
<span class=normal><a href=#__codelineno-0-131>131</a></span>
<span class=normal><a href=#__codelineno-0-132>132</a></span>
<span class=normal><a href=#__codelineno-0-133>133</a></span>
<span class=normal><a href=#__codelineno-0-134>134</a></span>
<span class=normal><a href=#__codelineno-0-135>135</a></span>
<span class=normal><a href=#__codelineno-0-136>136</a></span>
<span class=normal><a href=#__codelineno-0-137>137</a></span>
<span class=normal><a href=#__codelineno-0-138>138</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-119><a id=__codelineno-0-119 name=__codelineno-0-119></a><span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prefetch</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span> <span class=n>display</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>):</span>
</span><span id=__span-0-120><a id=__codelineno-0-120 name=__codelineno-0-120></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Initialize the FSDP optimization callback.</span>
</span><span id=__span-0-121><a id=__codelineno-0-121 name=__codelineno-0-121></a>
</span><span id=__span-0-122><a id=__codelineno-0-122 name=__codelineno-0-122></a><span class=sd>    Args:</span>
</span><span id=__span-0-123><a id=__codelineno-0-123 name=__codelineno-0-123></a><span class=sd>        prefetch: Number of modules to prefetch ahead. Must be &gt;= 1.</span>
</span><span id=__span-0-124><a id=__codelineno-0-124 name=__codelineno-0-124></a><span class=sd>            Values &gt;= 2 enable more aggressive overlap but use more memory.</span>
</span><span id=__span-0-125><a id=__codelineno-0-125 name=__codelineno-0-125></a>
</span><span id=__span-0-126><a id=__codelineno-0-126 name=__codelineno-0-126></a><span class=sd>    Raises:</span>
</span><span id=__span-0-127><a id=__codelineno-0-127 name=__codelineno-0-127></a><span class=sd>        ValueError: If prefetch is less than 1.</span>
</span><span id=__span-0-128><a id=__codelineno-0-128 name=__codelineno-0-128></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-129><a id=__codelineno-0-129 name=__codelineno-0-129></a>    <span class=k>if</span> <span class=n>prefetch</span> <span class=o>&lt;</span> <span class=mi>1</span><span class=p>:</span>
</span><span id=__span-0-130><a id=__codelineno-0-130 name=__codelineno-0-130></a>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;prefetch must be &gt;= 1, got </span><span class=si>{</span><span class=n>prefetch</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-131><a id=__codelineno-0-131 name=__codelineno-0-131></a>
</span><span id=__span-0-132><a id=__codelineno-0-132 name=__codelineno-0-132></a>    <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span> <span class=o>=</span> <span class=n>prefetch</span>
</span><span id=__span-0-133><a id=__codelineno-0-133 name=__codelineno-0-133></a>    <span class=bp>self</span><span class=o>.</span><span class=n>display</span> <span class=o>=</span> <span class=n>display</span>
</span><span id=__span-0-134><a id=__codelineno-0-134 name=__codelineno-0-134></a>
</span><span id=__span-0-135><a id=__codelineno-0-135 name=__codelineno-0-135></a>    <span class=bp>self</span><span class=o>.</span><span class=n>stack</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span>
</span><span id=__span-0-136><a id=__codelineno-0-136 name=__codelineno-0-136></a>        <span class=nb>tuple</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>bool</span><span class=p>,</span> <span class=n>Literal</span><span class=p>[</span><span class=s2>&quot;pre_forward_call&quot;</span><span class=p>,</span> <span class=s2>&quot;post_forward_call&quot;</span><span class=p>,</span> <span class=s2>&quot;prefetch&quot;</span><span class=p>]]</span>
</span><span id=__span-0-137><a id=__codelineno-0-137 name=__codelineno-0-137></a>    <span class=p>]</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-0-138><a id=__codelineno-0-138 name=__codelineno-0-138></a>    <span class=bp>self</span><span class=o>.</span><span class=n>hooks</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=n>RemovableHandle</span><span class=p>]</span> <span class=o>=</span> <span class=p>[]</span>
</span></code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <h3 id=dream_trainer.callbacks.OptimizeFSDP-functions>Functions<a href=#dream_trainer.callbacks.OptimizeFSDP-functions class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.OptimizeFSDP.pre_train_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_train_step</span> <a href=#dream_trainer.callbacks.OptimizeFSDP.pre_train_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_train_step</span><span class=p>(</span><span class=o>*</span><span class=n>_</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Unshard FSDP models asynchronously before training step.</p> <p>This method is called before each training step. It triggers asynchronous unsharding of the first all-gather of all FSDP model, allowing the unsharding operation to overlap with other computations and reducing the time spent waiting for data movement.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>*_</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>Unused arguments from the trainer callback interface.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-default> <b>DEFAULT:</b> <code>()</code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/optimize_fsdp.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-235>235</a></span>
<span class=normal><a href=#__codelineno-0-236>236</a></span>
<span class=normal><a href=#__codelineno-0-237>237</a></span>
<span class=normal><a href=#__codelineno-0-238>238</a></span>
<span class=normal><a href=#__codelineno-0-239>239</a></span>
<span class=normal><a href=#__codelineno-0-240>240</a></span>
<span class=normal><a href=#__codelineno-0-241>241</a></span>
<span class=normal><a href=#__codelineno-0-242>242</a></span>
<span class=normal><a href=#__codelineno-0-243>243</a></span>
<span class=normal><a href=#__codelineno-0-244>244</a></span>
<span class=normal><a href=#__codelineno-0-245>245</a></span>
<span class=normal><a href=#__codelineno-0-246>246</a></span>
<span class=normal><a href=#__codelineno-0-247>247</a></span>
<span class=normal><a href=#__codelineno-0-248>248</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-235><a id=__codelineno-0-235 name=__codelineno-0-235></a><span class=nd>@override</span>
</span><span id=__span-0-236><a id=__codelineno-0-236 name=__codelineno-0-236></a><span class=k>def</span><span class=w> </span><span class=nf>pre_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=n>_</span><span class=p>):</span>
</span><span id=__span-0-237><a id=__codelineno-0-237 name=__codelineno-0-237></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Unshard FSDP models asynchronously before training step.</span>
</span><span id=__span-0-238><a id=__codelineno-0-238 name=__codelineno-0-238></a>
</span><span id=__span-0-239><a id=__codelineno-0-239 name=__codelineno-0-239></a><span class=sd>    This method is called before each training step. It triggers asynchronous unsharding of</span>
</span><span id=__span-0-240><a id=__codelineno-0-240 name=__codelineno-0-240></a><span class=sd>    the first all-gather of all FSDP model, allowing the unsharding operation to overlap</span>
</span><span id=__span-0-241><a id=__codelineno-0-241 name=__codelineno-0-241></a><span class=sd>    with other computations and reducing the time spent waiting for data movement.</span>
</span><span id=__span-0-242><a id=__codelineno-0-242 name=__codelineno-0-242></a>
</span><span id=__span-0-243><a id=__codelineno-0-243 name=__codelineno-0-243></a><span class=sd>    Args:</span>
</span><span id=__span-0-244><a id=__codelineno-0-244 name=__codelineno-0-244></a><span class=sd>        *_: Unused arguments from the trainer callback interface.</span>
</span><span id=__span-0-245><a id=__codelineno-0-245 name=__codelineno-0-245></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-246><a id=__codelineno-0-246 name=__codelineno-0-246></a>    <span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>model</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>named_models</span><span class=p>()</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-0-247><a id=__codelineno-0-247 name=__codelineno-0-247></a>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>FSDPModule</span><span class=p>):</span>
</span><span id=__span-0-248><a id=__codelineno-0-248 name=__codelineno-0-248></a>            <span class=n>model</span><span class=o>.</span><span class=n>unshard</span><span class=p>(</span><span class=n>async_op</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.OptimizeFSDP.post_train_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_train_step</span> <a href=#dream_trainer.callbacks.OptimizeFSDP.post_train_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_train_step</span><span class=p>(</span><span class=n>_</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Set up prefetching based on traced execution order and clean up hooks.</p> <p>This method is called after the first training step. It uses the execution order recorded by the hooks to set up optimal prefetching for both forward and backward passes. After setting up prefetching, it removes all hooks and clears the execution stack since tracing is only needed once.</p> <p>The prefetching setup works by: 1. Using the forward execution order for forward prefetching 2. Using the reverse order (filtering only modules with gradients) for backward prefetching 3. Setting each module to prefetch the next <code>prefetch</code> modules in sequence</p> <p>Prefetch list behavior: - Single module lists (prefetch=1): Same overlap as default, earlier CPU scheduling - Multi-module lists (prefetch&gt;=2): More aggressive overlap, higher memory usage</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>*_</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>Unused arguments from the trainer callback interface.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/optimize_fsdp.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-250>250</a></span>
<span class=normal><a href=#__codelineno-0-251>251</a></span>
<span class=normal><a href=#__codelineno-0-252>252</a></span>
<span class=normal><a href=#__codelineno-0-253>253</a></span>
<span class=normal><a href=#__codelineno-0-254>254</a></span>
<span class=normal><a href=#__codelineno-0-255>255</a></span>
<span class=normal><a href=#__codelineno-0-256>256</a></span>
<span class=normal><a href=#__codelineno-0-257>257</a></span>
<span class=normal><a href=#__codelineno-0-258>258</a></span>
<span class=normal><a href=#__codelineno-0-259>259</a></span>
<span class=normal><a href=#__codelineno-0-260>260</a></span>
<span class=normal><a href=#__codelineno-0-261>261</a></span>
<span class=normal><a href=#__codelineno-0-262>262</a></span>
<span class=normal><a href=#__codelineno-0-263>263</a></span>
<span class=normal><a href=#__codelineno-0-264>264</a></span>
<span class=normal><a href=#__codelineno-0-265>265</a></span>
<span class=normal><a href=#__codelineno-0-266>266</a></span>
<span class=normal><a href=#__codelineno-0-267>267</a></span>
<span class=normal><a href=#__codelineno-0-268>268</a></span>
<span class=normal><a href=#__codelineno-0-269>269</a></span>
<span class=normal><a href=#__codelineno-0-270>270</a></span>
<span class=normal><a href=#__codelineno-0-271>271</a></span>
<span class=normal><a href=#__codelineno-0-272>272</a></span>
<span class=normal><a href=#__codelineno-0-273>273</a></span>
<span class=normal><a href=#__codelineno-0-274>274</a></span>
<span class=normal><a href=#__codelineno-0-275>275</a></span>
<span class=normal><a href=#__codelineno-0-276>276</a></span>
<span class=normal><a href=#__codelineno-0-277>277</a></span>
<span class=normal><a href=#__codelineno-0-278>278</a></span>
<span class=normal><a href=#__codelineno-0-279>279</a></span>
<span class=normal><a href=#__codelineno-0-280>280</a></span>
<span class=normal><a href=#__codelineno-0-281>281</a></span>
<span class=normal><a href=#__codelineno-0-282>282</a></span>
<span class=normal><a href=#__codelineno-0-283>283</a></span>
<span class=normal><a href=#__codelineno-0-284>284</a></span>
<span class=normal><a href=#__codelineno-0-285>285</a></span>
<span class=normal><a href=#__codelineno-0-286>286</a></span>
<span class=normal><a href=#__codelineno-0-287>287</a></span>
<span class=normal><a href=#__codelineno-0-288>288</a></span>
<span class=normal><a href=#__codelineno-0-289>289</a></span>
<span class=normal><a href=#__codelineno-0-290>290</a></span>
<span class=normal><a href=#__codelineno-0-291>291</a></span>
<span class=normal><a href=#__codelineno-0-292>292</a></span>
<span class=normal><a href=#__codelineno-0-293>293</a></span>
<span class=normal><a href=#__codelineno-0-294>294</a></span>
<span class=normal><a href=#__codelineno-0-295>295</a></span>
<span class=normal><a href=#__codelineno-0-296>296</a></span>
<span class=normal><a href=#__codelineno-0-297>297</a></span>
<span class=normal><a href=#__codelineno-0-298>298</a></span>
<span class=normal><a href=#__codelineno-0-299>299</a></span>
<span class=normal><a href=#__codelineno-0-300>300</a></span>
<span class=normal><a href=#__codelineno-0-301>301</a></span>
<span class=normal><a href=#__codelineno-0-302>302</a></span>
<span class=normal><a href=#__codelineno-0-303>303</a></span>
<span class=normal><a href=#__codelineno-0-304>304</a></span>
<span class=normal><a href=#__codelineno-0-305>305</a></span>
<span class=normal><a href=#__codelineno-0-306>306</a></span>
<span class=normal><a href=#__codelineno-0-307>307</a></span>
<span class=normal><a href=#__codelineno-0-308>308</a></span>
<span class=normal><a href=#__codelineno-0-309>309</a></span>
<span class=normal><a href=#__codelineno-0-310>310</a></span>
<span class=normal><a href=#__codelineno-0-311>311</a></span>
<span class=normal><a href=#__codelineno-0-312>312</a></span>
<span class=normal><a href=#__codelineno-0-313>313</a></span>
<span class=normal><a href=#__codelineno-0-314>314</a></span>
<span class=normal><a href=#__codelineno-0-315>315</a></span>
<span class=normal><a href=#__codelineno-0-316>316</a></span>
<span class=normal><a href=#__codelineno-0-317>317</a></span>
<span class=normal><a href=#__codelineno-0-318>318</a></span>
<span class=normal><a href=#__codelineno-0-319>319</a></span>
<span class=normal><a href=#__codelineno-0-320>320</a></span>
<span class=normal><a href=#__codelineno-0-321>321</a></span>
<span class=normal><a href=#__codelineno-0-322>322</a></span>
<span class=normal><a href=#__codelineno-0-323>323</a></span>
<span class=normal><a href=#__codelineno-0-324>324</a></span>
<span class=normal><a href=#__codelineno-0-325>325</a></span>
<span class=normal><a href=#__codelineno-0-326>326</a></span>
<span class=normal><a href=#__codelineno-0-327>327</a></span>
<span class=normal><a href=#__codelineno-0-328>328</a></span>
<span class=normal><a href=#__codelineno-0-329>329</a></span>
<span class=normal><a href=#__codelineno-0-330>330</a></span>
<span class=normal><a href=#__codelineno-0-331>331</a></span>
<span class=normal><a href=#__codelineno-0-332>332</a></span>
<span class=normal><a href=#__codelineno-0-333>333</a></span>
<span class=normal><a href=#__codelineno-0-334>334</a></span>
<span class=normal><a href=#__codelineno-0-335>335</a></span>
<span class=normal><a href=#__codelineno-0-336>336</a></span>
<span class=normal><a href=#__codelineno-0-337>337</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-250><a id=__codelineno-0-250 name=__codelineno-0-250></a><span class=nd>@override</span>
</span><span id=__span-0-251><a id=__codelineno-0-251 name=__codelineno-0-251></a><span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-252><a id=__codelineno-0-252 name=__codelineno-0-252></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Set up prefetching based on traced execution order and clean up hooks.</span>
</span><span id=__span-0-253><a id=__codelineno-0-253 name=__codelineno-0-253></a>
</span><span id=__span-0-254><a id=__codelineno-0-254 name=__codelineno-0-254></a><span class=sd>    This method is called after the first training step. It uses the execution</span>
</span><span id=__span-0-255><a id=__codelineno-0-255 name=__codelineno-0-255></a><span class=sd>    order recorded by the hooks to set up optimal prefetching for both forward</span>
</span><span id=__span-0-256><a id=__codelineno-0-256 name=__codelineno-0-256></a><span class=sd>    and backward passes. After setting up prefetching, it removes all hooks</span>
</span><span id=__span-0-257><a id=__codelineno-0-257 name=__codelineno-0-257></a><span class=sd>    and clears the execution stack since tracing is only needed once.</span>
</span><span id=__span-0-258><a id=__codelineno-0-258 name=__codelineno-0-258></a>
</span><span id=__span-0-259><a id=__codelineno-0-259 name=__codelineno-0-259></a><span class=sd>    The prefetching setup works by:</span>
</span><span id=__span-0-260><a id=__codelineno-0-260 name=__codelineno-0-260></a><span class=sd>    1. Using the forward execution order for forward prefetching</span>
</span><span id=__span-0-261><a id=__codelineno-0-261 name=__codelineno-0-261></a><span class=sd>    2. Using the reverse order (filtering only modules with gradients) for backward prefetching</span>
</span><span id=__span-0-262><a id=__codelineno-0-262 name=__codelineno-0-262></a><span class=sd>    3. Setting each module to prefetch the next `prefetch` modules in sequence</span>
</span><span id=__span-0-263><a id=__codelineno-0-263 name=__codelineno-0-263></a>
</span><span id=__span-0-264><a id=__codelineno-0-264 name=__codelineno-0-264></a><span class=sd>    Prefetch list behavior:</span>
</span><span id=__span-0-265><a id=__codelineno-0-265 name=__codelineno-0-265></a><span class=sd>    - Single module lists (prefetch=1): Same overlap as default, earlier CPU scheduling</span>
</span><span id=__span-0-266><a id=__codelineno-0-266 name=__codelineno-0-266></a><span class=sd>    - Multi-module lists (prefetch&gt;=2): More aggressive overlap, higher memory usage</span>
</span><span id=__span-0-267><a id=__codelineno-0-267 name=__codelineno-0-267></a>
</span><span id=__span-0-268><a id=__codelineno-0-268 name=__codelineno-0-268></a><span class=sd>    Args:</span>
</span><span id=__span-0-269><a id=__codelineno-0-269 name=__codelineno-0-269></a><span class=sd>        *_: Unused arguments from the trainer callback interface.</span>
</span><span id=__span-0-270><a id=__codelineno-0-270 name=__codelineno-0-270></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-271><a id=__codelineno-0-271 name=__codelineno-0-271></a>
</span><span id=__span-0-272><a id=__codelineno-0-272 name=__codelineno-0-272></a>    <span class=c1># Add forward prefetching after first training step</span>
</span><span id=__span-0-273><a id=__codelineno-0-273 name=__codelineno-0-273></a>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>local_batches</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-0-274><a id=__codelineno-0-274 name=__codelineno-0-274></a>        <span class=n>prefetch_mode</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-0-275><a id=__codelineno-0-275 name=__codelineno-0-275></a>            <span class=s2>&quot;conservative (singleton lists)&quot;</span>
</span><span id=__span-0-276><a id=__codelineno-0-276 name=__codelineno-0-276></a>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span> <span class=o>==</span> <span class=mi>1</span>
</span><span id=__span-0-277><a id=__codelineno-0-277 name=__codelineno-0-277></a>            <span class=k>else</span> <span class=s2>&quot;aggressive (multi-module lists)&quot;</span>
</span><span id=__span-0-278><a id=__codelineno-0-278 name=__codelineno-0-278></a>        <span class=p>)</span>
</span><span id=__span-0-279><a id=__codelineno-0-279 name=__codelineno-0-279></a>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span>
</span><span id=__span-0-280><a id=__codelineno-0-280 name=__codelineno-0-280></a>            <span class=sa>f</span><span class=s2>&quot;Setting up </span><span class=si>{</span><span class=n>prefetch_mode</span><span class=si>}</span><span class=s2> prefetch for </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>stack</span><span class=p>)</span><span class=si>}</span><span class=s2> forward and backward calls &quot;</span>
</span><span id=__span-0-281><a id=__codelineno-0-281 name=__codelineno-0-281></a>            <span class=sa>f</span><span class=s2>&quot;with prefetch factor </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span><span class=si>}</span><span class=s2>&quot;</span>
</span><span id=__span-0-282><a id=__codelineno-0-282 name=__codelineno-0-282></a>        <span class=p>)</span>
</span><span id=__span-0-283><a id=__codelineno-0-283 name=__codelineno-0-283></a>
</span><span id=__span-0-284><a id=__codelineno-0-284 name=__codelineno-0-284></a>        <span class=c1># Get the modules in order of execution</span>
</span><span id=__span-0-285><a id=__codelineno-0-285 name=__codelineno-0-285></a>        <span class=n>ordered_forward_modules</span> <span class=o>=</span> <span class=n>cast</span><span class=p>(</span>
</span><span id=__span-0-286><a id=__codelineno-0-286 name=__codelineno-0-286></a>            <span class=nb>list</span><span class=p>[</span><span class=n>FSDPModule</span><span class=p>],</span>
</span><span id=__span-0-287><a id=__codelineno-0-287 name=__codelineno-0-287></a>            <span class=p>[</span>
</span><span id=__span-0-288><a id=__codelineno-0-288 name=__codelineno-0-288></a>                <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>get_module</span><span class=p>(</span><span class=n>fqn</span><span class=p>)</span>
</span><span id=__span-0-289><a id=__codelineno-0-289 name=__codelineno-0-289></a>                <span class=k>for</span> <span class=n>fqn</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>origin</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>stack</span>
</span><span id=__span-0-290><a id=__codelineno-0-290 name=__codelineno-0-290></a>                <span class=k>if</span> <span class=n>origin</span> <span class=o>==</span> <span class=s2>&quot;pre_forward_call&quot;</span>
</span><span id=__span-0-291><a id=__codelineno-0-291 name=__codelineno-0-291></a>            <span class=p>],</span>
</span><span id=__span-0-292><a id=__codelineno-0-292 name=__codelineno-0-292></a>        <span class=p>)</span>
</span><span id=__span-0-293><a id=__codelineno-0-293 name=__codelineno-0-293></a>        <span class=n>ordered_backwards_modules</span> <span class=o>=</span> <span class=n>cast</span><span class=p>(</span>
</span><span id=__span-0-294><a id=__codelineno-0-294 name=__codelineno-0-294></a>            <span class=nb>list</span><span class=p>[</span><span class=n>FSDPModule</span><span class=p>],</span>
</span><span id=__span-0-295><a id=__codelineno-0-295 name=__codelineno-0-295></a>            <span class=p>[</span>
</span><span id=__span-0-296><a id=__codelineno-0-296 name=__codelineno-0-296></a>                <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>get_module</span><span class=p>(</span><span class=n>fqn</span><span class=p>)</span>
</span><span id=__span-0-297><a id=__codelineno-0-297 name=__codelineno-0-297></a>                <span class=k>for</span> <span class=n>fqn</span><span class=p>,</span> <span class=n>requires_grad</span><span class=p>,</span> <span class=n>origin</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>stack</span><span class=p>[::</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-0-298><a id=__codelineno-0-298 name=__codelineno-0-298></a>                <span class=k>if</span> <span class=n>requires_grad</span> <span class=ow>and</span> <span class=n>origin</span> <span class=o>==</span> <span class=s2>&quot;pre_forward_call&quot;</span>
</span><span id=__span-0-299><a id=__codelineno-0-299 name=__codelineno-0-299></a>            <span class=p>],</span>
</span><span id=__span-0-300><a id=__codelineno-0-300 name=__codelineno-0-300></a>        <span class=p>)</span>
</span><span id=__span-0-301><a id=__codelineno-0-301 name=__codelineno-0-301></a>
</span><span id=__span-0-302><a id=__codelineno-0-302 name=__codelineno-0-302></a>        <span class=c1># Set up prefetching</span>
</span><span id=__span-0-303><a id=__codelineno-0-303 name=__codelineno-0-303></a>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>module</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>ordered_forward_modules</span><span class=p>):</span>
</span><span id=__span-0-304><a id=__codelineno-0-304 name=__codelineno-0-304></a>            <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-0-305><a id=__codelineno-0-305 name=__codelineno-0-305></a>                <span class=n>module</span><span class=o>.</span><span class=n>set_modules_to_forward_prefetch</span><span class=p>(</span>
</span><span id=__span-0-306><a id=__codelineno-0-306 name=__codelineno-0-306></a>                    <span class=n>ordered_forward_modules</span><span class=p>[</span><span class=mi>1</span> <span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span><span class=p>]</span>
</span><span id=__span-0-307><a id=__codelineno-0-307 name=__codelineno-0-307></a>                <span class=p>)</span>
</span><span id=__span-0-308><a id=__codelineno-0-308 name=__codelineno-0-308></a>            <span class=k>else</span><span class=p>:</span>
</span><span id=__span-0-309><a id=__codelineno-0-309 name=__codelineno-0-309></a>                <span class=n>module</span><span class=o>.</span><span class=n>set_modules_to_forward_prefetch</span><span class=p>(</span>
</span><span id=__span-0-310><a id=__codelineno-0-310 name=__codelineno-0-310></a>                    <span class=n>ordered_forward_modules</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span> <span class=p>:</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span><span class=p>]</span>
</span><span id=__span-0-311><a id=__codelineno-0-311 name=__codelineno-0-311></a>                <span class=p>)</span>
</span><span id=__span-0-312><a id=__codelineno-0-312 name=__codelineno-0-312></a>
</span><span id=__span-0-313><a id=__codelineno-0-313 name=__codelineno-0-313></a>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>module</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>ordered_backwards_modules</span><span class=p>):</span>
</span><span id=__span-0-314><a id=__codelineno-0-314 name=__codelineno-0-314></a>            <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-0-315><a id=__codelineno-0-315 name=__codelineno-0-315></a>                <span class=n>module</span><span class=o>.</span><span class=n>set_modules_to_backward_prefetch</span><span class=p>(</span>
</span><span id=__span-0-316><a id=__codelineno-0-316 name=__codelineno-0-316></a>                    <span class=n>ordered_backwards_modules</span><span class=p>[</span><span class=mi>1</span> <span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span><span class=p>]</span>
</span><span id=__span-0-317><a id=__codelineno-0-317 name=__codelineno-0-317></a>                <span class=p>)</span>
</span><span id=__span-0-318><a id=__codelineno-0-318 name=__codelineno-0-318></a>            <span class=k>else</span><span class=p>:</span>
</span><span id=__span-0-319><a id=__codelineno-0-319 name=__codelineno-0-319></a>                <span class=n>module</span><span class=o>.</span><span class=n>set_modules_to_backward_prefetch</span><span class=p>(</span>
</span><span id=__span-0-320><a id=__codelineno-0-320 name=__codelineno-0-320></a>                    <span class=n>ordered_backwards_modules</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span> <span class=p>:</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>prefetch</span><span class=p>]</span>
</span><span id=__span-0-321><a id=__codelineno-0-321 name=__codelineno-0-321></a>                <span class=p>)</span>
</span><span id=__span-0-322><a id=__codelineno-0-322 name=__codelineno-0-322></a>
</span><span id=__span-0-323><a id=__codelineno-0-323 name=__codelineno-0-323></a>        <span class=c1># Clear the stack for second training step</span>
</span><span id=__span-0-324><a id=__codelineno-0-324 name=__codelineno-0-324></a>        <span class=bp>self</span><span class=o>.</span><span class=n>stack</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span><span id=__span-0-325><a id=__codelineno-0-325 name=__codelineno-0-325></a>
</span><span id=__span-0-326><a id=__codelineno-0-326 name=__codelineno-0-326></a>        <span class=c1># Add hook to log prefetching</span>
</span><span id=__span-0-327><a id=__codelineno-0-327 name=__codelineno-0-327></a>        <span class=n>FSDPParamGroup</span><span class=o>.</span><span class=n>_prefetch_unshard</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>append_prefetch</span><span class=p>()</span>
</span><span id=__span-0-328><a id=__codelineno-0-328 name=__codelineno-0-328></a>
</span><span id=__span-0-329><a id=__codelineno-0-329 name=__codelineno-0-329></a>    <span class=c1># Log a tree inorder of forward calls and prefetching</span>
</span><span id=__span-0-330><a id=__codelineno-0-330 name=__codelineno-0-330></a>    <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>local_batches</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span><span id=__span-0-331><a id=__codelineno-0-331 name=__codelineno-0-331></a>        <span class=n>FSDPParamGroup</span><span class=o>.</span><span class=n>_prefetch_unshard</span> <span class=o>=</span> <span class=nb>staticmethod</span><span class=p>(</span><span class=n>_original_prefetch_unshard</span><span class=p>)</span>
</span><span id=__span-0-332><a id=__codelineno-0-332 name=__codelineno-0-332></a>
</span><span id=__span-0-333><a id=__codelineno-0-333 name=__codelineno-0-333></a>        <span class=k>for</span> <span class=n>hook</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>hooks</span><span class=p>:</span>
</span><span id=__span-0-334><a id=__codelineno-0-334 name=__codelineno-0-334></a>            <span class=n>hook</span><span class=o>.</span><span class=n>remove</span><span class=p>()</span>
</span><span id=__span-0-335><a id=__codelineno-0-335 name=__codelineno-0-335></a>
</span><span id=__span-0-336><a id=__codelineno-0-336 name=__codelineno-0-336></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>display</span><span class=p>:</span>
</span><span id=__span-0-337><a id=__codelineno-0-337 name=__codelineno-0-337></a>            <span class=n>_Node</span><span class=o>.</span><span class=n>from_stack</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>stack</span><span class=p>)</span><span class=o>.</span><span class=n>print</span><span class=p>()</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div><h3 id=usage_2>Usage<a class=headerlink href=#usage_2 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>OptimizeFSDP</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=c1># Basic FSDP optimization</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=n>fsdp_opt</span> <span class=o>=</span> <span class=n>OptimizeFSDP</span><span class=p>(</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=n>prefetch</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>  <span class=c1># Prefetch 1 module ahead</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=n>display</span><span class=o>=</span><span class=kc>False</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=p>)</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=c1># Aggressive prefetching</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=n>fsdp_opt</span> <span class=o>=</span> <span class=n>OptimizeFSDP</span><span class=p>(</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=n>prefetch</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>  <span class=c1># Prefetch 2 modules ahead</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>    <span class=n>display</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># Show execution order</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=p>)</span>
</span></code></pre></div> <h3 id=how-it-works>How It Works<a class=headerlink href=#how-it-works title="Permanent link">&para;</a></h3> <ol> <li><strong>Traces execution order</strong> during first training step</li> <li><strong>Sets up prefetching</strong> based on traced order</li> <li><strong>Optimizes overlap</strong> between computation and communication</li> </ol> <p>Benefits: - 10-20% speedup for large models - Better GPU utilization - Reduced communication overhead</p> <h2 id=faulttolerancecallback>FaultToleranceCallback<a class=headerlink href=#faulttolerancecallback title="Permanent link">&para;</a></h2> <p>Enable fault-tolerant training with torchft:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.FaultToleranceCallback class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">FaultToleranceCallback</span> <a href=#dream_trainer.callbacks.FaultToleranceCallback class=headerlink title="Permanent link">&para;</a></h2> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>FaultToleranceCallback</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>FaultToleranceParameters</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents first"> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/ft.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-23>23</a></span>
<span class=normal><a href=#__codelineno-0-24>24</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23></a><span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>FaultToleranceParameters</span><span class=p>):</span>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24></a>    <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> </div> </div> </div><h3 id=usage_3>Usage<a class=headerlink href=#usage_3 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>FaultToleranceCallback</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.configs</span><span class=w> </span><span class=kn>import</span> <span class=n>FaultToleranceParameters</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>ft_config</span> <span class=o>=</span> <span class=n>FaultToleranceParameters</span><span class=p>(</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>    <span class=n>checkpoint_interval</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>  <span class=c1># Checkpoint every 100 steps</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>    <span class=n>max_failures</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>          <span class=c1># Tolerate up to 3 failures</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>    <span class=n>heartbeat_interval</span><span class=o>=</span><span class=mi>60</span><span class=p>,</span>   <span class=c1># Check health every 60 seconds</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=p>)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=n>ft_callback</span> <span class=o>=</span> <span class=n>FaultToleranceCallback</span><span class=p>(</span><span class=n>ft_config</span><span class=p>)</span>
</span></code></pre></div> <h2 id=fp8quantization>Fp8Quantization<a class=headerlink href=#fp8quantization title="Permanent link">&para;</a></h2> <p>Enable FP8 training for memory and compute efficiency:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.Fp8Quantization class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">Fp8Quantization</span> <a href=#dream_trainer.callbacks.Fp8Quantization class=headerlink title="Permanent link">&para;</a></h2> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>Fp8Quantization</span><span class=p>(</span><span class=n>recipe</span><span class=p>:</span> <span class=nb>str</span> <span class=o>|</span> <span class=n>Float8LinearRecipeName</span> <span class=o>|</span> <span class=kc>None</span> <span class=o>=</span> <span class=kc>None</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents first"> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/fp8.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-35>35</a></span>
<span class=normal><a href=#__codelineno-0-36>36</a></span>
<span class=normal><a href=#__codelineno-0-37>37</a></span>
<span class=normal><a href=#__codelineno-0-38>38</a></span>
<span class=normal><a href=#__codelineno-0-39>39</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-35><a id=__codelineno-0-35 name=__codelineno-0-35></a><span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>recipe</span><span class=p>:</span> <span class=nb>str</span> <span class=o>|</span> <span class=n>Float8LinearRecipeName</span> <span class=o>|</span> <span class=kc>None</span> <span class=o>=</span> <span class=kc>None</span><span class=p>):</span>
</span><span id=__span-0-36><a id=__codelineno-0-36 name=__codelineno-0-36></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>is_sm89_or_later</span><span class=p>():</span>
</span><span id=__span-0-37><a id=__codelineno-0-37 name=__codelineno-0-37></a>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;Native fp8 is only supported on H100+ GPUs.&quot;</span><span class=p>)</span>
</span><span id=__span-0-38><a id=__codelineno-0-38 name=__codelineno-0-38></a>
</span><span id=__span-0-39><a id=__codelineno-0-39 name=__codelineno-0-39></a>    <span class=bp>self</span><span class=o>.</span><span class=n>recipe</span> <span class=o>=</span> <span class=n>Float8LinearRecipeName</span><span class=p>(</span><span class=n>recipe</span><span class=p>)</span> <span class=k>if</span> <span class=n>recipe</span> <span class=k>else</span> <span class=kc>None</span>
</span></code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <h3 id=dream_trainer.callbacks.Fp8Quantization-functions>Functions<a href=#dream_trainer.callbacks.Fp8Quantization-functions class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Fp8Quantization.post_optimizer_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_optimizer_step</span> <a href=#dream_trainer.callbacks.Fp8Quantization.post_optimizer_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_optimizer_step</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Calculate scale dynamically for all float8 parameters. This should be run after the optimizer step. It performs a single all-reduce to compute the scales for all float8 weights.</p> <p>This callback hook assume there is one optimizer per model.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/fp8.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-117>117</a></span>
<span class=normal><a href=#__codelineno-0-118>118</a></span>
<span class=normal><a href=#__codelineno-0-119>119</a></span>
<span class=normal><a href=#__codelineno-0-120>120</a></span>
<span class=normal><a href=#__codelineno-0-121>121</a></span>
<span class=normal><a href=#__codelineno-0-122>122</a></span>
<span class=normal><a href=#__codelineno-0-123>123</a></span>
<span class=normal><a href=#__codelineno-0-124>124</a></span>
<span class=normal><a href=#__codelineno-0-125>125</a></span>
<span class=normal><a href=#__codelineno-0-126>126</a></span>
<span class=normal><a href=#__codelineno-0-127>127</a></span>
<span class=normal><a href=#__codelineno-0-128>128</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-117><a id=__codelineno-0-117 name=__codelineno-0-117></a><span class=nd>@override</span>
</span><span id=__span-0-118><a id=__codelineno-0-118 name=__codelineno-0-118></a><span class=k>def</span><span class=w> </span><span class=nf>post_optimizer_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-0-119><a id=__codelineno-0-119 name=__codelineno-0-119></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-120><a id=__codelineno-0-120 name=__codelineno-0-120></a><span class=sd>    Calculate scale dynamically for all float8 parameters.</span>
</span><span id=__span-0-121><a id=__codelineno-0-121 name=__codelineno-0-121></a><span class=sd>    This should be run after the optimizer step. It performs a single all-reduce to compute the</span>
</span><span id=__span-0-122><a id=__codelineno-0-122 name=__codelineno-0-122></a><span class=sd>    scales for all float8 weights.</span>
</span><span id=__span-0-123><a id=__codelineno-0-123 name=__codelineno-0-123></a>
</span><span id=__span-0-124><a id=__codelineno-0-124 name=__codelineno-0-124></a><span class=sd>    This callback hook assume there is one optimizer per model.</span>
</span><span id=__span-0-125><a id=__codelineno-0-125 name=__codelineno-0-125></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-126><a id=__codelineno-0-126 name=__codelineno-0-126></a>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>FSDPModule</span><span class=p>):</span>
</span><span id=__span-0-127><a id=__codelineno-0-127 name=__codelineno-0-127></a>        <span class=c1># TODO: This could be done direclty on the optimizer param groups</span>
</span><span id=__span-0-128><a id=__codelineno-0-128 name=__codelineno-0-128></a>        <span class=n>precompute_float8_dynamic_scale_for_fsdp</span><span class=p>(</span><span class=n>cast</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>model</span><span class=p>))</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div><h3 id=usage_4>Usage<a class=headerlink href=#usage_4 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>Fp8Quantization</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># Enable FP8 training</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>fp8</span> <span class=o>=</span> <span class=n>Fp8Quantization</span><span class=p>(</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=n>enabled</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=n>amax_history_len</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>  <span class=c1># History for scaling factors</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=n>amax_compute_algo</span><span class=o>=</span><span class=s2>&quot;most_recent&quot;</span>  <span class=c1># or &quot;max&quot;</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a><span class=p>)</span>
</span></code></pre></div> <h2 id=creating-custom-performance-callbacks>Creating Custom Performance Callbacks<a class=headerlink href=#creating-custom-performance-callbacks title="Permanent link">&para;</a></h2> <h3 id=throughput-monitor>Throughput Monitor<a class=headerlink href=#throughput-monitor title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=k>class</span><span class=w> </span><span class=nc>ThroughputMonitor</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Monitor training throughput.&quot;&quot;&quot;</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>warmup_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10</span><span class=p>):</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span> <span class=o>=</span> <span class=n>warmup_steps</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>start_time</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>samples_processed</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>        <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span><span class=p>:</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>            <span class=bp>self</span><span class=o>.</span><span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>            <span class=bp>self</span><span class=o>.</span><span class=n>samples_processed</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>        <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>start_time</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>            <span class=n>batch_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>batch_size</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a>            <span class=bp>self</span><span class=o>.</span><span class=n>samples_processed</span> <span class=o>+=</span> <span class=n>batch_size</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a>            <span class=c1># Log every 100 steps</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>            <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>                <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>start_time</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>                <span class=n>throughput</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>samples_processed</span> <span class=o>/</span> <span class=n>elapsed</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Throughput: </span><span class=si>{</span><span class=n>throughput</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> samples/sec&quot;</span><span class=p>)</span>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a>                <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=p>,</span> <span class=s2>&quot;log_scalar&quot;</span><span class=p>):</span>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a>                    <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>log_scalar</span><span class=p>(</span><span class=s2>&quot;perf/throughput&quot;</span><span class=p>,</span> <span class=n>throughput</span><span class=p>)</span>
</span></code></pre></div> <h3 id=compilation-monitor>Compilation Monitor<a class=headerlink href=#compilation-monitor title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=k>class</span><span class=w> </span><span class=nc>CompilationMonitor</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Monitor torch.compile performance.&quot;&quot;&quot;</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>compile_times</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>graph_breaks</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>        <span class=c1># Hook into torch.compile</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>        <span class=n>original_compile</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>compile</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>        <span class=k>def</span><span class=w> </span><span class=nf>monitored_compile</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>            <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>            <span class=n>compiled</span> <span class=o>=</span> <span class=n>original_compile</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>            <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>            <span class=n>model_name</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>            <span class=bp>self</span><span class=o>.</span><span class=n>compile_times</span><span class=p>[</span><span class=n>model_name</span><span class=p>]</span> <span class=o>=</span> <span class=n>elapsed</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Compiled </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> in </span><span class=si>{</span><span class=n>elapsed</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>            <span class=k>return</span> <span class=n>compiled</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>        <span class=n>torch</span><span class=o>.</span><span class=n>compile</span> <span class=o>=</span> <span class=n>monitored_compile</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>        <span class=c1># Report compilation summary</span>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a>        <span class=n>total_time</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>compile_times</span><span class=o>.</span><span class=n>values</span><span class=p>())</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Compilation Summary:&quot;</span><span class=p>)</span>
</span><span id=__span-8-29><a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total time: </span><span class=si>{</span><span class=n>total_time</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span><span id=__span-8-30><a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a>
</span><span id=__span-8-31><a id=__codelineno-8-31 name=__codelineno-8-31 href=#__codelineno-8-31></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>time</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>compile_times</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-8-32><a id=__codelineno-8-32 name=__codelineno-8-32 href=#__codelineno-8-32></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;- </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>time</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=memory-profiler>Memory Profiler<a class=headerlink href=#memory-profiler title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=k>class</span><span class=w> </span><span class=nc>MemoryProfiler</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Profile memory usage patterns.&quot;&quot;&quot;</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>profile_every</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>100</span><span class=p>):</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>profile_every</span> <span class=o>=</span> <span class=n>profile_every</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>memory_stats</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>        <span class=k>if</span> <span class=n>batch_idx</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>profile_every</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>            <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>                <span class=c1># Get memory stats</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>                <span class=n>allocated</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>memory_allocated</span><span class=p>()</span> <span class=o>/</span> <span class=mi>1024</span><span class=o>**</span><span class=mi>3</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>                <span class=n>reserved</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>memory_reserved</span><span class=p>()</span> <span class=o>/</span> <span class=mi>1024</span><span class=o>**</span><span class=mi>3</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a>                <span class=c1># Get peak stats</span>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a>                <span class=n>peak_allocated</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>max_memory_allocated</span><span class=p>()</span> <span class=o>/</span> <span class=mi>1024</span><span class=o>**</span><span class=mi>3</span>
</span><span id=__span-9-17><a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a>                <span class=n>peak_reserved</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>max_memory_reserved</span><span class=p>()</span> <span class=o>/</span> <span class=mi>1024</span><span class=o>**</span><span class=mi>3</span>
</span><span id=__span-9-18><a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a>
</span><span id=__span-9-19><a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a>                <span class=n>stats</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-9-20><a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a>                    <span class=s2>&quot;step&quot;</span><span class=p>:</span> <span class=n>batch_idx</span><span class=p>,</span>
</span><span id=__span-9-21><a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a>                    <span class=s2>&quot;allocated_gb&quot;</span><span class=p>:</span> <span class=n>allocated</span><span class=p>,</span>
</span><span id=__span-9-22><a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a>                    <span class=s2>&quot;reserved_gb&quot;</span><span class=p>:</span> <span class=n>reserved</span><span class=p>,</span>
</span><span id=__span-9-23><a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a>                    <span class=s2>&quot;peak_allocated_gb&quot;</span><span class=p>:</span> <span class=n>peak_allocated</span><span class=p>,</span>
</span><span id=__span-9-24><a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a>                    <span class=s2>&quot;peak_reserved_gb&quot;</span><span class=p>:</span> <span class=n>peak_reserved</span><span class=p>,</span>
</span><span id=__span-9-25><a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a>                    <span class=s2>&quot;fragmentation&quot;</span><span class=p>:</span> <span class=p>(</span><span class=n>reserved</span> <span class=o>-</span> <span class=n>allocated</span><span class=p>)</span> <span class=o>/</span> <span class=n>reserved</span>
</span><span id=__span-9-26><a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a>                <span class=p>}</span>
</span><span id=__span-9-27><a id=__codelineno-9-27 name=__codelineno-9-27 href=#__codelineno-9-27></a>
</span><span id=__span-9-28><a id=__codelineno-9-28 name=__codelineno-9-28 href=#__codelineno-9-28></a>                <span class=bp>self</span><span class=o>.</span><span class=n>memory_stats</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>stats</span><span class=p>)</span>
</span><span id=__span-9-29><a id=__codelineno-9-29 name=__codelineno-9-29 href=#__codelineno-9-29></a>
</span><span id=__span-9-30><a id=__codelineno-9-30 name=__codelineno-9-30 href=#__codelineno-9-30></a>                <span class=c1># Log if fragmentation is high</span>
</span><span id=__span-9-31><a id=__codelineno-9-31 name=__codelineno-9-31 href=#__codelineno-9-31></a>                <span class=k>if</span> <span class=n>stats</span><span class=p>[</span><span class=s2>&quot;fragmentation&quot;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mf>0.3</span><span class=p>:</span>
</span><span id=__span-9-32><a id=__codelineno-9-32 name=__codelineno-9-32 href=#__codelineno-9-32></a>                    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;⚠️ High memory fragmentation: </span><span class=si>{</span><span class=n>stats</span><span class=p>[</span><span class=s1>&#39;fragmentation&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-9-33><a id=__codelineno-9-33 name=__codelineno-9-33 href=#__codelineno-9-33></a>
</span><span id=__span-9-34><a id=__codelineno-9-34 name=__codelineno-9-34 href=#__codelineno-9-34></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-9-35><a id=__codelineno-9-35 name=__codelineno-9-35 href=#__codelineno-9-35></a>        <span class=c1># Save detailed report</span>
</span><span id=__span-9-36><a id=__codelineno-9-36 name=__codelineno-9-36 href=#__codelineno-9-36></a>        <span class=kn>import</span><span class=w> </span><span class=nn>json</span>
</span><span id=__span-9-37><a id=__codelineno-9-37 name=__codelineno-9-37 href=#__codelineno-9-37></a>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&quot;memory_profile.json&quot;</span><span class=p>,</span> <span class=s2>&quot;w&quot;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-9-38><a id=__codelineno-9-38 name=__codelineno-9-38 href=#__codelineno-9-38></a>            <span class=n>json</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>memory_stats</span><span class=p>,</span> <span class=n>f</span><span class=p>,</span> <span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></code></pre></div> <h2 id=performance-optimization-strategies>Performance Optimization Strategies<a class=headerlink href=#performance-optimization-strategies title="Permanent link">&para;</a></h2> <h3 id=1-profiling-strategy>1. Profiling Strategy<a class=headerlink href=#1-profiling-strategy title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Profile different phases</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>callbacks</span> <span class=o>=</span> <span class=n>CallbackCollection</span><span class=p>([</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=c1># Warmup without profiling</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=n>WarmupCallback</span><span class=p>(</span><span class=n>steps</span><span class=o>=</span><span class=mi>100</span><span class=p>),</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=c1># Profile training</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=n>ProfileCallback</span><span class=p>(</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>        <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>profile</span><span class=p>(</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>            <span class=n>activities</span><span class=o>=</span><span class=p>[</span><span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CUDA</span><span class=p>],</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>            <span class=n>schedule</span><span class=o>=</span><span class=n>schedule</span><span class=p>(</span><span class=n>wait</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>warmup</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>active</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>        <span class=p>)</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=p>),</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    <span class=c1># Monitor throughput</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>    <span class=n>ThroughputMonitor</span><span class=p>(</span><span class=n>warmup_steps</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a><span class=p>])</span>
</span></code></pre></div> <h3 id=2-fsdp-optimization>2. FSDP Optimization<a class=headerlink href=#2-fsdp-optimization title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># Combine FSDP optimizations</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=n>callbacks</span> <span class=o>=</span> <span class=n>CallbackCollection</span><span class=p>([</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=c1># Optimize prefetching</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>    <span class=n>OptimizeFSDP</span><span class=p>(</span><span class=n>prefetch</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=c1># Monitor memory</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>    <span class=n>MemoryProfiler</span><span class=p>(</span><span class=n>profile_every</span><span class=o>=</span><span class=mi>50</span><span class=p>),</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=c1># Track throughput</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>    <span class=n>ThroughputMonitor</span><span class=p>()</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a><span class=p>])</span>
</span></code></pre></div> <h3 id=3-debugging-compilation>3. Debugging Compilation<a class=headerlink href=#3-debugging-compilation title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Debug torch.compile issues</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=n>callbacks</span> <span class=o>=</span> <span class=n>CallbackCollection</span><span class=p>([</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=c1># Find graph breaks</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=n>FindGraphBreaksCallback</span><span class=p>(</span><span class=s2>&quot;breaks.log&quot;</span><span class=p>),</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>    <span class=c1># Monitor compilation</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>    <span class=n>CompilationMonitor</span><span class=p>(),</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a>    <span class=c1># Profile compiled vs eager</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>    <span class=n>ProfileCallback</span><span class=p>(</span><span class=n>profiler</span><span class=p>)</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a><span class=p>])</span>
</span></code></pre></div> <h2 id=analyzing-performance>Analyzing Performance<a class=headerlink href=#analyzing-performance title="Permanent link">&para;</a></h2> <h3 id=using-tensorboard>Using TensorBoard<a class=headerlink href=#using-tensorboard title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># Launch TensorBoard</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=c1># tensorboard --logdir=./logs</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=c1># View:</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=c1># - GPU utilization</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=c1># - Kernel timings</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=c1># - Memory usage</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=c1># - Operator breakdown</span>
</span></code></pre></div> <h3 id=creating-reports>Creating Reports<a class=headerlink href=#creating-reports title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=k>class</span><span class=w> </span><span class=nc>PerformanceReporter</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Generate performance reports.&quot;&quot;&quot;</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>            <span class=s2>&quot;throughput&quot;</span><span class=p>:</span> <span class=p>[],</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>            <span class=s2>&quot;gpu_util&quot;</span><span class=p>:</span> <span class=p>[],</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>            <span class=s2>&quot;memory&quot;</span><span class=p>:</span> <span class=p>[],</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>            <span class=s2>&quot;compile_time&quot;</span><span class=p>:</span> <span class=mi>0</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a>        <span class=p>}</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a>        <span class=c1># Generate report</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a>        <span class=n>report</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a><span class=s2>Performance Report</span>
</span><span id=__span-14-16><a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a><span class=s2>==================</span>
</span><span id=__span-14-17><a id=__codelineno-14-17 name=__codelineno-14-17 href=#__codelineno-14-17></a>
</span><span id=__span-14-18><a id=__codelineno-14-18 name=__codelineno-14-18 href=#__codelineno-14-18></a><span class=s2>Training Summary:</span>
</span><span id=__span-14-19><a id=__codelineno-14-19 name=__codelineno-14-19 href=#__codelineno-14-19></a><span class=s2>- Total time: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>total_time</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s</span>
</span><span id=__span-14-20><a id=__codelineno-14-20 name=__codelineno-14-20 href=#__codelineno-14-20></a><span class=s2>- Average throughput: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>])</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> samples/s</span>
</span><span id=__span-14-21><a id=__codelineno-14-21 name=__codelineno-14-21 href=#__codelineno-14-21></a><span class=s2>- Peak memory: </span><span class=si>{</span><span class=nb>max</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;memory&#39;</span><span class=p>])</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> GB</span>
</span><span id=__span-14-22><a id=__codelineno-14-22 name=__codelineno-14-22 href=#__codelineno-14-22></a><span class=s2>- Compilation time: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;compile_time&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s</span>
</span><span id=__span-14-23><a id=__codelineno-14-23 name=__codelineno-14-23 href=#__codelineno-14-23></a>
</span><span id=__span-14-24><a id=__codelineno-14-24 name=__codelineno-14-24 href=#__codelineno-14-24></a><span class=s2>GPU Utilization:</span>
</span><span id=__span-14-25><a id=__codelineno-14-25 name=__codelineno-14-25 href=#__codelineno-14-25></a><span class=s2>- Average: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;gpu_util&#39;</span><span class=p>])</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%</span>
</span><span id=__span-14-26><a id=__codelineno-14-26 name=__codelineno-14-26 href=#__codelineno-14-26></a><span class=s2>- Min: </span><span class=si>{</span><span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;gpu_util&#39;</span><span class=p>])</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%</span>
</span><span id=__span-14-27><a id=__codelineno-14-27 name=__codelineno-14-27 href=#__codelineno-14-27></a><span class=s2>- Max: </span><span class=si>{</span><span class=nb>max</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;gpu_util&#39;</span><span class=p>])</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%</span>
</span><span id=__span-14-28><a id=__codelineno-14-28 name=__codelineno-14-28 href=#__codelineno-14-28></a>
</span><span id=__span-14-29><a id=__codelineno-14-29 name=__codelineno-14-29 href=#__codelineno-14-29></a><span class=s2>Recommendations:</span>
</span><span id=__span-14-30><a id=__codelineno-14-30 name=__codelineno-14-30 href=#__codelineno-14-30></a><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>get_recommendations</span><span class=p>()</span><span class=si>}</span>
</span><span id=__span-14-31><a id=__codelineno-14-31 name=__codelineno-14-31 href=#__codelineno-14-31></a><span class=s2>&quot;&quot;&quot;</span>
</span><span id=__span-14-32><a id=__codelineno-14-32 name=__codelineno-14-32 href=#__codelineno-14-32></a>
</span><span id=__span-14-33><a id=__codelineno-14-33 name=__codelineno-14-33 href=#__codelineno-14-33></a>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&quot;performance_report.txt&quot;</span><span class=p>,</span> <span class=s2>&quot;w&quot;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-14-34><a id=__codelineno-14-34 name=__codelineno-14-34 href=#__codelineno-14-34></a>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>report</span><span class=p>)</span>
</span></code></pre></div> <h2 id=best-practices>Best Practices<a class=headerlink href=#best-practices title="Permanent link">&para;</a></h2> <h3 id=1-profile-in-stages>1. Profile in Stages<a class=headerlink href=#1-profile-in-stages title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># Don&#39;t profile everything at once</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=c1># Stage 1: Data loading</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=c1># Stage 2: Forward pass</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=c1># Stage 3: Backward pass</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a><span class=c1># Stage 4: Optimizer step</span>
</span></code></pre></div> <h3 id=2-use-appropriate-tools>2. Use Appropriate Tools<a class=headerlink href=#2-use-appropriate-tools title="Permanent link">&para;</a></h3> <ul> <li><strong>CPU bottlenecks</strong>: cProfile, py-spy</li> <li><strong>GPU bottlenecks</strong>: nsight, PyTorch profiler</li> <li><strong>Memory issues</strong>: memory_profiler, tracemalloc</li> <li><strong>Compilation</strong>: torch._dynamo.explain</li> </ul> <h3 id=3-automate-analysis>3. Automate Analysis<a class=headerlink href=#3-automate-analysis title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=k>class</span><span class=w> </span><span class=nc>AutoAnalyzer</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Automatically identify bottlenecks.&quot;&quot;&quot;</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=k>def</span><span class=w> </span><span class=nf>analyze_profile</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>profile_data</span><span class=p>):</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>        <span class=c1># Find slow operations</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>        <span class=n>slow_ops</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>find_slow_operations</span><span class=p>(</span><span class=n>profile_data</span><span class=p>)</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>        <span class=c1># Detect patterns</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>is_communication_bound</span><span class=p>(</span><span class=n>profile_data</span><span class=p>):</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training is communication bound&quot;</span><span class=p>)</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Consider: larger batch size, gradient accumulation&quot;</span><span class=p>)</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>is_memory_bound</span><span class=p>(</span><span class=n>profile_data</span><span class=p>):</span>
</span><span id=__span-16-14><a id=__codelineno-16-14 name=__codelineno-16-14 href=#__codelineno-16-14></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training is memory bound&quot;</span><span class=p>)</span>
</span><span id=__span-16-15><a id=__codelineno-16-15 name=__codelineno-16-15 href=#__codelineno-16-15></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Consider: activation checkpointing, CPU offload&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=see-also>See Also<a class=headerlink href=#see-also title="Permanent link">&para;</a></h2> <ul> <li><a href=../base/ >Callback System</a> - Base callback documentation</li> <li><a href=../../performance.md>Optimization Guide</a> - Performance tuning</li> <li><a href=https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html>PyTorch Profiler</a></li> <li><a href=https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html>torch.compile Guide</a> </li> </ul> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../monitoring/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Monitoring Callbacks"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Monitoring Callbacks </div> </div> </a> <a href=../../configuration/parameters/ class="md-footer__link md-footer__link--next" aria-label="Next: Parameter Classes"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Parameter Classes </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dream3d/dream-trainer target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://discord.gg/dream-trainer target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> <a href=https://twitter.com/dream3d_ai target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.prune", "navigation.indexes", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.action.edit", "content.action.view", "content.tooltips", "toc.follow", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "stable", "provider": "mike"}}</script> <script src=../../../assets/javascripts/bundle.56ea9cef.min.js></script> <script src=../../../js/timeago.min.js></script> <script src=../../../js/timeago_mkdocs_material.js></script> <script src=../../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>