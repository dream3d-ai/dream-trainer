<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Composable distributed training framework built around PyTorch DTensor abstractions"><link href=https://dream3d.ai/trainer/api/callbacks/base/ rel=canonical><link href=../../mixins/quantize/ rel=prev><link href=../checkpoint/ rel=next><link rel=icon href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.15"><title>Callback Base - dream-trainer</title><link rel=stylesheet href=../../../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../../../css/timeago.css><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#callback-system class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title=dream-trainer class="md-header__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> dream-trainer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Callback Base </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../installation/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../../configuration/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../../tutorials/first-trainer.md class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../../examples/vision.md class=md-tabs__link> Examples </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../../contributing.md class=md-tabs__link> Community </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=dream-trainer class="md-nav__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> dream-trainer </label> <div class=md-nav__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../installation/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../configuration/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../tutorials/first-trainer.md class=md-nav__link> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../examples/vision.md class=md-nav__link> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> API Reference </span> </a> <label class="md-nav__link " for=__nav_6 id=__nav_6_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=true> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_2> <label class=md-nav__link for=__nav_6_2 id=__nav_6_2_label tabindex> <span class=md-ellipsis> Trainers </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> Trainers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../trainers/abstract/ class=md-nav__link> <span class=md-ellipsis> AbstractTrainer </span> </a> </li> <li class=md-nav__item> <a href=../../trainers/base/ class=md-nav__link> <span class=md-ellipsis> BaseTrainer </span> </a> </li> <li class=md-nav__item> <a href=../../trainers/dream/ class=md-nav__link> <span class=md-ellipsis> DreamTrainer </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_3> <label class=md-nav__link for=__nav_6_3 id=__nav_6_3_label tabindex> <span class=md-ellipsis> Mixins </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> Mixins </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../mixins/setup/ class=md-nav__link> <span class=md-ellipsis> Setup Mixins </span> </a> </li> <li class=md-nav__item> <a href=../../mixins/eval_metric/ class=md-nav__link> <span class=md-ellipsis> Evaluation Mixins </span> </a> </li> <li class=md-nav__item> <a href=../../mixins/loggers/ class=md-nav__link> <span class=md-ellipsis> Logger Mixins </span> </a> </li> <li class=md-nav__item> <a href=../../mixins/quantize/ class=md-nav__link> <span class=md-ellipsis> Quantization Mixins </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4 checked> <label class=md-nav__link for=__nav_6_4 id=__nav_6_4_label tabindex> <span class=md-ellipsis> Callbacks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_4_label aria-expanded=true> <label class=md-nav__title for=__nav_6_4> <span class="md-nav__icon md-icon"></span> Callbacks </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Callback Base </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Callback Base </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#overview class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=#base-classes class=md-nav__link> <span class=md-ellipsis> Base Classes </span> </a> <nav class=md-nav aria-label="Base Classes"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#callback class=md-nav__link> <span class=md-ellipsis> Callback </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;Callback </span> </a> <nav class=md-nav aria-label= Callback> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback-functions class=md-nav__link> <span class=md-ellipsis> Functions </span> </a> <nav class=md-nav aria-label=Functions> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_launch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_launch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_configure class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_configure </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_configure class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_configure </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_setup class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_setup </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_setup class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_setup </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_fit class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_fit </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_fit class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_fit </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_epoch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_epoch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_epoch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_epoch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_train_epoch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_train_epoch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_train_epoch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_train_epoch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_train_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_train_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_train_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_train_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_optimizer_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_optimizer_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_optimizer_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_optimizer_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_optimizer_zero_grad class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_optimizer_zero_grad </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_optimizer_zero_grad class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_optimizer_zero_grad </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_validation_epoch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_validation_epoch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_validation_epoch class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_validation_epoch </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.pre_validation_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pre_validation_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.post_validation_step class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;post_validation_step </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.train_context class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train_context </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.Callback.validation_context class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;validation_context </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rankzerocallback class=md-nav__link> <span class=md-ellipsis> RankZeroCallback </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.RankZeroCallback class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;RankZeroCallback </span> </a> <nav class=md-nav aria-label= RankZeroCallback> <ul class=md-nav__list> <li class=md-nav__item> <a href=#callbackcollection class=md-nav__link> <span class=md-ellipsis> CallbackCollection </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CallbackCollection </span> </a> <nav class=md-nav aria-label= CallbackCollection> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection-functions class=md-nav__link> <span class=md-ellipsis> Functions </span> </a> <nav class=md-nav aria-label=Functions> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection.initialize class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;initialize </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection.state_dict class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;state_dict </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection.load_state_dict class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_state_dict </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection.append class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;append </span> </a> </li> <li class=md-nav__item> <a href=#dream_trainer.callbacks.CallbackCollection.refresh class=md-nav__link> <span class=md-ellipsis> <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;refresh </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#creating-custom-callbacks class=md-nav__link> <span class=md-ellipsis> Creating Custom Callbacks </span> </a> <nav class=md-nav aria-label="Creating Custom Callbacks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-callback class=md-nav__link> <span class=md-ellipsis> Basic Callback </span> </a> </li> <li class=md-nav__item> <a href=#callback-with-dependencies class=md-nav__link> <span class=md-ellipsis> Callback with Dependencies </span> </a> </li> <li class=md-nav__item> <a href=#rank-zero-callback class=md-nav__link> <span class=md-ellipsis> Rank Zero Callback </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#lifecycle-hooks class=md-nav__link> <span class=md-ellipsis> Lifecycle Hooks </span> </a> <nav class=md-nav aria-label="Lifecycle Hooks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#initialization-phase class=md-nav__link> <span class=md-ellipsis> Initialization Phase </span> </a> </li> <li class=md-nav__item> <a href=#training-phase class=md-nav__link> <span class=md-ellipsis> Training Phase </span> </a> </li> <li class=md-nav__item> <a href=#optimizer-hooks class=md-nav__link> <span class=md-ellipsis> Optimizer Hooks </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#context-managers class=md-nav__link> <span class=md-ellipsis> Context Managers </span> </a> </li> <li class=md-nav__item> <a href=#state-management class=md-nav__link> <span class=md-ellipsis> State Management </span> </a> </li> <li class=md-nav__item> <a href=#using-callbacks class=md-nav__link> <span class=md-ellipsis> Using Callbacks </span> </a> <nav class=md-nav aria-label="Using Callbacks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#single-callback class=md-nav__link> <span class=md-ellipsis> Single Callback </span> </a> </li> <li class=md-nav__item> <a href=#multiple-callbacks class=md-nav__link> <span class=md-ellipsis> Multiple Callbacks </span> </a> </li> <li class=md-nav__item> <a href=#adding-callbacks-dynamically class=md-nav__link> <span class=md-ellipsis> Adding Callbacks Dynamically </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#built-in-callbacks class=md-nav__link> <span class=md-ellipsis> Built-in Callbacks </span> </a> </li> <li class=md-nav__item> <a href=#best-practices class=md-nav__link> <span class=md-ellipsis> Best Practices </span> </a> <nav class=md-nav aria-label="Best Practices"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-use-type-hints class=md-nav__link> <span class=md-ellipsis> 1. Use Type Hints </span> </a> </li> <li class=md-nav__item> <a href=#2-handle-distributed-training class=md-nav__link> <span class=md-ellipsis> 2. Handle Distributed Training </span> </a> </li> <li class=md-nav__item> <a href=#3-avoid-side-effects class=md-nav__link> <span class=md-ellipsis> 3. Avoid Side Effects </span> </a> </li> <li class=md-nav__item> <a href=#4-resource-management class=md-nav__link> <span class=md-ellipsis> 4. Resource Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#see-also class=md-nav__link> <span class=md-ellipsis> See Also </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../checkpoint/ class=md-nav__link> <span class=md-ellipsis> Checkpoint Callbacks </span> </a> </li> <li class=md-nav__item> <a href=../monitoring/ class=md-nav__link> <span class=md-ellipsis> Monitoring Callbacks </span> </a> </li> <li class=md-nav__item> <a href=../performance/ class=md-nav__link> <span class=md-ellipsis> Performance Callbacks </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_5> <label class=md-nav__link for=__nav_6_5 id=__nav_6_5_label tabindex> <span class=md-ellipsis> Configuration </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_5_label aria-expanded=false> <label class=md-nav__title for=__nav_6_5> <span class="md-nav__icon md-icon"></span> Configuration </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../configuration/parameters/ class=md-nav__link> <span class=md-ellipsis> Parameter Classes </span> </a> </li> <li class=md-nav__item> <a href=../../configuration/device/ class=md-nav__link> <span class=md-ellipsis> Device Config </span> </a> </li> <li class=md-nav__item> <a href=../../configuration/training/ class=md-nav__link> <span class=md-ellipsis> Training Config </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6_6> <label class=md-nav__link for=__nav_6_6 id=__nav_6_6_label tabindex> <span class=md-ellipsis> Utilities </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6_6> <span class="md-nav__icon md-icon"></span> Utilities </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../utilities/world/ class=md-nav__link> <span class=md-ellipsis> World Management </span> </a> </li> <li class=md-nav__item> <a href=../../utilities/data/ class=md-nav__link> <span class=md-ellipsis> Data Utilities </span> </a> </li> <li class=md-nav__item> <a href=../../utilities/common.md class=md-nav__link> <span class=md-ellipsis> Common Utilities </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../contributing.md class=md-nav__link> <span class=md-ellipsis> Community </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dream3d/dream-trainer/edit/main/dream-trainer/pages/docs/api/callbacks/base.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dream3d/dream-trainer/raw/main/dream-trainer/pages/docs/api/callbacks/base.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=callback-system>Callback System<a class=headerlink href=#callback-system title="Permanent link">&para;</a></h1> <p>The callback system in Dream Trainer provides a powerful way to extend and customize the training loop without modifying the core trainer code. Callbacks can hook into various points of the training lifecycle to add functionality like logging, checkpointing, profiling, and more.</p> <h2 id=overview>Overview<a class=headerlink href=#overview title="Permanent link">&para;</a></h2> <p>Callbacks provide: - Hooks at every stage of the training lifecycle - Type-safe dependency injection for trainer mixins - Automatic distributed training support - State management for resumable training - Context managers for training/validation steps</p> <h2 id=base-classes>Base Classes<a class=headerlink href=#base-classes title="Permanent link">&para;</a></h2> <h3 id=callback>Callback<a class=headerlink href=#callback title="Permanent link">&para;</a></h3> <p>The base callback class that all callbacks inherit from:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.Callback class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">Callback</span> <a href=#dream_trainer.callbacks.Callback class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents first"> <p>A base class for any hooks that need to be called during the training loop.</p> <p>When subclassing, instantiate the generic with the mixins you need.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <div class="doc doc-children"> <h3 id=dream_trainer.callbacks.Callback-functions>Functions<a href=#dream_trainer.callbacks.Callback-functions class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_launch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_launch</span> <a href=#dream_trainer.callbacks.Callback.pre_launch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_launch</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called before the launch of the distributed world.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-49>49</a></span>
<span class=normal><a href=#__codelineno-0-50>50</a></span>
<span class=normal><a href=#__codelineno-0-51>51</a></span>
<span class=normal><a href=#__codelineno-0-52>52</a></span>
<span class=normal><a href=#__codelineno-0-53>53</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-49><a id=__codelineno-0-49 name=__codelineno-0-49></a><span class=k>def</span><span class=w> </span><span class=nf>pre_launch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-50><a id=__codelineno-0-50 name=__codelineno-0-50></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-51><a id=__codelineno-0-51 name=__codelineno-0-51></a><span class=sd>    Called before the launch of the distributed world.</span>
</span><span id=__span-0-52><a id=__codelineno-0-52 name=__codelineno-0-52></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-53><a id=__codelineno-0-53 name=__codelineno-0-53></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_configure class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_configure</span> <a href=#dream_trainer.callbacks.Callback.pre_configure class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_configure</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called before the model, optimizers, schedulers and dataloaders are configured.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-55>55</a></span>
<span class=normal><a href=#__codelineno-0-56>56</a></span>
<span class=normal><a href=#__codelineno-0-57>57</a></span>
<span class=normal><a href=#__codelineno-0-58>58</a></span>
<span class=normal><a href=#__codelineno-0-59>59</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-55><a id=__codelineno-0-55 name=__codelineno-0-55></a><span class=k>def</span><span class=w> </span><span class=nf>pre_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-56><a id=__codelineno-0-56 name=__codelineno-0-56></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-57><a id=__codelineno-0-57 name=__codelineno-0-57></a><span class=sd>    Called before the model, optimizers, schedulers and dataloaders are configured.</span>
</span><span id=__span-0-58><a id=__codelineno-0-58 name=__codelineno-0-58></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-59><a id=__codelineno-0-59 name=__codelineno-0-59></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_configure class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_configure</span> <a href=#dream_trainer.callbacks.Callback.post_configure class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_configure</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called after the model, optimizers, schedulers and dataloaders are configured.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-61>61</a></span>
<span class=normal><a href=#__codelineno-0-62>62</a></span>
<span class=normal><a href=#__codelineno-0-63>63</a></span>
<span class=normal><a href=#__codelineno-0-64>64</a></span>
<span class=normal><a href=#__codelineno-0-65>65</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-61><a id=__codelineno-0-61 name=__codelineno-0-61></a><span class=k>def</span><span class=w> </span><span class=nf>post_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-62><a id=__codelineno-0-62 name=__codelineno-0-62></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-63><a id=__codelineno-0-63 name=__codelineno-0-63></a><span class=sd>    Called after the model, optimizers, schedulers and dataloaders are configured.</span>
</span><span id=__span-0-64><a id=__codelineno-0-64 name=__codelineno-0-64></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-65><a id=__codelineno-0-65 name=__codelineno-0-65></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_setup class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_setup</span> <a href=#dream_trainer.callbacks.Callback.pre_setup class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_setup</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called before the model, optimizers, schedulers and dataloaders are setup.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-67>67</a></span>
<span class=normal><a href=#__codelineno-0-68>68</a></span>
<span class=normal><a href=#__codelineno-0-69>69</a></span>
<span class=normal><a href=#__codelineno-0-70>70</a></span>
<span class=normal><a href=#__codelineno-0-71>71</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-67><a id=__codelineno-0-67 name=__codelineno-0-67></a><span class=k>def</span><span class=w> </span><span class=nf>pre_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-68><a id=__codelineno-0-68 name=__codelineno-0-68></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-69><a id=__codelineno-0-69 name=__codelineno-0-69></a><span class=sd>    Called before the model, optimizers, schedulers and dataloaders are setup.</span>
</span><span id=__span-0-70><a id=__codelineno-0-70 name=__codelineno-0-70></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-71><a id=__codelineno-0-71 name=__codelineno-0-71></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_setup class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_setup</span> <a href=#dream_trainer.callbacks.Callback.post_setup class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_setup</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called after the model, optimizers, schedulers and dataloaders are setup.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-73>73</a></span>
<span class=normal><a href=#__codelineno-0-74>74</a></span>
<span class=normal><a href=#__codelineno-0-75>75</a></span>
<span class=normal><a href=#__codelineno-0-76>76</a></span>
<span class=normal><a href=#__codelineno-0-77>77</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-73><a id=__codelineno-0-73 name=__codelineno-0-73></a><span class=k>def</span><span class=w> </span><span class=nf>post_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-74><a id=__codelineno-0-74 name=__codelineno-0-74></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-75><a id=__codelineno-0-75 name=__codelineno-0-75></a><span class=sd>    Called after the model, optimizers, schedulers and dataloaders are setup.</span>
</span><span id=__span-0-76><a id=__codelineno-0-76 name=__codelineno-0-76></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-77><a id=__codelineno-0-77 name=__codelineno-0-77></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_fit class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_fit</span> <a href=#dream_trainer.callbacks.Callback.pre_fit class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_fit</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called when the fit process starts.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-79>79</a></span>
<span class=normal><a href=#__codelineno-0-80>80</a></span>
<span class=normal><a href=#__codelineno-0-81>81</a></span>
<span class=normal><a href=#__codelineno-0-82>82</a></span>
<span class=normal><a href=#__codelineno-0-83>83</a></span>
<span class=normal><a href=#__codelineno-0-84>84</a></span>
<span class=normal><a href=#__codelineno-0-85>85</a></span>
<span class=normal><a href=#__codelineno-0-86>86</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-79><a id=__codelineno-0-79 name=__codelineno-0-79></a><span class=k>def</span><span class=w> </span><span class=nf>pre_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-80><a id=__codelineno-0-80 name=__codelineno-0-80></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-81><a id=__codelineno-0-81 name=__codelineno-0-81></a><span class=sd>    Called when the fit process starts.</span>
</span><span id=__span-0-82><a id=__codelineno-0-82 name=__codelineno-0-82></a>
</span><span id=__span-0-83><a id=__codelineno-0-83 name=__codelineno-0-83></a><span class=sd>    Args:</span>
</span><span id=__span-0-84><a id=__codelineno-0-84 name=__codelineno-0-84></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-85><a id=__codelineno-0-85 name=__codelineno-0-85></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-86><a id=__codelineno-0-86 name=__codelineno-0-86></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_fit class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_fit</span> <a href=#dream_trainer.callbacks.Callback.post_fit class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_fit</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called when the fit process ends.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-88>88</a></span>
<span class=normal><a href=#__codelineno-0-89>89</a></span>
<span class=normal><a href=#__codelineno-0-90>90</a></span>
<span class=normal><a href=#__codelineno-0-91>91</a></span>
<span class=normal><a href=#__codelineno-0-92>92</a></span>
<span class=normal><a href=#__codelineno-0-93>93</a></span>
<span class=normal><a href=#__codelineno-0-94>94</a></span>
<span class=normal><a href=#__codelineno-0-95>95</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-88><a id=__codelineno-0-88 name=__codelineno-0-88></a><span class=k>def</span><span class=w> </span><span class=nf>post_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-89><a id=__codelineno-0-89 name=__codelineno-0-89></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-90><a id=__codelineno-0-90 name=__codelineno-0-90></a><span class=sd>    Called when the fit process ends.</span>
</span><span id=__span-0-91><a id=__codelineno-0-91 name=__codelineno-0-91></a>
</span><span id=__span-0-92><a id=__codelineno-0-92 name=__codelineno-0-92></a><span class=sd>    Args:</span>
</span><span id=__span-0-93><a id=__codelineno-0-93 name=__codelineno-0-93></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-94><a id=__codelineno-0-94 name=__codelineno-0-94></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-95><a id=__codelineno-0-95 name=__codelineno-0-95></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_epoch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_epoch</span> <a href=#dream_trainer.callbacks.Callback.pre_epoch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_epoch</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the beginning of each epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-97> 97</a></span>
<span class=normal><a href=#__codelineno-0-98> 98</a></span>
<span class=normal><a href=#__codelineno-0-99> 99</a></span>
<span class=normal><a href=#__codelineno-0-100>100</a></span>
<span class=normal><a href=#__codelineno-0-101>101</a></span>
<span class=normal><a href=#__codelineno-0-102>102</a></span>
<span class=normal><a href=#__codelineno-0-103>103</a></span>
<span class=normal><a href=#__codelineno-0-104>104</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-97><a id=__codelineno-0-97 name=__codelineno-0-97></a><span class=k>def</span><span class=w> </span><span class=nf>pre_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-98><a id=__codelineno-0-98 name=__codelineno-0-98></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-99><a id=__codelineno-0-99 name=__codelineno-0-99></a><span class=sd>    Called at the beginning of each epoch.</span>
</span><span id=__span-0-100><a id=__codelineno-0-100 name=__codelineno-0-100></a>
</span><span id=__span-0-101><a id=__codelineno-0-101 name=__codelineno-0-101></a><span class=sd>    Args:</span>
</span><span id=__span-0-102><a id=__codelineno-0-102 name=__codelineno-0-102></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-103><a id=__codelineno-0-103 name=__codelineno-0-103></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-104><a id=__codelineno-0-104 name=__codelineno-0-104></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_epoch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_epoch</span> <a href=#dream_trainer.callbacks.Callback.post_epoch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_epoch</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-106>106</a></span>
<span class=normal><a href=#__codelineno-0-107>107</a></span>
<span class=normal><a href=#__codelineno-0-108>108</a></span>
<span class=normal><a href=#__codelineno-0-109>109</a></span>
<span class=normal><a href=#__codelineno-0-110>110</a></span>
<span class=normal><a href=#__codelineno-0-111>111</a></span>
<span class=normal><a href=#__codelineno-0-112>112</a></span>
<span class=normal><a href=#__codelineno-0-113>113</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-106><a id=__codelineno-0-106 name=__codelineno-0-106></a><span class=k>def</span><span class=w> </span><span class=nf>post_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-107><a id=__codelineno-0-107 name=__codelineno-0-107></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-108><a id=__codelineno-0-108 name=__codelineno-0-108></a><span class=sd>    Called at the end of each epoch.</span>
</span><span id=__span-0-109><a id=__codelineno-0-109 name=__codelineno-0-109></a>
</span><span id=__span-0-110><a id=__codelineno-0-110 name=__codelineno-0-110></a><span class=sd>    Args:</span>
</span><span id=__span-0-111><a id=__codelineno-0-111 name=__codelineno-0-111></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-112><a id=__codelineno-0-112 name=__codelineno-0-112></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-113><a id=__codelineno-0-113 name=__codelineno-0-113></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_train_epoch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_train_epoch</span> <a href=#dream_trainer.callbacks.Callback.pre_train_epoch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_train_epoch</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the beginning of each training epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-115>115</a></span>
<span class=normal><a href=#__codelineno-0-116>116</a></span>
<span class=normal><a href=#__codelineno-0-117>117</a></span>
<span class=normal><a href=#__codelineno-0-118>118</a></span>
<span class=normal><a href=#__codelineno-0-119>119</a></span>
<span class=normal><a href=#__codelineno-0-120>120</a></span>
<span class=normal><a href=#__codelineno-0-121>121</a></span>
<span class=normal><a href=#__codelineno-0-122>122</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-115><a id=__codelineno-0-115 name=__codelineno-0-115></a><span class=k>def</span><span class=w> </span><span class=nf>pre_train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-116><a id=__codelineno-0-116 name=__codelineno-0-116></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-117><a id=__codelineno-0-117 name=__codelineno-0-117></a><span class=sd>    Called at the beginning of each training epoch.</span>
</span><span id=__span-0-118><a id=__codelineno-0-118 name=__codelineno-0-118></a>
</span><span id=__span-0-119><a id=__codelineno-0-119 name=__codelineno-0-119></a><span class=sd>    Args:</span>
</span><span id=__span-0-120><a id=__codelineno-0-120 name=__codelineno-0-120></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-121><a id=__codelineno-0-121 name=__codelineno-0-121></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-122><a id=__codelineno-0-122 name=__codelineno-0-122></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_train_epoch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_train_epoch</span> <a href=#dream_trainer.callbacks.Callback.post_train_epoch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_train_epoch</span><span class=p>(</span><span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each training epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>result</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The result of the training epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=dict>dict</span>[<span title=str>str</span>, <span title=typing.Any>Any</span>]</code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-124>124</a></span>
<span class=normal><a href=#__codelineno-0-125>125</a></span>
<span class=normal><a href=#__codelineno-0-126>126</a></span>
<span class=normal><a href=#__codelineno-0-127>127</a></span>
<span class=normal><a href=#__codelineno-0-128>128</a></span>
<span class=normal><a href=#__codelineno-0-129>129</a></span>
<span class=normal><a href=#__codelineno-0-130>130</a></span>
<span class=normal><a href=#__codelineno-0-131>131</a></span>
<span class=normal><a href=#__codelineno-0-132>132</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-124><a id=__codelineno-0-124 name=__codelineno-0-124></a><span class=k>def</span><span class=w> </span><span class=nf>post_train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]):</span>
</span><span id=__span-0-125><a id=__codelineno-0-125 name=__codelineno-0-125></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-126><a id=__codelineno-0-126 name=__codelineno-0-126></a><span class=sd>    Called at the end of each training epoch.</span>
</span><span id=__span-0-127><a id=__codelineno-0-127 name=__codelineno-0-127></a>
</span><span id=__span-0-128><a id=__codelineno-0-128 name=__codelineno-0-128></a><span class=sd>    Args:</span>
</span><span id=__span-0-129><a id=__codelineno-0-129 name=__codelineno-0-129></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-130><a id=__codelineno-0-130 name=__codelineno-0-130></a><span class=sd>        result (dict[str, Any]): The result of the training epoch.</span>
</span><span id=__span-0-131><a id=__codelineno-0-131 name=__codelineno-0-131></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-132><a id=__codelineno-0-132 name=__codelineno-0-132></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_train_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_train_step</span> <a href=#dream_trainer.callbacks.Callback.pre_train_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_train_step</span><span class=p>(</span><span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the start of each training step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>batch</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The current batch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=dict>dict</span>[<span title=str>str</span>, <span title=typing.Any>Any</span>]</code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>batch_idx</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The index of the current batch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-134>134</a></span>
<span class=normal><a href=#__codelineno-0-135>135</a></span>
<span class=normal><a href=#__codelineno-0-136>136</a></span>
<span class=normal><a href=#__codelineno-0-137>137</a></span>
<span class=normal><a href=#__codelineno-0-138>138</a></span>
<span class=normal><a href=#__codelineno-0-139>139</a></span>
<span class=normal><a href=#__codelineno-0-140>140</a></span>
<span class=normal><a href=#__codelineno-0-141>141</a></span>
<span class=normal><a href=#__codelineno-0-142>142</a></span>
<span class=normal><a href=#__codelineno-0-143>143</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-134><a id=__codelineno-0-134 name=__codelineno-0-134></a><span class=k>def</span><span class=w> </span><span class=nf>pre_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-135><a id=__codelineno-0-135 name=__codelineno-0-135></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-136><a id=__codelineno-0-136 name=__codelineno-0-136></a><span class=sd>    Called at the start of each training step.</span>
</span><span id=__span-0-137><a id=__codelineno-0-137 name=__codelineno-0-137></a>
</span><span id=__span-0-138><a id=__codelineno-0-138 name=__codelineno-0-138></a><span class=sd>    Args:</span>
</span><span id=__span-0-139><a id=__codelineno-0-139 name=__codelineno-0-139></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-140><a id=__codelineno-0-140 name=__codelineno-0-140></a><span class=sd>        batch (dict[str, Any]): The current batch.</span>
</span><span id=__span-0-141><a id=__codelineno-0-141 name=__codelineno-0-141></a><span class=sd>        batch_idx (int): The index of the current batch.</span>
</span><span id=__span-0-142><a id=__codelineno-0-142 name=__codelineno-0-142></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-143><a id=__codelineno-0-143 name=__codelineno-0-143></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_train_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_train_step</span> <a href=#dream_trainer.callbacks.Callback.post_train_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_train_step</span><span class=p>(</span><span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each training step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>result</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The result of the training step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=typing.Any>Any</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>batch_idx</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The index of the current batch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-145>145</a></span>
<span class=normal><a href=#__codelineno-0-146>146</a></span>
<span class=normal><a href=#__codelineno-0-147>147</a></span>
<span class=normal><a href=#__codelineno-0-148>148</a></span>
<span class=normal><a href=#__codelineno-0-149>149</a></span>
<span class=normal><a href=#__codelineno-0-150>150</a></span>
<span class=normal><a href=#__codelineno-0-151>151</a></span>
<span class=normal><a href=#__codelineno-0-152>152</a></span>
<span class=normal><a href=#__codelineno-0-153>153</a></span>
<span class=normal><a href=#__codelineno-0-154>154</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-145><a id=__codelineno-0-145 name=__codelineno-0-145></a><span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-146><a id=__codelineno-0-146 name=__codelineno-0-146></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-147><a id=__codelineno-0-147 name=__codelineno-0-147></a><span class=sd>    Called at the end of each training step.</span>
</span><span id=__span-0-148><a id=__codelineno-0-148 name=__codelineno-0-148></a>
</span><span id=__span-0-149><a id=__codelineno-0-149 name=__codelineno-0-149></a><span class=sd>    Args:</span>
</span><span id=__span-0-150><a id=__codelineno-0-150 name=__codelineno-0-150></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-151><a id=__codelineno-0-151 name=__codelineno-0-151></a><span class=sd>        result (Any): The result of the training step.</span>
</span><span id=__span-0-152><a id=__codelineno-0-152 name=__codelineno-0-152></a><span class=sd>        batch_idx (int): The index of the current batch.</span>
</span><span id=__span-0-153><a id=__codelineno-0-153 name=__codelineno-0-153></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-154><a id=__codelineno-0-154 name=__codelineno-0-154></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_optimizer_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_optimizer_step</span> <a href=#dream_trainer.callbacks.Callback.pre_optimizer_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_optimizer_step</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the before each optimizer step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-156>156</a></span>
<span class=normal><a href=#__codelineno-0-157>157</a></span>
<span class=normal><a href=#__codelineno-0-158>158</a></span>
<span class=normal><a href=#__codelineno-0-159>159</a></span>
<span class=normal><a href=#__codelineno-0-160>160</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-156><a id=__codelineno-0-156 name=__codelineno-0-156></a><span class=k>def</span><span class=w> </span><span class=nf>pre_optimizer_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-0-157><a id=__codelineno-0-157 name=__codelineno-0-157></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-158><a id=__codelineno-0-158 name=__codelineno-0-158></a><span class=sd>    Called at the before each optimizer step.</span>
</span><span id=__span-0-159><a id=__codelineno-0-159 name=__codelineno-0-159></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-160><a id=__codelineno-0-160 name=__codelineno-0-160></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_optimizer_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_optimizer_step</span> <a href=#dream_trainer.callbacks.Callback.post_optimizer_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_optimizer_step</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each optimizer step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-162>162</a></span>
<span class=normal><a href=#__codelineno-0-163>163</a></span>
<span class=normal><a href=#__codelineno-0-164>164</a></span>
<span class=normal><a href=#__codelineno-0-165>165</a></span>
<span class=normal><a href=#__codelineno-0-166>166</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-162><a id=__codelineno-0-162 name=__codelineno-0-162></a><span class=k>def</span><span class=w> </span><span class=nf>post_optimizer_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-0-163><a id=__codelineno-0-163 name=__codelineno-0-163></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-164><a id=__codelineno-0-164 name=__codelineno-0-164></a><span class=sd>    Called at the end of each optimizer step.</span>
</span><span id=__span-0-165><a id=__codelineno-0-165 name=__codelineno-0-165></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-166><a id=__codelineno-0-166 name=__codelineno-0-166></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_optimizer_zero_grad class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_optimizer_zero_grad</span> <a href=#dream_trainer.callbacks.Callback.pre_optimizer_zero_grad class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_optimizer_zero_grad</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the before each optimizer zero grad.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-168>168</a></span>
<span class=normal><a href=#__codelineno-0-169>169</a></span>
<span class=normal><a href=#__codelineno-0-170>170</a></span>
<span class=normal><a href=#__codelineno-0-171>171</a></span>
<span class=normal><a href=#__codelineno-0-172>172</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-168><a id=__codelineno-0-168 name=__codelineno-0-168></a><span class=k>def</span><span class=w> </span><span class=nf>pre_optimizer_zero_grad</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-0-169><a id=__codelineno-0-169 name=__codelineno-0-169></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-170><a id=__codelineno-0-170 name=__codelineno-0-170></a><span class=sd>    Called at the before each optimizer zero grad.</span>
</span><span id=__span-0-171><a id=__codelineno-0-171 name=__codelineno-0-171></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-172><a id=__codelineno-0-172 name=__codelineno-0-172></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_optimizer_zero_grad class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_optimizer_zero_grad</span> <a href=#dream_trainer.callbacks.Callback.post_optimizer_zero_grad class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_optimizer_zero_grad</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each optimizer zero grad.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-174>174</a></span>
<span class=normal><a href=#__codelineno-0-175>175</a></span>
<span class=normal><a href=#__codelineno-0-176>176</a></span>
<span class=normal><a href=#__codelineno-0-177>177</a></span>
<span class=normal><a href=#__codelineno-0-178>178</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-174><a id=__codelineno-0-174 name=__codelineno-0-174></a><span class=k>def</span><span class=w> </span><span class=nf>post_optimizer_zero_grad</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-0-175><a id=__codelineno-0-175 name=__codelineno-0-175></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-176><a id=__codelineno-0-176 name=__codelineno-0-176></a><span class=sd>    Called at the end of each optimizer zero grad.</span>
</span><span id=__span-0-177><a id=__codelineno-0-177 name=__codelineno-0-177></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-178><a id=__codelineno-0-178 name=__codelineno-0-178></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_validation_epoch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_validation_epoch</span> <a href=#dream_trainer.callbacks.Callback.pre_validation_epoch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_validation_epoch</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the beginning of each validation epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-180>180</a></span>
<span class=normal><a href=#__codelineno-0-181>181</a></span>
<span class=normal><a href=#__codelineno-0-182>182</a></span>
<span class=normal><a href=#__codelineno-0-183>183</a></span>
<span class=normal><a href=#__codelineno-0-184>184</a></span>
<span class=normal><a href=#__codelineno-0-185>185</a></span>
<span class=normal><a href=#__codelineno-0-186>186</a></span>
<span class=normal><a href=#__codelineno-0-187>187</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-180><a id=__codelineno-0-180 name=__codelineno-0-180></a><span class=k>def</span><span class=w> </span><span class=nf>pre_validation_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-181><a id=__codelineno-0-181 name=__codelineno-0-181></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-182><a id=__codelineno-0-182 name=__codelineno-0-182></a><span class=sd>    Called at the beginning of each validation epoch.</span>
</span><span id=__span-0-183><a id=__codelineno-0-183 name=__codelineno-0-183></a>
</span><span id=__span-0-184><a id=__codelineno-0-184 name=__codelineno-0-184></a><span class=sd>    Args:</span>
</span><span id=__span-0-185><a id=__codelineno-0-185 name=__codelineno-0-185></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-186><a id=__codelineno-0-186 name=__codelineno-0-186></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-187><a id=__codelineno-0-187 name=__codelineno-0-187></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_validation_epoch class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_validation_epoch</span> <a href=#dream_trainer.callbacks.Callback.post_validation_epoch class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_validation_epoch</span><span class=p>(</span><span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each validation epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>result</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The result of the validation epoch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=typing.Any>Any</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-189>189</a></span>
<span class=normal><a href=#__codelineno-0-190>190</a></span>
<span class=normal><a href=#__codelineno-0-191>191</a></span>
<span class=normal><a href=#__codelineno-0-192>192</a></span>
<span class=normal><a href=#__codelineno-0-193>193</a></span>
<span class=normal><a href=#__codelineno-0-194>194</a></span>
<span class=normal><a href=#__codelineno-0-195>195</a></span>
<span class=normal><a href=#__codelineno-0-196>196</a></span>
<span class=normal><a href=#__codelineno-0-197>197</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-189><a id=__codelineno-0-189 name=__codelineno-0-189></a><span class=k>def</span><span class=w> </span><span class=nf>post_validation_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]):</span>
</span><span id=__span-0-190><a id=__codelineno-0-190 name=__codelineno-0-190></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-191><a id=__codelineno-0-191 name=__codelineno-0-191></a><span class=sd>    Called at the end of each validation epoch.</span>
</span><span id=__span-0-192><a id=__codelineno-0-192 name=__codelineno-0-192></a>
</span><span id=__span-0-193><a id=__codelineno-0-193 name=__codelineno-0-193></a><span class=sd>    Args:</span>
</span><span id=__span-0-194><a id=__codelineno-0-194 name=__codelineno-0-194></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-195><a id=__codelineno-0-195 name=__codelineno-0-195></a><span class=sd>        result (Any): The result of the validation epoch.</span>
</span><span id=__span-0-196><a id=__codelineno-0-196 name=__codelineno-0-196></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-197><a id=__codelineno-0-197 name=__codelineno-0-197></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.pre_validation_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_validation_step</span> <a href=#dream_trainer.callbacks.Callback.pre_validation_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>pre_validation_step</span><span class=p>(</span><span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the start of each validation step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>batch_idx</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The index of the current batch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-199>199</a></span>
<span class=normal><a href=#__codelineno-0-200>200</a></span>
<span class=normal><a href=#__codelineno-0-201>201</a></span>
<span class=normal><a href=#__codelineno-0-202>202</a></span>
<span class=normal><a href=#__codelineno-0-203>203</a></span>
<span class=normal><a href=#__codelineno-0-204>204</a></span>
<span class=normal><a href=#__codelineno-0-205>205</a></span>
<span class=normal><a href=#__codelineno-0-206>206</a></span>
<span class=normal><a href=#__codelineno-0-207>207</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-199><a id=__codelineno-0-199 name=__codelineno-0-199></a><span class=k>def</span><span class=w> </span><span class=nf>pre_validation_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-200><a id=__codelineno-0-200 name=__codelineno-0-200></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-201><a id=__codelineno-0-201 name=__codelineno-0-201></a><span class=sd>    Called at the start of each validation step.</span>
</span><span id=__span-0-202><a id=__codelineno-0-202 name=__codelineno-0-202></a>
</span><span id=__span-0-203><a id=__codelineno-0-203 name=__codelineno-0-203></a><span class=sd>    Args:</span>
</span><span id=__span-0-204><a id=__codelineno-0-204 name=__codelineno-0-204></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-205><a id=__codelineno-0-205 name=__codelineno-0-205></a><span class=sd>        batch_idx (int): The index of the current batch.</span>
</span><span id=__span-0-206><a id=__codelineno-0-206 name=__codelineno-0-206></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-207><a id=__codelineno-0-207 name=__codelineno-0-207></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.post_validation_step class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">post_validation_step</span> <a href=#dream_trainer.callbacks.Callback.post_validation_step class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>post_validation_step</span><span class=p>(</span><span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Called at the end of each validation step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <table> <thead> <tr> <th><span class=doc-section-title>PARAMETER</span></th> <th><span>DESCRIPTION</span></th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>trainer</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The trainer instance.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=FSDP2Trainer>FSDP2Trainer</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>result</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The result of the validation step.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=typing.Any>Any</span></code> </span> </p> </td> </tr> <tr class=doc-section-item> <td> <code>batch_idx</code> </td> <td class=doc-param-details> <div class=doc-md-description> <p>The index of the current batch.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> </div> <p> <span class=doc-param-annotation> <b>TYPE:</b> <code><span title=int>int</span></code> </span> </p> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-209>209</a></span>
<span class=normal><a href=#__codelineno-0-210>210</a></span>
<span class=normal><a href=#__codelineno-0-211>211</a></span>
<span class=normal><a href=#__codelineno-0-212>212</a></span>
<span class=normal><a href=#__codelineno-0-213>213</a></span>
<span class=normal><a href=#__codelineno-0-214>214</a></span>
<span class=normal><a href=#__codelineno-0-215>215</a></span>
<span class=normal><a href=#__codelineno-0-216>216</a></span>
<span class=normal><a href=#__codelineno-0-217>217</a></span>
<span class=normal><a href=#__codelineno-0-218>218</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-209><a id=__codelineno-0-209 name=__codelineno-0-209></a><span class=k>def</span><span class=w> </span><span class=nf>post_validation_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-210><a id=__codelineno-0-210 name=__codelineno-0-210></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-211><a id=__codelineno-0-211 name=__codelineno-0-211></a><span class=sd>    Called at the end of each validation step.</span>
</span><span id=__span-0-212><a id=__codelineno-0-212 name=__codelineno-0-212></a>
</span><span id=__span-0-213><a id=__codelineno-0-213 name=__codelineno-0-213></a><span class=sd>    Args:</span>
</span><span id=__span-0-214><a id=__codelineno-0-214 name=__codelineno-0-214></a><span class=sd>        trainer (FSDP2Trainer): The trainer instance.</span>
</span><span id=__span-0-215><a id=__codelineno-0-215 name=__codelineno-0-215></a><span class=sd>        result (Any): The result of the validation step.</span>
</span><span id=__span-0-216><a id=__codelineno-0-216 name=__codelineno-0-216></a><span class=sd>        batch_idx (int): The index of the current batch.</span>
</span><span id=__span-0-217><a id=__codelineno-0-217 name=__codelineno-0-217></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-218><a id=__codelineno-0-218 name=__codelineno-0-218></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.train_context class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">train_context</span> <a href=#dream_trainer.callbacks.Callback.train_context class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>train_context</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>contextlib</span><span class=o>.</span><span class=n>_GeneratorContextManager</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Training steps happen under this context manager.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-220>220</a></span>
<span class=normal><a href=#__codelineno-0-221>221</a></span>
<span class=normal><a href=#__codelineno-0-222>222</a></span>
<span class=normal><a href=#__codelineno-0-223>223</a></span>
<span class=normal><a href=#__codelineno-0-224>224</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-220><a id=__codelineno-0-220 name=__codelineno-0-220></a><span class=k>def</span><span class=w> </span><span class=nf>train_context</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>contextlib</span><span class=o>.</span><span class=n>_GeneratorContextManager</span><span class=p>:</span>
</span><span id=__span-0-221><a id=__codelineno-0-221 name=__codelineno-0-221></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-222><a id=__codelineno-0-222 name=__codelineno-0-222></a><span class=sd>    Training steps happen under this context manager.</span>
</span><span id=__span-0-223><a id=__codelineno-0-223 name=__codelineno-0-223></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-224><a id=__codelineno-0-224 name=__codelineno-0-224></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.Callback.validation_context class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">validation_context</span> <a href=#dream_trainer.callbacks.Callback.validation_context class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>validation_context</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>contextlib</span><span class=o>.</span><span class=n>_GeneratorContextManager</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Validation steps happen under this context manager.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-226>226</a></span>
<span class=normal><a href=#__codelineno-0-227>227</a></span>
<span class=normal><a href=#__codelineno-0-228>228</a></span>
<span class=normal><a href=#__codelineno-0-229>229</a></span>
<span class=normal><a href=#__codelineno-0-230>230</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-226><a id=__codelineno-0-226 name=__codelineno-0-226></a><span class=k>def</span><span class=w> </span><span class=nf>validation_context</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>contextlib</span><span class=o>.</span><span class=n>_GeneratorContextManager</span><span class=p>:</span>
</span><span id=__span-0-227><a id=__codelineno-0-227 name=__codelineno-0-227></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-228><a id=__codelineno-0-228 name=__codelineno-0-228></a><span class=sd>    Validation steps happen under this context manager.</span>
</span><span id=__span-0-229><a id=__codelineno-0-229 name=__codelineno-0-229></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-230><a id=__codelineno-0-230 name=__codelineno-0-230></a>    <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&quot;This function should never be called&quot;</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div><h3 id=rankzerocallback>RankZeroCallback<a class=headerlink href=#rankzerocallback title="Permanent link">&para;</a></h3> <p>A special callback that only executes on rank 0 in distributed training:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.RankZeroCallback class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">RankZeroCallback</span> <a href=#dream_trainer.callbacks.RankZeroCallback class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents first"> <p>Equivalent to the base Callback, but ensures all functions are only called on the rank zero process.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <div class="doc doc-children"> </div> </div> </div><h3 id=callbackcollection>CallbackCollection<a class=headerlink href=#callbackcollection title="Permanent link">&para;</a></h3> <p>Manages multiple callbacks efficiently:</p> <div class="doc doc-object doc-class"> <h2 id=dream_trainer.callbacks.CallbackCollection class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">CallbackCollection</span> <a href=#dream_trainer.callbacks.CallbackCollection class=headerlink title="Permanent link">&para;</a></h2> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>CallbackCollection</span><span class=p>(</span><span class=n>callbacks</span><span class=p>:</span> <span class=n>Iterable</span><span class=p>[</span><span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>]</span> <span class=o>|</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>]</span> <span class=o>|</span> <span class=n>Iterable</span><span class=p>[</span><span class=nb>tuple</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>]]</span> <span class=o>=</span> <span class=p>[])</span>
</span></code></pre></div> <div class="doc doc-contents first"> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-243>243</a></span>
<span class=normal><a href=#__codelineno-0-244>244</a></span>
<span class=normal><a href=#__codelineno-0-245>245</a></span>
<span class=normal><a href=#__codelineno-0-246>246</a></span>
<span class=normal><a href=#__codelineno-0-247>247</a></span>
<span class=normal><a href=#__codelineno-0-248>248</a></span>
<span class=normal><a href=#__codelineno-0-249>249</a></span>
<span class=normal><a href=#__codelineno-0-250>250</a></span>
<span class=normal><a href=#__codelineno-0-251>251</a></span>
<span class=normal><a href=#__codelineno-0-252>252</a></span>
<span class=normal><a href=#__codelineno-0-253>253</a></span>
<span class=normal><a href=#__codelineno-0-254>254</a></span>
<span class=normal><a href=#__codelineno-0-255>255</a></span>
<span class=normal><a href=#__codelineno-0-256>256</a></span>
<span class=normal><a href=#__codelineno-0-257>257</a></span>
<span class=normal><a href=#__codelineno-0-258>258</a></span>
<span class=normal><a href=#__codelineno-0-259>259</a></span>
<span class=normal><a href=#__codelineno-0-260>260</a></span>
<span class=normal><a href=#__codelineno-0-261>261</a></span>
<span class=normal><a href=#__codelineno-0-262>262</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-243><a id=__codelineno-0-243 name=__codelineno-0-243></a><span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
</span><span id=__span-0-244><a id=__codelineno-0-244 name=__codelineno-0-244></a>    <span class=bp>self</span><span class=p>,</span>
</span><span id=__span-0-245><a id=__codelineno-0-245 name=__codelineno-0-245></a>    <span class=n>callbacks</span><span class=p>:</span> <span class=n>Iterable</span><span class=p>[</span><span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>]</span>
</span><span id=__span-0-246><a id=__codelineno-0-246 name=__codelineno-0-246></a>    <span class=o>|</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>]</span>
</span><span id=__span-0-247><a id=__codelineno-0-247 name=__codelineno-0-247></a>    <span class=o>|</span> <span class=n>Iterable</span><span class=p>[</span><span class=nb>tuple</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>]]</span> <span class=o>=</span> <span class=p>[],</span>
</span><span id=__span-0-248><a id=__codelineno-0-248 name=__codelineno-0-248></a><span class=p>):</span>
</span><span id=__span-0-249><a id=__codelineno-0-249 name=__codelineno-0-249></a>    <span class=c1># Get all methods defined in Callback above</span>
</span><span id=__span-0-250><a id=__codelineno-0-250 name=__codelineno-0-250></a>    <span class=bp>self</span><span class=o>.</span><span class=n>trigger_names</span> <span class=o>=</span> <span class=p>{</span><span class=n>m</span> <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=nb>dir</span><span class=p>(</span><span class=n>Callback</span><span class=p>)</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>m</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s2>&quot;_&quot;</span><span class=p>)}</span>
</span><span id=__span-0-251><a id=__codelineno-0-251 name=__codelineno-0-251></a>
</span><span id=__span-0-252><a id=__codelineno-0-252 name=__codelineno-0-252></a>    <span class=c1># Allow callback initialization to match dict initialization</span>
</span><span id=__span-0-253><a id=__codelineno-0-253 name=__codelineno-0-253></a>    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>callbacks</span><span class=p>,</span> <span class=nb>dict</span><span class=p>):</span>
</span><span id=__span-0-254><a id=__codelineno-0-254 name=__codelineno-0-254></a>        <span class=n>callbacks</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-0-255><a id=__codelineno-0-255 name=__codelineno-0-255></a>            <span class=n>callback</span>
</span><span id=__span-0-256><a id=__codelineno-0-256 name=__codelineno-0-256></a>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>callback</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>)</span>
</span><span id=__span-0-257><a id=__codelineno-0-257 name=__codelineno-0-257></a>            <span class=k>else</span> <span class=p>(</span><span class=n>callback</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>,</span> <span class=n>callback</span><span class=p>)</span>
</span><span id=__span-0-258><a id=__codelineno-0-258 name=__codelineno-0-258></a>            <span class=k>for</span> <span class=n>callback</span> <span class=ow>in</span> <span class=n>callbacks</span>
</span><span id=__span-0-259><a id=__codelineno-0-259 name=__codelineno-0-259></a>        <span class=p>]</span>
</span><span id=__span-0-260><a id=__codelineno-0-260 name=__codelineno-0-260></a>
</span><span id=__span-0-261><a id=__codelineno-0-261 name=__codelineno-0-261></a>    <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>callbacks</span><span class=p>)</span>  <span class=c1># type: ignore</span>
</span><span id=__span-0-262><a id=__codelineno-0-262 name=__codelineno-0-262></a>    <span class=bp>self</span><span class=o>.</span><span class=n>refresh</span><span class=p>()</span>
</span></code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <h3 id=dream_trainer.callbacks.CallbackCollection-functions>Functions<a href=#dream_trainer.callbacks.CallbackCollection-functions class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.CallbackCollection.initialize class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">initialize</span> <a href=#dream_trainer.callbacks.CallbackCollection.initialize class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>initialize</span><span class=p>(</span><span class=n>trainer</span><span class=p>:</span> <span class=n>AbstractTrainer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-264>264</a></span>
<span class=normal><a href=#__codelineno-0-265>265</a></span>
<span class=normal><a href=#__codelineno-0-266>266</a></span>
<span class=normal><a href=#__codelineno-0-267>267</a></span>
<span class=normal><a href=#__codelineno-0-268>268</a></span>
<span class=normal><a href=#__codelineno-0-269>269</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-264><a id=__codelineno-0-264 name=__codelineno-0-264></a><span class=k>def</span><span class=w> </span><span class=nf>initialize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>trainer</span><span class=p>:</span> <span class=n>AbstractTrainer</span><span class=p>):</span>
</span><span id=__span-0-265><a id=__codelineno-0-265 name=__codelineno-0-265></a>    <span class=k>for</span> <span class=n>callback</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>values</span><span class=p>():</span>
</span><span id=__span-0-266><a id=__codelineno-0-266 name=__codelineno-0-266></a>        <span class=n>deps</span> <span class=o>=</span> <span class=n>deps</span> <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>deps</span> <span class=o>:=</span> <span class=n>callback</span><span class=o>.</span><span class=n>_dependency</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>)</span> <span class=k>else</span> <span class=p>(</span><span class=n>deps</span><span class=p>,)</span>
</span><span id=__span-0-267><a id=__codelineno-0-267 name=__codelineno-0-267></a>        <span class=k>assert</span> <span class=nb>all</span><span class=p>(</span><span class=nb>isinstance</span><span class=p>(</span><span class=n>trainer</span><span class=p>,</span> <span class=n>dependency</span><span class=p>)</span> <span class=k>for</span> <span class=n>dependency</span> <span class=ow>in</span> <span class=n>deps</span><span class=p>)</span>
</span><span id=__span-0-268><a id=__codelineno-0-268 name=__codelineno-0-268></a>
</span><span id=__span-0-269><a id=__codelineno-0-269 name=__codelineno-0-269></a>        <span class=n>callback</span><span class=o>.</span><span class=n>trainer</span> <span class=o>=</span> <span class=n>trainer</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.CallbackCollection.state_dict class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">state_dict</span> <a href=#dream_trainer.callbacks.CallbackCollection.state_dict class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>state_dict</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-274>274</a></span>
<span class=normal><a href=#__codelineno-0-275>275</a></span>
<span class=normal><a href=#__codelineno-0-276>276</a></span>
<span class=normal><a href=#__codelineno-0-277>277</a></span>
<span class=normal><a href=#__codelineno-0-278>278</a></span>
<span class=normal><a href=#__codelineno-0-279>279</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-274><a id=__codelineno-0-274 name=__codelineno-0-274></a><span class=k>def</span><span class=w> </span><span class=nf>state_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-275><a id=__codelineno-0-275 name=__codelineno-0-275></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-0-276><a id=__codelineno-0-276 name=__codelineno-0-276></a>        <span class=n>name</span><span class=p>:</span> <span class=nb>getattr</span><span class=p>(</span><span class=n>callback</span><span class=p>,</span> <span class=s2>&quot;state_dict&quot;</span><span class=p>)()</span>
</span><span id=__span-0-277><a id=__codelineno-0-277 name=__codelineno-0-277></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>callback</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>items</span><span class=p>()</span>
</span><span id=__span-0-278><a id=__codelineno-0-278 name=__codelineno-0-278></a>        <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>callback</span><span class=p>,</span> <span class=s2>&quot;state_dict&quot;</span><span class=p>)</span>
</span><span id=__span-0-279><a id=__codelineno-0-279 name=__codelineno-0-279></a>    <span class=p>}</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.CallbackCollection.load_state_dict class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">load_state_dict</span> <a href=#dream_trainer.callbacks.CallbackCollection.load_state_dict class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>load_state_dict</span><span class=p>(</span><span class=n>state_dicts</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]],</span> <span class=n>trainer</span><span class=p>:</span> <span class=n>AbstractTrainer</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-281>281</a></span>
<span class=normal><a href=#__codelineno-0-282>282</a></span>
<span class=normal><a href=#__codelineno-0-283>283</a></span>
<span class=normal><a href=#__codelineno-0-284>284</a></span>
<span class=normal><a href=#__codelineno-0-285>285</a></span>
<span class=normal><a href=#__codelineno-0-286>286</a></span>
<span class=normal><a href=#__codelineno-0-287>287</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-281><a id=__codelineno-0-281 name=__codelineno-0-281></a><span class=k>def</span><span class=w> </span><span class=nf>load_state_dict</span><span class=p>(</span>
</span><span id=__span-0-282><a id=__codelineno-0-282 name=__codelineno-0-282></a>    <span class=bp>self</span><span class=p>,</span>
</span><span id=__span-0-283><a id=__codelineno-0-283 name=__codelineno-0-283></a>    <span class=n>state_dicts</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]],</span>
</span><span id=__span-0-284><a id=__codelineno-0-284 name=__codelineno-0-284></a>    <span class=n>trainer</span><span class=p>:</span> <span class=n>AbstractTrainer</span><span class=p>,</span>
</span><span id=__span-0-285><a id=__codelineno-0-285 name=__codelineno-0-285></a><span class=p>):</span>
</span><span id=__span-0-286><a id=__codelineno-0-286 name=__codelineno-0-286></a>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>state_dict</span> <span class=ow>in</span> <span class=n>state_dicts</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-0-287><a id=__codelineno-0-287 name=__codelineno-0-287></a>        <span class=nb>getattr</span><span class=p>(</span><span class=bp>self</span><span class=p>[</span><span class=n>name</span><span class=p>],</span> <span class=s2>&quot;load_state_dict&quot;</span><span class=p>)(</span><span class=n>state_dict</span><span class=p>,</span> <span class=n>trainer</span><span class=p>)</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.CallbackCollection.append class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">append</span> <a href=#dream_trainer.callbacks.CallbackCollection.append class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>append</span><span class=p>(</span><span class=n>callback</span><span class=p>:</span> <span class=n>Callback</span> <span class=o>|</span> <span class=n>RankZeroCallback</span><span class=p>)</span>
</span></code></pre></div> <div class="doc doc-contents "> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-316>316</a></span>
<span class=normal><a href=#__codelineno-0-317>317</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-316><a id=__codelineno-0-316 name=__codelineno-0-316></a><span class=k>def</span><span class=w> </span><span class=nf>append</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>callback</span><span class=p>:</span> <span class=s2>&quot;Callback | RankZeroCallback&quot;</span><span class=p>):</span>
</span><span id=__span-0-317><a id=__codelineno-0-317 name=__codelineno-0-317></a>    <span class=bp>self</span><span class=p>[</span><span class=n>callback</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>]</span> <span class=o>=</span> <span class=n>callback</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h4 id=dream_trainer.callbacks.CallbackCollection.refresh class="doc doc-heading"> <code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">refresh</span> <a href=#dream_trainer.callbacks.CallbackCollection.refresh class=headerlink title="Permanent link">&para;</a></h4> <div class="language-python doc-signature highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=nf>refresh</span><span class=p>()</span>
</span></code></pre></div> <div class="doc doc-contents "> <p>Organizes callbacks by method name for efficient execution.</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <details class=quote> <summary>Source code in <code>src/dream_trainer/callbacks/callback.py</code></summary> <div class="language-python highlight"><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-289>289</a></span>
<span class=normal><a href=#__codelineno-0-290>290</a></span>
<span class=normal><a href=#__codelineno-0-291>291</a></span>
<span class=normal><a href=#__codelineno-0-292>292</a></span>
<span class=normal><a href=#__codelineno-0-293>293</a></span>
<span class=normal><a href=#__codelineno-0-294>294</a></span>
<span class=normal><a href=#__codelineno-0-295>295</a></span>
<span class=normal><a href=#__codelineno-0-296>296</a></span>
<span class=normal><a href=#__codelineno-0-297>297</a></span>
<span class=normal><a href=#__codelineno-0-298>298</a></span>
<span class=normal><a href=#__codelineno-0-299>299</a></span>
<span class=normal><a href=#__codelineno-0-300>300</a></span>
<span class=normal><a href=#__codelineno-0-301>301</a></span></pre></div></td><td class=code><div><pre><span></span><code><span id=__span-0-289><a id=__codelineno-0-289 name=__codelineno-0-289></a><span class=k>def</span><span class=w> </span><span class=nf>refresh</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-290><a id=__codelineno-0-290 name=__codelineno-0-290></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-291><a id=__codelineno-0-291 name=__codelineno-0-291></a><span class=sd>    Organizes callbacks by method name for efficient execution.</span>
</span><span id=__span-0-292><a id=__codelineno-0-292 name=__codelineno-0-292></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-293><a id=__codelineno-0-293 name=__codelineno-0-293></a>    <span class=bp>self</span><span class=o>.</span><span class=n>triggers</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-0-294><a id=__codelineno-0-294 name=__codelineno-0-294></a>        <span class=n>trigger</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-0-295><a id=__codelineno-0-295 name=__codelineno-0-295></a>            <span class=n>callback</span>
</span><span id=__span-0-296><a id=__codelineno-0-296 name=__codelineno-0-296></a>            <span class=k>for</span> <span class=n>callback</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>values</span><span class=p>()</span>
</span><span id=__span-0-297><a id=__codelineno-0-297 name=__codelineno-0-297></a>            <span class=c1># Only add triggers that were overridden in the callback</span>
</span><span id=__span-0-298><a id=__codelineno-0-298 name=__codelineno-0-298></a>            <span class=k>if</span> <span class=ow>not</span> <span class=nb>getattr</span><span class=p>(</span><span class=n>callback</span><span class=p>,</span> <span class=n>trigger</span><span class=p>)</span><span class=o>.</span><span class=vm>__qualname__</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s2>&quot;Callback.&quot;</span><span class=p>)</span>
</span><span id=__span-0-299><a id=__codelineno-0-299 name=__codelineno-0-299></a>        <span class=p>]</span>
</span><span id=__span-0-300><a id=__codelineno-0-300 name=__codelineno-0-300></a>        <span class=k>for</span> <span class=n>trigger</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>trigger_names</span>
</span><span id=__span-0-301><a id=__codelineno-0-301 name=__codelineno-0-301></a>    <span class=p>}</span>
</span></code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div><h2 id=creating-custom-callbacks>Creating Custom Callbacks<a class=headerlink href=#creating-custom-callbacks title="Permanent link">&para;</a></h2> <h3 id=basic-callback>Basic Callback<a class=headerlink href=#basic-callback title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>Callback</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>BaseTrainer</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=k>class</span><span class=w> </span><span class=nc>SimpleLoggingCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Log training progress to a file.&quot;&quot;&quot;</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>log_file</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>log_file</span> <span class=o>=</span> <span class=n>log_file</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>        <span class=c1># Open log file when training starts</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>        <span class=bp>self</span><span class=o>.</span><span class=n>file</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>log_file</span><span class=p>,</span> <span class=s2>&quot;w&quot;</span><span class=p>)</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>        <span class=bp>self</span><span class=o>.</span><span class=n>file</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training started for </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>experiment</span><span class=si>}</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>        <span class=c1># Log loss after each step</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;loss&quot;</span><span class=p>)</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>        <span class=k>if</span> <span class=n>loss</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>            <span class=bp>self</span><span class=o>.</span><span class=n>file</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Step </span><span class=si>{</span><span class=n>batch_idx</span><span class=si>}</span><span class=s2>: loss=</span><span class=si>{</span><span class=n>loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a>        <span class=c1># Close file when training ends</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>        <span class=bp>self</span><span class=o>.</span><span class=n>file</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&quot;Training completed</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a>        <span class=bp>self</span><span class=o>.</span><span class=n>file</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></code></pre></div> <h3 id=callback-with-dependencies>Callback with Dependencies<a class=headerlink href=#callback-with-dependencies title="Permanent link">&para;</a></h3> <p>Callbacks can specify dependencies on trainer mixins using generics:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>Callback</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.trainer.mixins</span><span class=w> </span><span class=kn>import</span> <span class=n>EvalMetricMixin</span><span class=p>,</span> <span class=n>WandBLoggerMixin</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=k>class</span><span class=w> </span><span class=nc>MetricLoggingCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>EvalMetricMixin</span> <span class=o>&amp;</span> <span class=n>WandBLoggerMixin</span><span class=p>]):</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Log metrics to WandB after validation.&quot;&quot;&quot;</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_validation_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]):</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>        <span class=c1># Access metrics from EvalMetricMixin</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>        <span class=n>metrics</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>named_metrics</span><span class=p>()</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>        <span class=c1># Compute and log metrics using WandBLoggerMixin</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>metric</span> <span class=ow>in</span> <span class=n>metrics</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>            <span class=n>value</span> <span class=o>=</span> <span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>()</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>            <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>log_scalar</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;val/</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>,</span> <span class=n>value</span><span class=p>)</span>
</span></code></pre></div> <h3 id=rank-zero-callback>Rank Zero Callback<a class=headerlink href=#rank-zero-callback title="Permanent link">&para;</a></h3> <p>For operations that should only run on the main process:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>RankZeroCallback</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=k>class</span><span class=w> </span><span class=nc>ModelSummaryCallback</span><span class=p>(</span><span class=n>RankZeroCallback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Print model summary only on rank 0.&quot;&quot;&quot;</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>        <span class=c1># This only runs on rank 0</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>        <span class=n>total_params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>        <span class=n>trainable_params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>            <span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()</span> <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>requires_grad</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>        <span class=p>)</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total parameters: </span><span class=si>{</span><span class=n>total_params</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Trainable parameters: </span><span class=si>{</span><span class=n>trainable_params</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Non-trainable parameters: </span><span class=si>{</span><span class=n>total_params</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>trainable_params</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=lifecycle-hooks>Lifecycle Hooks<a class=headerlink href=#lifecycle-hooks title="Permanent link">&para;</a></h2> <p>The callback system provides hooks at every stage of training:</p> <h3 id=initialization-phase>Initialization Phase<a class=headerlink href=#initialization-phase title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=k>class</span><span class=w> </span><span class=nc>InitializationCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_launch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before distributed world is created.&quot;&quot;&quot;</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Setting up environment variables&quot;</span><span class=p>)</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before models/optimizers are configured.&quot;&quot;&quot;</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Preparing configuration&quot;</span><span class=p>)</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After configuration but before setup.&quot;&quot;&quot;</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Configuration complete&quot;</span><span class=p>)</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before models are materialized.&quot;&quot;&quot;</span>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Beginning setup&quot;</span><span class=p>)</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After all components are ready.&quot;&quot;&quot;</span>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Setup complete&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=training-phase>Training Phase<a class=headerlink href=#training-phase title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=k>class</span><span class=w> </span><span class=nc>TrainingCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Training is about to start.&quot;&quot;&quot;</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before each epoch (train + val).&quot;&quot;&quot;</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>epoch_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before training epoch.&quot;&quot;&quot;</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Starting epoch </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>current_epoch</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before each training step.&quot;&quot;&quot;</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a>        <span class=c1># Modify batch if needed</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a>        <span class=k>return</span> <span class=n>batch</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After training step.&quot;&quot;&quot;</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a>        <span class=c1># Process results</span>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a>        <span class=k>pass</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a>
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]):</span>
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After training epoch.&quot;&quot;&quot;</span>
</span><span id=__span-4-26><a id=__codelineno-4-26 name=__codelineno-4-26 href=#__codelineno-4-26></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Epoch </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>current_epoch</span><span class=si>}</span><span class=s2> complete&quot;</span><span class=p>)</span>
</span><span id=__span-4-27><a id=__codelineno-4-27 name=__codelineno-4-27 href=#__codelineno-4-27></a>
</span><span id=__span-4-28><a id=__codelineno-4-28 name=__codelineno-4-28 href=#__codelineno-4-28></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-29><a id=__codelineno-4-29 name=__codelineno-4-29 href=#__codelineno-4-29></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After full epoch (train + val).&quot;&quot;&quot;</span>
</span><span id=__span-4-30><a id=__codelineno-4-30 name=__codelineno-4-30 href=#__codelineno-4-30></a>        <span class=n>epoch_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>epoch_start</span>
</span><span id=__span-4-31><a id=__codelineno-4-31 name=__codelineno-4-31 href=#__codelineno-4-31></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Epoch took </span><span class=si>{</span><span class=n>epoch_time</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span><span id=__span-4-32><a id=__codelineno-4-32 name=__codelineno-4-32 href=#__codelineno-4-32></a>
</span><span id=__span-4-33><a id=__codelineno-4-33 name=__codelineno-4-33 href=#__codelineno-4-33></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-34><a id=__codelineno-4-34 name=__codelineno-4-34 href=#__codelineno-4-34></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Training complete.&quot;&quot;&quot;</span>
</span><span id=__span-4-35><a id=__codelineno-4-35 name=__codelineno-4-35 href=#__codelineno-4-35></a>        <span class=n>total_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>start_time</span>
</span><span id=__span-4-36><a id=__codelineno-4-36 name=__codelineno-4-36 href=#__codelineno-4-36></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total training time: </span><span class=si>{</span><span class=n>total_time</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=optimizer-hooks>Optimizer Hooks<a class=headerlink href=#optimizer-hooks title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=k>class</span><span class=w> </span><span class=nc>GradientCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_optimizer_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before optimizer step.&quot;&quot;&quot;</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>        <span class=c1># Could modify gradients here</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>        <span class=n>total_norm</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Gradient norm: </span><span class=si>{</span><span class=n>total_norm</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_optimizer_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After optimizer step.&quot;&quot;&quot;</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>        <span class=c1># Log learning rate</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>        <span class=n>lr</span> <span class=o>=</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s2>&quot;lr&quot;</span><span class=p>]</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Learning rate: </span><span class=si>{</span><span class=n>lr</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_optimizer_zero_grad</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Before zeroing gradients.&quot;&quot;&quot;</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>        <span class=k>pass</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_optimizer_zero_grad</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>:</span> <span class=n>Optimizer</span><span class=p>):</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;After zeroing gradients.&quot;&quot;&quot;</span>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a>        <span class=k>pass</span>
</span></code></pre></div> <h2 id=context-managers>Context Managers<a class=headerlink href=#context-managers title="Permanent link">&para;</a></h2> <p>Callbacks can provide context managers for training/validation:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>import</span><span class=w> </span><span class=nn>contextlib</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Any</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=k>class</span><span class=w> </span><span class=nc>ProfilingCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>profiler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>profile</span><span class=p>(</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>            <span class=n>activities</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>                <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CPU</span><span class=p>,</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>                <span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CUDA</span><span class=p>,</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>            <span class=p>],</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>            <span class=n>schedule</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>schedule</span><span class=p>(</span><span class=n>wait</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>warmup</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>active</span><span class=o>=</span><span class=mi>3</span><span class=p>),</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>            <span class=n>on_trace_ready</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>profiler</span><span class=o>.</span><span class=n>tensorboard_trace_handler</span><span class=p>(</span><span class=s2>&quot;./logs&quot;</span><span class=p>),</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>        <span class=p>)</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>    <span class=nd>@contextlib</span><span class=o>.</span><span class=n>contextmanager</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>    <span class=k>def</span><span class=w> </span><span class=nf>train_context</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Context for training steps.&quot;&quot;&quot;</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>profiler</span><span class=p>:</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>            <span class=k>yield</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a>    <span class=nd>@contextlib</span><span class=o>.</span><span class=n>contextmanager</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>    <span class=k>def</span><span class=w> </span><span class=nf>validation_context</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Context for validation steps.&quot;&quot;&quot;</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>        <span class=c1># No profiling during validation</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a>        <span class=k>yield</span>
</span></code></pre></div> <h2 id=state-management>State Management<a class=headerlink href=#state-management title="Permanent link">&para;</a></h2> <p>Callbacks can save and restore state for resumable training:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=k>class</span><span class=w> </span><span class=nc>StatefulCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>        <span class=bp>self</span><span class=o>.</span><span class=n>step_count</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>best_metric</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=s2>&quot;inf&quot;</span><span class=p>)</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>batch_idx</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>        <span class=bp>self</span><span class=o>.</span><span class=n>step_count</span> <span class=o>+=</span> <span class=mi>1</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_validation_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]):</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>        <span class=n>metric</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;val_loss&quot;</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s2>&quot;inf&quot;</span><span class=p>))</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>best_metric</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_metric</span><span class=p>,</span> <span class=n>metric</span><span class=p>)</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>    <span class=k>def</span><span class=w> </span><span class=nf>state_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Save callback state.&quot;&quot;&quot;</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>        <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>            <span class=s2>&quot;step_count&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>step_count</span><span class=p>,</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a>            <span class=s2>&quot;best_metric&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_metric</span><span class=p>,</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>        <span class=p>}</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>    <span class=k>def</span><span class=w> </span><span class=nf>load_state_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>state_dict</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>trainer</span><span class=p>:</span> <span class=n>BaseTrainer</span><span class=p>):</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Restore callback state.&quot;&quot;&quot;</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>        <span class=bp>self</span><span class=o>.</span><span class=n>step_count</span> <span class=o>=</span> <span class=n>state_dict</span><span class=p>[</span><span class=s2>&quot;step_count&quot;</span><span class=p>]</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>        <span class=bp>self</span><span class=o>.</span><span class=n>best_metric</span> <span class=o>=</span> <span class=n>state_dict</span><span class=p>[</span><span class=s2>&quot;best_metric&quot;</span><span class=p>]</span>
</span></code></pre></div> <h2 id=using-callbacks>Using Callbacks<a class=headerlink href=#using-callbacks title="Permanent link">&para;</a></h2> <h3 id=single-callback>Single Callback<a class=headerlink href=#single-callback title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>DreamTrainer</span><span class=p>,</span> <span class=n>DreamTrainerConfig</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>CallbackCollection</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=n>config</span> <span class=o>=</span> <span class=n>DreamTrainerConfig</span><span class=p>(</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>    <span class=c1># ... other config ...</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>    <span class=n>callbacks</span><span class=o>=</span><span class=n>CallbackCollection</span><span class=p>([</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>        <span class=n>SimpleLoggingCallback</span><span class=p>(</span><span class=s2>&quot;training.log&quot;</span><span class=p>)</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=p>])</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=p>)</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=n>trainer</span> <span class=o>=</span> <span class=n>MyTrainer</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=n>trainer</span><span class=o>.</span><span class=n>configure</span><span class=p>()</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a><span class=n>trainer</span><span class=o>.</span><span class=n>setup</span><span class=p>()</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=n>trainer</span><span class=o>.</span><span class=n>fit</span><span class=p>()</span>
</span></code></pre></div> <h3 id=multiple-callbacks>Multiple Callbacks<a class=headerlink href=#multiple-callbacks title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=n>callbacks</span> <span class=o>=</span> <span class=n>CallbackCollection</span><span class=p>([</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>    <span class=n>ProgressBar</span><span class=p>(),</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>    <span class=n>ModelSummaryCallback</span><span class=p>(),</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>    <span class=n>CheckpointCallback</span><span class=p>(</span><span class=n>checkpoint_config</span><span class=p>),</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>    <span class=n>ProfileCallback</span><span class=p>(</span><span class=n>profiler</span><span class=p>),</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>    <span class=n>CustomMetricCallback</span><span class=p>(),</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=p>])</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=n>config</span> <span class=o>=</span> <span class=n>DreamTrainerConfig</span><span class=p>(</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>    <span class=c1># ... other config ...</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>    <span class=n>callbacks</span><span class=o>=</span><span class=n>callbacks</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=p>)</span>
</span></code></pre></div> <h3 id=adding-callbacks-dynamically>Adding Callbacks Dynamically<a class=headerlink href=#adding-callbacks-dynamically title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=n>trainer</span> <span class=o>=</span> <span class=n>MyTrainer</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=c1># Add callback after initialization</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=n>trainer</span><span class=o>.</span><span class=n>callbacks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>NewCallback</span><span class=p>())</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=c1># Or use dict-style access</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a><span class=n>trainer</span><span class=o>.</span><span class=n>callbacks</span><span class=p>[</span><span class=s2>&quot;CustomCallback&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>CustomCallback</span><span class=p>()</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=c1># Remove callback</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=k>del</span> <span class=n>trainer</span><span class=o>.</span><span class=n>callbacks</span><span class=p>[</span><span class=s2>&quot;CustomCallback&quot;</span><span class=p>]</span>
</span></code></pre></div> <h2 id=built-in-callbacks>Built-in Callbacks<a class=headerlink href=#built-in-callbacks title="Permanent link">&para;</a></h2> <p>Dream Trainer includes several built-in callbacks:</p> <ul> <li><strong><a href=../monitoring/#progressbar>ProgressBar</a></strong> - Display training progress</li> <li><strong><a href=../checkpoint/ >CheckpointCallback</a></strong> - Save and restore checkpoints</li> <li><strong><a href=../performance/#profilecallback>ProfileCallback</a></strong> - Profile training performance</li> <li><strong><a href=../monitoring/#loggercallback>LoggerCallback</a></strong> - Log metrics</li> <li><strong><a href=../monitoring/#trainersummary>TrainerSummary</a></strong> - Display trainer configuration</li> <li><strong><a href=../performance/#findgraphbreakscallback>FindGraphBreaksCallback</a></strong> - Debug torch.compile</li> <li><strong><a href=../performance/#optimizefsdp>OptimizeFSDP</a></strong> - Optimize FSDP performance</li> </ul> <h2 id=best-practices>Best Practices<a class=headerlink href=#best-practices title="Permanent link">&para;</a></h2> <h3 id=1-use-type-hints>1. Use Type Hints<a class=headerlink href=#1-use-type-hints title="Permanent link">&para;</a></h3> <p>Always specify the trainer type for better IDE support:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=k>class</span><span class=w> </span><span class=nc>MyCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>DreamTrainer</span><span class=p>]):</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>    <span class=c1># Now self.trainer is typed as DreamTrainer</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>        <span class=n>models</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>named_models</span><span class=p>()</span>  <span class=c1># Type-safe access</span>
</span></code></pre></div> <h3 id=2-handle-distributed-training>2. Handle Distributed Training<a class=headerlink href=#2-handle-distributed-training title="Permanent link">&para;</a></h3> <p>Be aware of distributed training when designing callbacks:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>class</span><span class=w> </span><span class=nc>DistributedAwareCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]):</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>        <span class=c1># Aggregate metrics across all processes</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=s2>&quot;loss&quot;</span><span class=p>]</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>        <span class=n>avg_loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>world</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>op</span><span class=o>=</span><span class=s2>&quot;mean&quot;</span><span class=p>)</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>world</span><span class=o>.</span><span class=n>is_global_zero</span><span class=p>:</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Average loss: </span><span class=si>{</span><span class=n>avg_loss</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=3-avoid-side-effects>3. Avoid Side Effects<a class=headerlink href=#3-avoid-side-effects title="Permanent link">&para;</a></h3> <p>Don't modify trainer state in unexpected ways:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># Bad - modifies training state</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=k>class</span><span class=w> </span><span class=nc>BadCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>global_step</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># Don&#39;t do this!</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=c1># Good - only observes state</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=k>class</span><span class=w> </span><span class=nc>GoodCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Current step: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>global_step</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=4-resource-management>4. Resource Management<a class=headerlink href=#4-resource-management title="Permanent link">&para;</a></h3> <p>Clean up resources properly:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=k>class</span><span class=w> </span><span class=nc>ResourceCallback</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>BaseTrainer</span><span class=p>]):</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>    <span class=k>def</span><span class=w> </span><span class=nf>pre_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>        <span class=bp>self</span><span class=o>.</span><span class=n>file</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&quot;log.txt&quot;</span><span class=p>,</span> <span class=s2>&quot;w&quot;</span><span class=p>)</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>connection</span> <span class=o>=</span> <span class=n>create_database_connection</span><span class=p>()</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>        <span class=c1># Always clean up, even if training fails</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>        <span class=k>try</span><span class=p>:</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>            <span class=bp>self</span><span class=o>.</span><span class=n>file</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a>        <span class=k>except</span><span class=p>:</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a>            <span class=k>pass</span>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a>        <span class=k>try</span><span class=p>:</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a>            <span class=bp>self</span><span class=o>.</span><span class=n>connection</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a>        <span class=k>except</span><span class=p>:</span>
</span><span id=__span-14-16><a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a>            <span class=k>pass</span>
</span></code></pre></div> <h2 id=see-also>See Also<a class=headerlink href=#see-also title="Permanent link">&para;</a></h2> <ul> <li><a href=../checkpoint/ >CheckpointCallback</a> - Checkpointing implementation</li> <li><a href=../monitoring/ >Monitoring Callbacks</a> - Progress and logging callbacks</li> <li><a href=../performance/ >Performance Callbacks</a> - Profiling and optimization</li> <li><a href=../../trainers/base/ >BaseTrainer</a> - Trainer implementation </li> </ul> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../mixins/quantize/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Quantization Mixins"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Quantization Mixins </div> </div> </a> <a href=../checkpoint/ class="md-footer__link md-footer__link--next" aria-label="Next: Checkpoint Callbacks"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Checkpoint Callbacks </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dream3d/dream-trainer target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://discord.gg/dream-trainer target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> <a href=https://twitter.com/dream3d_ai target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.prune", "navigation.indexes", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.action.edit", "content.action.view", "content.tooltips", "toc.follow", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "stable", "provider": "mike"}}</script> <script src=../../../assets/javascripts/bundle.56ea9cef.min.js></script> <script src=../../../js/timeago.min.js></script> <script src=../../../js/timeago_mkdocs_material.js></script> <script src=../../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>