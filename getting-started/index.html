<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Composable distributed training framework built around PyTorch DTensor abstractions"><link href=https://dream3d.ai/trainer/getting-started/ rel=canonical><link href=../installation/ rel=prev><link href=../core-concepts/ rel=next><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.15"><title>Quick Start - dream-trainer</title><link rel=stylesheet href=../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../assets/_mkdocstrings.css><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#getting-started-with-dream-trainer class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=dream-trainer class="md-header__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> dream-trainer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Quick Start </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../installation/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../configuration/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../tutorials/first-trainer.md class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../examples/vision.md class=md-tabs__link> Examples </a> </li> <li class=md-tabs__item> <a href=../api/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../contributing.md class=md-tabs__link> Community </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=dream-trainer class="md-nav__button md-logo" aria-label=dream-trainer data-md-component=logo> <img src=../assets/logo.png alt=logo> </a> dream-trainer </label> <div class=md-nav__source> <a href=https://github.com/dream3d/dream-trainer title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Quick Start </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Quick Start </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-dream-trainer class=md-nav__link> <span class=md-ellipsis> Why Dream Trainer? </span> </a> <nav class=md-nav aria-label="Why Dream Trainer?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#composable-mixin-architecture class=md-nav__link> <span class=md-ellipsis> 🧩 Composable Mixin Architecture </span> </a> </li> <li class=md-nav__item> <a href=#dtensor-native-from-day-one class=md-nav__link> <span class=md-ellipsis> 🚀 DTensor-Native from Day One </span> </a> </li> <li class=md-nav__item> <a href=#zero-compromise-performance class=md-nav__link> <span class=md-ellipsis> ⚡ Zero-Compromise Performance </span> </a> </li> <li class=md-nav__item> <a href=#configs-as-code-for-type-safety class=md-nav__link> <span class=md-ellipsis> 📝 Configs as Code for Type Safety </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#installation class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=#your-first-trainer class=md-nav__link> <span class=md-ellipsis> Your First Trainer </span> </a> <nav class=md-nav aria-label="Your First Trainer"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#step-1-understanding-the-mixin-pattern class=md-nav__link> <span class=md-ellipsis> Step 1: Understanding the Mixin Pattern </span> </a> </li> <li class=md-nav__item> <a href=#step-2-add-advanced-parallelism class=md-nav__link> <span class=md-ellipsis> Step 2: Add Advanced Parallelism </span> </a> </li> <li class=md-nav__item> <a href=#step-3-implement-parallelism-methods class=md-nav__link> <span class=md-ellipsis> Step 3: Implement Parallelism Methods </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#complete-example-multi-gpu-language-model class=md-nav__link> <span class=md-ellipsis> Complete Example: Multi-GPU Language Model </span> </a> </li> <li class=md-nav__item> <a href=#launch-training class=md-nav__link> <span class=md-ellipsis> Launch Training </span> </a> <nav class=md-nav aria-label="Launch Training"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#single-gpu class=md-nav__link> <span class=md-ellipsis> Single GPU </span> </a> </li> <li class=md-nav__item> <a href=#multiple-gpus-single-node class=md-nav__link> <span class=md-ellipsis> Multiple GPUs (Single Node) </span> </a> </li> <li class=md-nav__item> <a href=#multiple-nodes class=md-nav__link> <span class=md-ellipsis> Multiple Nodes </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-dream-trainers-advantages class=md-nav__link> <span class=md-ellipsis> Understanding Dream Trainer's Advantages </span> </a> <nav class=md-nav aria-label="Understanding Dream Trainer's Advantages"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-clean-parallelism-abstractions class=md-nav__link> <span class=md-ellipsis> 1. Clean Parallelism Abstractions </span> </a> </li> <li class=md-nav__item> <a href=#2-automatic-mixed-precision class=md-nav__link> <span class=md-ellipsis> 2. Automatic Mixed Precision </span> </a> </li> <li class=md-nav__item> <a href=#3-gradient-accumulation-that-just-works class=md-nav__link> <span class=md-ellipsis> 3. Gradient Accumulation That Just Works </span> </a> </li> <li class=md-nav__item> <a href=#4-composable-features class=md-nav__link> <span class=md-ellipsis> 4. Composable Features </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-patterns class=md-nav__link> <span class=md-ellipsis> Common Patterns </span> </a> <nav class=md-nav aria-label="Common Patterns"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#adding-custom-callbacks class=md-nav__link> <span class=md-ellipsis> Adding Custom Callbacks </span> </a> </li> <li class=md-nav__item> <a href=#debugging-distributed-training class=md-nav__link> <span class=md-ellipsis> Debugging Distributed Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#next-steps class=md-nav__link> <span class=md-ellipsis> Next Steps </span> </a> </li> <li class=md-nav__item> <a href=#troubleshooting class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> <nav class=md-nav aria-label=Troubleshooting> <ul class=md-nav__list> <li class=md-nav__item> <a href=#installation-issues class=md-nav__link> <span class=md-ellipsis> Installation Issues </span> </a> </li> <li class=md-nav__item> <a href=#common-issues class=md-nav__link> <span class=md-ellipsis> Common Issues </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#getting-help class=md-nav__link> <span class=md-ellipsis> Getting Help </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../core-concepts/ class=md-nav__link> <span class=md-ellipsis> Core Concepts </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../configuration/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../tutorials/first-trainer.md class=md-nav__link> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../examples/vision.md class=md-nav__link> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../api/ class=md-nav__link> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../contributing.md class=md-nav__link> <span class=md-ellipsis> Community </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dream3d/dream-trainer/edit/main/dream-trainer/pages/docs/getting-started.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dream3d/dream-trainer/raw/main/dream-trainer/pages/docs/getting-started.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=getting-started-with-dream-trainer>Getting Started with Dream Trainer<a class=headerlink href=#getting-started-with-dream-trainer title="Permanent link">&para;</a></h1> <p>Welcome to Dream Trainer! This guide will help you understand what makes Dream Trainer unique and get you training models with advanced parallelism in minutes.</p> <h2 id=why-dream-trainer>Why Dream Trainer?<a class=headerlink href=#why-dream-trainer title="Permanent link">&para;</a></h2> <p>Before we dive in, let's understand what makes Dream Trainer different:</p> <h3 id=composable-mixin-architecture>🧩 <strong>Composable Mixin Architecture</strong><a class=headerlink href=#composable-mixin-architecture title="Permanent link">&para;</a></h3> <p>Unlike monolithic frameworks, Dream Trainer lets you compose exactly the features you need:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># Minimal trainer - just the essentials</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=k>class</span><span class=w> </span><span class=nc>SimpleTrainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>):</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>    <span class=k>pass</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=c1># Add features as needed</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=k>class</span><span class=w> </span><span class=nc>ProductionTrainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>,</span> <span class=n>WandBLoggerMixin</span><span class=p>,</span> 
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>                       <span class=n>EvalMetricMixin</span><span class=p>,</span> <span class=n>QuantizeMixin</span><span class=p>):</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>    <span class=k>pass</span>  <span class=c1># Now with logging, metrics, and quantization!</span>
</span></code></pre></div> <h3 id=dtensor-native-from-day-one>🚀 <strong>DTensor-Native from Day One</strong><a class=headerlink href=#dtensor-native-from-day-one title="Permanent link">&para;</a></h3> <p>Every parameter in Dream Trainer is a DTensor, giving you: - Automatic support for new PyTorch sharding patterns - Clean, debuggable distributed code - First-class support for TP, PP, CP, and FSDP2</p> <h3 id=zero-compromise-performance>⚡ <strong>Zero-Compromise Performance</strong><a class=headerlink href=#zero-compromise-performance title="Permanent link">&para;</a></h3> <ul> <li>Intelligent FSDP prefetching that traces execution order</li> <li>Loss parallelism for tensor-parallel training</li> <li>Async tensor parallelism support</li> <li>Compiled autograd integration</li> </ul> <h3 id=configs-as-code-for-type-safety>📝 <strong>Configs as Code for Type Safety</strong><a class=headerlink href=#configs-as-code-for-type-safety title="Permanent link">&para;</a></h3> <p>Dream Trainer embraces Python configs over YAML/JSON for better developer experience:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># ❌ Traditional approach - error-prone strings</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>config</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>    <span class=s2>&quot;model&quot;</span><span class=p>:</span> <span class=s2>&quot;gpt2&quot;</span><span class=p>,</span>  <span class=c1># Typo? Wrong name? Who knows!</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>    <span class=s2>&quot;lr&quot;</span><span class=p>:</span> <span class=s2>&quot;3e-4&quot;</span><span class=p>,</span>     <span class=c1># String or float? </span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>    <span class=s2>&quot;layers&quot;</span><span class=p>:</span> <span class=mi>12</span><span class=p>,</span>     <span class=c1># Is this valid for gpt2?</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=p>}</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=c1># ✅ Dream Trainer - full type safety and IDE support</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=nd>@dataclass</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=k>class</span><span class=w> </span><span class=nc>MyConfig</span><span class=p>(</span><span class=n>BaseTrainerConfig</span><span class=p>):</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>    <span class=n>learning_rate</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>3e-4</span>  <span class=c1># Type-checked!</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>    <span class=n>num_layers</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>12</span>         <span class=c1># Auto-completion!</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>    <span class=k>def</span><span class=w> </span><span class=nf>validate</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Custom validation logic&quot;&quot;&quot;</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_layers</span> <span class=o>&lt;</span> <span class=mi>1</span><span class=p>:</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;Need at least 1 layer!&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Benefits of configs as code: - <strong>Type Safety</strong>: Catch config errors at definition time, not runtime - <strong>IDE Support</strong>: Auto-completion, refactoring, and go-to-definition - <strong>Composability</strong>: Use functions, inheritance, and composition - <strong>Validation</strong>: Add custom validation logic and constraints - <strong>Documentation</strong>: Docstrings and type hints document themselves</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Example: Composable configs with validation</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=k>def</span><span class=w> </span><span class=nf>make_model_config</span><span class=p>(</span><span class=n>size</span><span class=p>:</span> <span class=n>Literal</span><span class=p>[</span><span class=s2>&quot;small&quot;</span><span class=p>,</span> <span class=s2>&quot;base&quot;</span><span class=p>,</span> <span class=s2>&quot;large&quot;</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>ModelConfig</span><span class=p>:</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Factory function for common model sizes&quot;&quot;&quot;</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>    <span class=n>sizes</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>        <span class=s2>&quot;small&quot;</span><span class=p>:</span> <span class=n>ModelConfig</span><span class=p>(</span><span class=n>hidden_size</span><span class=o>=</span><span class=mi>768</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>12</span><span class=p>),</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>        <span class=s2>&quot;base&quot;</span><span class=p>:</span> <span class=n>ModelConfig</span><span class=p>(</span><span class=n>hidden_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>24</span><span class=p>),</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>        <span class=s2>&quot;large&quot;</span><span class=p>:</span> <span class=n>ModelConfig</span><span class=p>(</span><span class=n>hidden_size</span><span class=o>=</span><span class=mi>1536</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>48</span><span class=p>),</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>    <span class=p>}</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>    <span class=k>return</span> <span class=n>sizes</span><span class=p>[</span><span class=n>size</span><span class=p>]</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=c1># Use partial functions for complex configs</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=kn>from</span><span class=w> </span><span class=nn>functools</span><span class=w> </span><span class=kn>import</span> <span class=n>partial</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=n>config</span> <span class=o>=</span> <span class=n>TrainerConfig</span><span class=p>(</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>    <span class=n>model</span><span class=o>=</span><span class=n>partial</span><span class=p>(</span><span class=n>TransformerModel</span><span class=p>,</span> <span class=n>num_heads</span><span class=o>=</span><span class=mi>16</span><span class=p>),</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a>    <span class=n>optimizer</span><span class=o>=</span><span class=n>partial</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>,</span> <span class=n>betas</span><span class=o>=</span><span class=p>(</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.95</span><span class=p>)),</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a>    <span class=n>scheduler</span><span class=o>=</span><span class=n>make_cosine_scheduler</span><span class=p>(</span><span class=n>warmup_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>),</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a><span class=p>)</span>
</span></code></pre></div> <h2 id=installation>Installation<a class=headerlink href=#installation title="Permanent link">&para;</a></h2> <p>To get started with Dream Trainer:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>pip<span class=w> </span>install<span class=w> </span>dream-trainer
</span></code></pre></div> <p>For detailed installation instructions, including: - System requirements and CUDA compatibility - Feature-specific installations (wandb, metrics, quantization, etc.) - Development setup - Docker and cluster deployments - Troubleshooting common issues</p> <p>Please see our comprehensive <a href=../installation/ >Installation Guide</a>.</p> <h2 id=your-first-trainer>Your First Trainer<a class=headerlink href=#your-first-trainer title="Permanent link">&para;</a></h2> <p>Let's build a trainer that showcases Dream Trainer's strengths:</p> <h3 id=step-1-understanding-the-mixin-pattern>Step 1: Understanding the Mixin Pattern<a class=headerlink href=#step-1-understanding-the-mixin-pattern title="Permanent link">&para;</a></h3> <p>Dream Trainer uses mixins to compose functionality. Here's the anatomy:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>BaseTrainerConfig</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.trainer.mixins</span><span class=w> </span><span class=kn>import</span> <span class=n>SetupMixin</span><span class=p>,</span> <span class=n>SetupConfigMixin</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=c1># 1. Configuration uses the same mixin pattern</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=nd>@dataclass</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=k>class</span><span class=w> </span><span class=nc>MyTrainerConfig</span><span class=p>(</span><span class=n>BaseTrainerConfig</span><span class=p>,</span> <span class=n>SetupConfigMixin</span><span class=p>):</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=c1># BaseTrainerConfig provides: epochs, batch_size, etc.</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=c1># SetupConfigMixin adds: model/optimizer/dataloader configs</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>learning_rate</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>3e-4</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=n>hidden_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>768</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=c1># 2. Trainer mirrors the config structure</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=k>class</span><span class=w> </span><span class=nc>MyTrainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>):</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a>    <span class=n>config</span><span class=p>:</span> <span class=n>MyTrainerConfig</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a>    <span class=c1># SetupMixin requires these methods:</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_models</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Define your models (on meta device - no memory used!)&quot;&quot;&quot;</span>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>TransformerModel</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>)</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a>    <span class=k>def</span><span class=w> </span><span class=nf>init_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Initialize weights after parallelism is applied&quot;&quot;&quot;</span>
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_init_weights</span><span class=p>)</span>
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a>
</span><span id=__span-4-26><a id=__codelineno-4-26 name=__codelineno-4-26 href=#__codelineno-4-26></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_optimizers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-27><a id=__codelineno-4-27 name=__codelineno-4-27 href=#__codelineno-4-27></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Define optimizers&quot;&quot;&quot;</span>
</span><span id=__span-4-28><a id=__codelineno-4-28 name=__codelineno-4-28 href=#__codelineno-4-28></a>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span>
</span><span id=__span-4-29><a id=__codelineno-4-29 name=__codelineno-4-29 href=#__codelineno-4-29></a>            <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span><span id=__span-4-30><a id=__codelineno-4-30 name=__codelineno-4-30 href=#__codelineno-4-30></a>            <span class=n>lr</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>learning_rate</span>
</span><span id=__span-4-31><a id=__codelineno-4-31 name=__codelineno-4-31 href=#__codelineno-4-31></a>        <span class=p>)</span>
</span><span id=__span-4-32><a id=__codelineno-4-32 name=__codelineno-4-32 href=#__codelineno-4-32></a>
</span><span id=__span-4-33><a id=__codelineno-4-33 name=__codelineno-4-33 href=#__codelineno-4-33></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_dataloaders</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-4-34><a id=__codelineno-4-34 name=__codelineno-4-34 href=#__codelineno-4-34></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Return train and validation dataloaders&quot;&quot;&quot;</span>
</span><span id=__span-4-35><a id=__codelineno-4-35 name=__codelineno-4-35 href=#__codelineno-4-35></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_make_train_loader</span><span class=p>(),</span> <span class=bp>self</span><span class=o>.</span><span class=n>_make_val_loader</span><span class=p>()</span>
</span><span id=__span-4-36><a id=__codelineno-4-36 name=__codelineno-4-36 href=#__codelineno-4-36></a>
</span><span id=__span-4-37><a id=__codelineno-4-37 name=__codelineno-4-37 href=#__codelineno-4-37></a>    <span class=c1># BaseTrainer requires these methods:</span>
</span><span id=__span-4-38><a id=__codelineno-4-38 name=__codelineno-4-38 href=#__codelineno-4-38></a>    <span class=k>def</span><span class=w> </span><span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-4-39><a id=__codelineno-4-39 name=__codelineno-4-39 href=#__codelineno-4-39></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Your forward pass and loss computation&quot;&quot;&quot;</span>
</span><span id=__span-4-40><a id=__codelineno-4-40 name=__codelineno-4-40 href=#__codelineno-4-40></a>        <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span><span id=__span-4-41><a id=__codelineno-4-41 name=__codelineno-4-41 href=#__codelineno-4-41></a>        <span class=bp>self</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>  <span class=c1># Handles gradient accumulation!</span>
</span><span id=__span-4-42><a id=__codelineno-4-42 name=__codelineno-4-42 href=#__codelineno-4-42></a>
</span><span id=__span-4-43><a id=__codelineno-4-43 name=__codelineno-4-43 href=#__codelineno-4-43></a>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>is_accumulating_gradients</span><span class=p>:</span>
</span><span id=__span-4-44><a id=__codelineno-4-44 name=__codelineno-4-44 href=#__codelineno-4-44></a>            <span class=n>grad_norm</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=p>)</span>
</span><span id=__span-4-45><a id=__codelineno-4-45 name=__codelineno-4-45 href=#__codelineno-4-45></a>            <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;loss&quot;</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span> <span class=s2>&quot;grad_norm&quot;</span><span class=p>:</span> <span class=n>grad_norm</span><span class=p>}</span>
</span><span id=__span-4-46><a id=__codelineno-4-46 name=__codelineno-4-46 href=#__codelineno-4-46></a>
</span><span id=__span-4-47><a id=__codelineno-4-47 name=__codelineno-4-47 href=#__codelineno-4-47></a>        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;loss&quot;</span><span class=p>:</span> <span class=n>loss</span><span class=p>}</span>
</span><span id=__span-4-48><a id=__codelineno-4-48 name=__codelineno-4-48 href=#__codelineno-4-48></a>
</span><span id=__span-4-49><a id=__codelineno-4-49 name=__codelineno-4-49 href=#__codelineno-4-49></a>    <span class=k>def</span><span class=w> </span><span class=nf>validation_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-4-50><a id=__codelineno-4-50 name=__codelineno-4-50 href=#__codelineno-4-50></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Validation forward pass&quot;&quot;&quot;</span>
</span><span id=__span-4-51><a id=__codelineno-4-51 name=__codelineno-4-51 href=#__codelineno-4-51></a>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-4-52><a id=__codelineno-4-52 name=__codelineno-4-52 href=#__codelineno-4-52></a>            <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span><span id=__span-4-53><a id=__codelineno-4-53 name=__codelineno-4-53 href=#__codelineno-4-53></a>        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;val_loss&quot;</span><span class=p>:</span> <span class=n>loss</span><span class=p>}</span>
</span></code></pre></div> <h3 id=step-2-add-advanced-parallelism>Step 2: Add Advanced Parallelism<a class=headerlink href=#step-2-add-advanced-parallelism title="Permanent link">&para;</a></h3> <p>Here's where Dream Trainer shines - adding parallelism is simple:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.configs</span><span class=w> </span><span class=kn>import</span> <span class=n>DeviceParameters</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=c1># Configure parallelism declaratively</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>config</span> <span class=o>=</span> <span class=n>MyTrainerConfig</span><span class=p>(</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>    <span class=n>device_parameters</span><span class=o>=</span><span class=n>DeviceParameters</span><span class=p>(</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>        <span class=c1># Data parallelism</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>        <span class=n>dp_shard</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>           <span class=c1># FSDP2 across 4 devices</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>        <span class=n>dp_replicate</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>       <span class=c1># DDP across 2 nodes (HSDP)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>        <span class=c1># Model parallelism  </span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>        <span class=n>tensor_parallel</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>    <span class=c1># Tensor parallel degree</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>        <span class=n>pipeline_parallel</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>  <span class=c1># Pipeline stages</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>        <span class=n>context_parallel</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>   <span class=c1># For long sequences</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>        <span class=c1># Optimizations</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>        <span class=n>async_tensor_parallel</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>        <span class=n>compile_model</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>        <span class=n>loss_parallel</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>    <span class=p>)</span>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a><span class=p>)</span>
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a>
</span><span id=__span-5-22><a id=__codelineno-5-22 name=__codelineno-5-22 href=#__codelineno-5-22></a><span class=c1># That&#39;s it! Dream Trainer handles all the complexity</span>
</span></code></pre></div> <h3 id=step-3-implement-parallelism-methods>Step 3: Implement Parallelism Methods<a class=headerlink href=#step-3-implement-parallelism-methods title="Permanent link">&para;</a></h3> <p>For advanced parallelism, implement these methods in your trainer:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=k>class</span><span class=w> </span><span class=nc>MyTrainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>):</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>    <span class=c1># ... previous methods ...</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=k>def</span><span class=w> </span><span class=nf>apply_tensor_parallel</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tp_mesh</span><span class=p>):</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Apply tensor parallelism to your model&quot;&quot;&quot;</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>        <span class=c1># Dream Trainer provides the mesh, you decide the sharding</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>        <span class=kn>from</span><span class=w> </span><span class=nn>torch.distributed.tensor.parallel</span><span class=w> </span><span class=kn>import</span> <span class=n>ColwiseParallel</span><span class=p>,</span> <span class=n>RowwiseParallel</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>        <span class=c1># Parallelize attention layers</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>        <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>layers</span><span class=p>:</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>            <span class=n>tp_plan</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>                <span class=s2>&quot;attention.wq&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>                <span class=s2>&quot;attention.wk&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span> 
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>                <span class=s2>&quot;attention.wv&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>                <span class=s2>&quot;attention.wo&quot;</span><span class=p>:</span> <span class=n>RowwiseParallel</span><span class=p>(),</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>            <span class=p>}</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>            <span class=n>parallelize_module</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>tp_mesh</span><span class=p>,</span> <span class=n>tp_plan</span><span class=p>)</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>    <span class=k>def</span><span class=w> </span><span class=nf>apply_pipeline_parallel</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>pp_mesh</span><span class=p>):</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Split model into pipeline stages&quot;&quot;&quot;</span>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a>        <span class=c1># Return pipeline schedule and split modules</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>        <span class=n>stages</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a>            <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>embed</span><span class=p>,</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>            <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>layers</span><span class=p>[:</span><span class=mi>8</span><span class=p>],</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a>            <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>layers</span><span class=p>[</span><span class=mi>8</span><span class=p>:</span><span class=mi>16</span><span class=p>],</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>            <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>output</span>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>        <span class=p>]</span>
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a>        <span class=kn>from</span><span class=w> </span><span class=nn>torch.distributed.pipelining</span><span class=w> </span><span class=kn>import</span> <span class=n>pipeline_parallel</span>
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a>        <span class=n>schedule</span> <span class=o>=</span> <span class=n>pipeline_parallel</span><span class=p>(</span><span class=n>stages</span><span class=p>,</span> <span class=n>pp_mesh</span><span class=p>)</span>
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a>
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a>        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;model&quot;</span><span class=p>:</span> <span class=p>(</span><span class=n>schedule</span><span class=p>,</span> <span class=n>stages</span><span class=p>,</span> <span class=kc>True</span><span class=p>,</span> <span class=kc>True</span><span class=p>)}</span>
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a>
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a>    <span class=k>def</span><span class=w> </span><span class=nf>apply_fully_shard</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>fsdp_config</span><span class=p>):</span>
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Apply FSDP2 sharding&quot;&quot;&quot;</span>
</span><span id=__span-6-36><a id=__codelineno-6-36 name=__codelineno-6-36 href=#__codelineno-6-36></a>        <span class=kn>from</span><span class=w> </span><span class=nn>torch.distributed._composable.fsdp</span><span class=w> </span><span class=kn>import</span> <span class=n>fully_shard</span>
</span><span id=__span-6-37><a id=__codelineno-6-37 name=__codelineno-6-37 href=#__codelineno-6-37></a>
</span><span id=__span-6-38><a id=__codelineno-6-38 name=__codelineno-6-38 href=#__codelineno-6-38></a>        <span class=c1># Shard each transformer layer</span>
</span><span id=__span-6-39><a id=__codelineno-6-39 name=__codelineno-6-39 href=#__codelineno-6-39></a>        <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>layers</span><span class=p>:</span>
</span><span id=__span-6-40><a id=__codelineno-6-40 name=__codelineno-6-40 href=#__codelineno-6-40></a>            <span class=n>fully_shard</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=o>**</span><span class=n>fsdp_config</span><span class=p>)</span>
</span><span id=__span-6-41><a id=__codelineno-6-41 name=__codelineno-6-41 href=#__codelineno-6-41></a>
</span><span id=__span-6-42><a id=__codelineno-6-42 name=__codelineno-6-42 href=#__codelineno-6-42></a>        <span class=c1># Shard the whole model</span>
</span><span id=__span-6-43><a id=__codelineno-6-43 name=__codelineno-6-43 href=#__codelineno-6-43></a>        <span class=n>fully_shard</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>,</span> <span class=o>**</span><span class=n>fsdp_config</span><span class=p>)</span>
</span></code></pre></div> <h2 id=complete-example-multi-gpu-language-model>Complete Example: Multi-GPU Language Model<a class=headerlink href=#complete-example-multi-gpu-language-model title="Permanent link">&para;</a></h2> <p>Let's put it all together with a realistic example:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span><span class=p>,</span> <span class=n>field</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>DataLoader</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>DreamTrainer</span><span class=p>,</span> <span class=n>DreamTrainerConfig</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=p>(</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=n>LoggerCallback</span><span class=p>,</span> 
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=n>CheckpointCallback</span><span class=p>,</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>    <span class=n>OptimizeFSDP</span><span class=p>,</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>    <span class=n>CallbackCollection</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=p>)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.configs</span><span class=w> </span><span class=kn>import</span> <span class=p>(</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=n>DeviceParameters</span><span class=p>,</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>    <span class=n>CheckpointParameters</span><span class=p>,</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>    <span class=n>TrainingParameters</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=p>)</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a><span class=nd>@dataclass</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a><span class=k>class</span><span class=w> </span><span class=nc>LMConfig</span><span class=p>(</span><span class=n>DreamTrainerConfig</span><span class=p>):</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>    <span class=c1># Model architecture</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>    <span class=n>vocab_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>50257</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>    <span class=n>hidden_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>768</span>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>    <span class=n>num_layers</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>12</span>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>    <span class=n>num_heads</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>12</span>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a>    <span class=c1># Training</span>
</span><span id=__span-7-28><a id=__codelineno-7-28 name=__codelineno-7-28 href=#__codelineno-7-28></a>    <span class=n>learning_rate</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>3e-4</span>
</span><span id=__span-7-29><a id=__codelineno-7-29 name=__codelineno-7-29 href=#__codelineno-7-29></a>    <span class=n>warmup_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1000</span>
</span><span id=__span-7-30><a id=__codelineno-7-30 name=__codelineno-7-30 href=#__codelineno-7-30></a>    <span class=n>weight_decay</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.1</span>
</span><span id=__span-7-31><a id=__codelineno-7-31 name=__codelineno-7-31 href=#__codelineno-7-31></a>
</span><span id=__span-7-32><a id=__codelineno-7-32 name=__codelineno-7-32 href=#__codelineno-7-32></a>    <span class=c1># Data</span>
</span><span id=__span-7-33><a id=__codelineno-7-33 name=__codelineno-7-33 href=#__codelineno-7-33></a>    <span class=n>sequence_length</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>2048</span>
</span><span id=__span-7-34><a id=__codelineno-7-34 name=__codelineno-7-34 href=#__codelineno-7-34></a>    <span class=n>dataset_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;data/openwebtext&quot;</span>
</span><span id=__span-7-35><a id=__codelineno-7-35 name=__codelineno-7-35 href=#__codelineno-7-35></a>
</span><span id=__span-7-36><a id=__codelineno-7-36 name=__codelineno-7-36 href=#__codelineno-7-36></a><span class=k>class</span><span class=w> </span><span class=nc>LanguageModelTrainer</span><span class=p>(</span><span class=n>DreamTrainer</span><span class=p>):</span>
</span><span id=__span-7-37><a id=__codelineno-7-37 name=__codelineno-7-37 href=#__codelineno-7-37></a>    <span class=n>config</span><span class=p>:</span> <span class=n>LMConfig</span>
</span><span id=__span-7-38><a id=__codelineno-7-38 name=__codelineno-7-38 href=#__codelineno-7-38></a>
</span><span id=__span-7-39><a id=__codelineno-7-39 name=__codelineno-7-39 href=#__codelineno-7-39></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_models</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-7-40><a id=__codelineno-7-40 name=__codelineno-7-40 href=#__codelineno-7-40></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Models are created on meta device - no memory used!&quot;&quot;&quot;</span>
</span><span id=__span-7-41><a id=__codelineno-7-41 name=__codelineno-7-41 href=#__codelineno-7-41></a>        <span class=kn>from</span><span class=w> </span><span class=nn>my_models</span><span class=w> </span><span class=kn>import</span> <span class=n>GPTModel</span>
</span><span id=__span-7-42><a id=__codelineno-7-42 name=__codelineno-7-42 href=#__codelineno-7-42></a>
</span><span id=__span-7-43><a id=__codelineno-7-43 name=__codelineno-7-43 href=#__codelineno-7-43></a>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>GPTModel</span><span class=p>(</span>
</span><span id=__span-7-44><a id=__codelineno-7-44 name=__codelineno-7-44 href=#__codelineno-7-44></a>            <span class=n>vocab_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>vocab_size</span><span class=p>,</span>
</span><span id=__span-7-45><a id=__codelineno-7-45 name=__codelineno-7-45 href=#__codelineno-7-45></a>            <span class=n>hidden_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span>
</span><span id=__span-7-46><a id=__codelineno-7-46 name=__codelineno-7-46 href=#__codelineno-7-46></a>            <span class=n>num_layers</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>num_layers</span><span class=p>,</span>
</span><span id=__span-7-47><a id=__codelineno-7-47 name=__codelineno-7-47 href=#__codelineno-7-47></a>            <span class=n>num_heads</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>num_heads</span><span class=p>,</span>
</span><span id=__span-7-48><a id=__codelineno-7-48 name=__codelineno-7-48 href=#__codelineno-7-48></a>        <span class=p>)</span>
</span><span id=__span-7-49><a id=__codelineno-7-49 name=__codelineno-7-49 href=#__codelineno-7-49></a>
</span><span id=__span-7-50><a id=__codelineno-7-50 name=__codelineno-7-50 href=#__codelineno-7-50></a>    <span class=k>def</span><span class=w> </span><span class=nf>init_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-7-51><a id=__codelineno-7-51 name=__codelineno-7-51 href=#__codelineno-7-51></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Initialize after parallelism is applied&quot;&quot;&quot;</span>
</span><span id=__span-7-52><a id=__codelineno-7-52 name=__codelineno-7-52 href=#__codelineno-7-52></a>        <span class=k>def</span><span class=w> </span><span class=nf>_init_weights</span><span class=p>(</span><span class=n>module</span><span class=p>):</span>
</span><span id=__span-7-53><a id=__codelineno-7-53 name=__codelineno-7-53 href=#__codelineno-7-53></a>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span><span id=__span-7-54><a id=__codelineno-7-54 name=__codelineno-7-54 href=#__codelineno-7-54></a>                <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-7-55><a id=__codelineno-7-55 name=__codelineno-7-55 href=#__codelineno-7-55></a>                <span class=k>if</span> <span class=n>module</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-7-56><a id=__codelineno-7-56 name=__codelineno-7-56 href=#__codelineno-7-56></a>                    <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span><span id=__span-7-57><a id=__codelineno-7-57 name=__codelineno-7-57 href=#__codelineno-7-57></a>
</span><span id=__span-7-58><a id=__codelineno-7-58 name=__codelineno-7-58 href=#__codelineno-7-58></a>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>_init_weights</span><span class=p>)</span>
</span><span id=__span-7-59><a id=__codelineno-7-59 name=__codelineno-7-59 href=#__codelineno-7-59></a>
</span><span id=__span-7-60><a id=__codelineno-7-60 name=__codelineno-7-60 href=#__codelineno-7-60></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_optimizers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-7-61><a id=__codelineno-7-61 name=__codelineno-7-61 href=#__codelineno-7-61></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Configure AdamW with weight decay&quot;&quot;&quot;</span>
</span><span id=__span-7-62><a id=__codelineno-7-62 name=__codelineno-7-62 href=#__codelineno-7-62></a>        <span class=c1># Separate parameters for weight decay</span>
</span><span id=__span-7-63><a id=__codelineno-7-63 name=__codelineno-7-63 href=#__codelineno-7-63></a>        <span class=n>decay_params</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-7-64><a id=__codelineno-7-64 name=__codelineno-7-64 href=#__codelineno-7-64></a>        <span class=n>no_decay_params</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-7-65><a id=__codelineno-7-65 name=__codelineno-7-65 href=#__codelineno-7-65></a>
</span><span id=__span-7-66><a id=__codelineno-7-66 name=__codelineno-7-66 href=#__codelineno-7-66></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-7-67><a id=__codelineno-7-67 name=__codelineno-7-67 href=#__codelineno-7-67></a>            <span class=k>if</span> <span class=s1>&#39;bias&#39;</span> <span class=ow>in</span> <span class=n>name</span> <span class=ow>or</span> <span class=s1>&#39;norm&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span><span id=__span-7-68><a id=__codelineno-7-68 name=__codelineno-7-68 href=#__codelineno-7-68></a>                <span class=n>no_decay_params</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>param</span><span class=p>)</span>
</span><span id=__span-7-69><a id=__codelineno-7-69 name=__codelineno-7-69 href=#__codelineno-7-69></a>            <span class=k>else</span><span class=p>:</span>
</span><span id=__span-7-70><a id=__codelineno-7-70 name=__codelineno-7-70 href=#__codelineno-7-70></a>                <span class=n>decay_params</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>param</span><span class=p>)</span>
</span><span id=__span-7-71><a id=__codelineno-7-71 name=__codelineno-7-71 href=#__codelineno-7-71></a>
</span><span id=__span-7-72><a id=__codelineno-7-72 name=__codelineno-7-72 href=#__codelineno-7-72></a>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>([</span>
</span><span id=__span-7-73><a id=__codelineno-7-73 name=__codelineno-7-73 href=#__codelineno-7-73></a>            <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>decay_params</span><span class=p>,</span> <span class=s1>&#39;weight_decay&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>weight_decay</span><span class=p>},</span>
</span><span id=__span-7-74><a id=__codelineno-7-74 name=__codelineno-7-74 href=#__codelineno-7-74></a>            <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>no_decay_params</span><span class=p>,</span> <span class=s1>&#39;weight_decay&#39;</span><span class=p>:</span> <span class=mf>0.0</span><span class=p>}</span>
</span><span id=__span-7-75><a id=__codelineno-7-75 name=__codelineno-7-75 href=#__codelineno-7-75></a>        <span class=p>],</span> <span class=n>lr</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>learning_rate</span><span class=p>)</span>
</span><span id=__span-7-76><a id=__codelineno-7-76 name=__codelineno-7-76 href=#__codelineno-7-76></a>
</span><span id=__span-7-77><a id=__codelineno-7-77 name=__codelineno-7-77 href=#__codelineno-7-77></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_schedulers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-7-78><a id=__codelineno-7-78 name=__codelineno-7-78 href=#__codelineno-7-78></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Cosine schedule with warmup&quot;&quot;&quot;</span>
</span><span id=__span-7-79><a id=__codelineno-7-79 name=__codelineno-7-79 href=#__codelineno-7-79></a>        <span class=kn>from</span><span class=w> </span><span class=nn>torch.optim.lr_scheduler</span><span class=w> </span><span class=kn>import</span> <span class=n>CosineAnnealingLR</span>
</span><span id=__span-7-80><a id=__codelineno-7-80 name=__codelineno-7-80 href=#__codelineno-7-80></a>
</span><span id=__span-7-81><a id=__codelineno-7-81 name=__codelineno-7-81 href=#__codelineno-7-81></a>        <span class=bp>self</span><span class=o>.</span><span class=n>scheduler</span> <span class=o>=</span> <span class=n>CosineAnnealingLR</span><span class=p>(</span>
</span><span id=__span-7-82><a id=__codelineno-7-82 name=__codelineno-7-82 href=#__codelineno-7-82></a>            <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=p>,</span>
</span><span id=__span-7-83><a id=__codelineno-7-83 name=__codelineno-7-83 href=#__codelineno-7-83></a>            <span class=n>T_max</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>training_parameters</span><span class=o>.</span><span class=n>n_epochs</span><span class=p>,</span>
</span><span id=__span-7-84><a id=__codelineno-7-84 name=__codelineno-7-84 href=#__codelineno-7-84></a>            <span class=n>eta_min</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>learning_rate</span> <span class=o>*</span> <span class=mf>0.1</span>
</span><span id=__span-7-85><a id=__codelineno-7-85 name=__codelineno-7-85 href=#__codelineno-7-85></a>        <span class=p>)</span>
</span><span id=__span-7-86><a id=__codelineno-7-86 name=__codelineno-7-86 href=#__codelineno-7-86></a>
</span><span id=__span-7-87><a id=__codelineno-7-87 name=__codelineno-7-87 href=#__codelineno-7-87></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_dataloaders</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-7-88><a id=__codelineno-7-88 name=__codelineno-7-88 href=#__codelineno-7-88></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Create distributed dataloaders&quot;&quot;&quot;</span>
</span><span id=__span-7-89><a id=__codelineno-7-89 name=__codelineno-7-89 href=#__codelineno-7-89></a>        <span class=kn>from</span><span class=w> </span><span class=nn>my_data</span><span class=w> </span><span class=kn>import</span> <span class=n>TextDataset</span>
</span><span id=__span-7-90><a id=__codelineno-7-90 name=__codelineno-7-90 href=#__codelineno-7-90></a>
</span><span id=__span-7-91><a id=__codelineno-7-91 name=__codelineno-7-91 href=#__codelineno-7-91></a>        <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>TextDataset</span><span class=p>(</span>
</span><span id=__span-7-92><a id=__codelineno-7-92 name=__codelineno-7-92 href=#__codelineno-7-92></a>            <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span>
</span><span id=__span-7-93><a id=__codelineno-7-93 name=__codelineno-7-93 href=#__codelineno-7-93></a>            <span class=n>sequence_length</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>sequence_length</span><span class=p>,</span>
</span><span id=__span-7-94><a id=__codelineno-7-94 name=__codelineno-7-94 href=#__codelineno-7-94></a>            <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span>
</span><span id=__span-7-95><a id=__codelineno-7-95 name=__codelineno-7-95 href=#__codelineno-7-95></a>        <span class=p>)</span>
</span><span id=__span-7-96><a id=__codelineno-7-96 name=__codelineno-7-96 href=#__codelineno-7-96></a>
</span><span id=__span-7-97><a id=__codelineno-7-97 name=__codelineno-7-97 href=#__codelineno-7-97></a>        <span class=c1># Dream Trainer provides distributed sampling utilities</span>
</span><span id=__span-7-98><a id=__codelineno-7-98 name=__codelineno-7-98 href=#__codelineno-7-98></a>        <span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span><span id=__span-7-99><a id=__codelineno-7-99 name=__codelineno-7-99 href=#__codelineno-7-99></a>            <span class=n>train_dataset</span><span class=p>,</span>
</span><span id=__span-7-100><a id=__codelineno-7-100 name=__codelineno-7-100 href=#__codelineno-7-100></a>            <span class=n>batch_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>training_parameters</span><span class=o>.</span><span class=n>train_batch_size</span><span class=p>,</span>
</span><span id=__span-7-101><a id=__codelineno-7-101 name=__codelineno-7-101 href=#__codelineno-7-101></a>            <span class=n>sampler</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>get_train_sampler</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>),</span>  <span class=c1># Handles DP/PP</span>
</span><span id=__span-7-102><a id=__codelineno-7-102 name=__codelineno-7-102 href=#__codelineno-7-102></a>            <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span><span id=__span-7-103><a id=__codelineno-7-103 name=__codelineno-7-103 href=#__codelineno-7-103></a>            <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-7-104><a id=__codelineno-7-104 name=__codelineno-7-104 href=#__codelineno-7-104></a>        <span class=p>)</span>
</span><span id=__span-7-105><a id=__codelineno-7-105 name=__codelineno-7-105 href=#__codelineno-7-105></a>
</span><span id=__span-7-106><a id=__codelineno-7-106 name=__codelineno-7-106 href=#__codelineno-7-106></a>        <span class=n>val_dataset</span> <span class=o>=</span> <span class=n>TextDataset</span><span class=p>(</span>
</span><span id=__span-7-107><a id=__codelineno-7-107 name=__codelineno-7-107 href=#__codelineno-7-107></a>            <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span>
</span><span id=__span-7-108><a id=__codelineno-7-108 name=__codelineno-7-108 href=#__codelineno-7-108></a>            <span class=n>sequence_length</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>sequence_length</span><span class=p>,</span>
</span><span id=__span-7-109><a id=__codelineno-7-109 name=__codelineno-7-109 href=#__codelineno-7-109></a>            <span class=n>split</span><span class=o>=</span><span class=s1>&#39;validation&#39;</span>
</span><span id=__span-7-110><a id=__codelineno-7-110 name=__codelineno-7-110 href=#__codelineno-7-110></a>        <span class=p>)</span>
</span><span id=__span-7-111><a id=__codelineno-7-111 name=__codelineno-7-111 href=#__codelineno-7-111></a>
</span><span id=__span-7-112><a id=__codelineno-7-112 name=__codelineno-7-112 href=#__codelineno-7-112></a>        <span class=n>val_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span><span id=__span-7-113><a id=__codelineno-7-113 name=__codelineno-7-113 href=#__codelineno-7-113></a>            <span class=n>val_dataset</span><span class=p>,</span>
</span><span id=__span-7-114><a id=__codelineno-7-114 name=__codelineno-7-114 href=#__codelineno-7-114></a>            <span class=n>batch_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>training_parameters</span><span class=o>.</span><span class=n>train_batch_size</span> <span class=o>*</span> <span class=mi>2</span><span class=p>,</span>
</span><span id=__span-7-115><a id=__codelineno-7-115 name=__codelineno-7-115 href=#__codelineno-7-115></a>            <span class=n>sampler</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>get_val_sampler</span><span class=p>(</span><span class=n>val_dataset</span><span class=p>),</span>
</span><span id=__span-7-116><a id=__codelineno-7-116 name=__codelineno-7-116 href=#__codelineno-7-116></a>            <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span><span id=__span-7-117><a id=__codelineno-7-117 name=__codelineno-7-117 href=#__codelineno-7-117></a>            <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-7-118><a id=__codelineno-7-118 name=__codelineno-7-118 href=#__codelineno-7-118></a>        <span class=p>)</span>
</span><span id=__span-7-119><a id=__codelineno-7-119 name=__codelineno-7-119 href=#__codelineno-7-119></a>
</span><span id=__span-7-120><a id=__codelineno-7-120 name=__codelineno-7-120 href=#__codelineno-7-120></a>        <span class=k>return</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>val_loader</span>
</span><span id=__span-7-121><a id=__codelineno-7-121 name=__codelineno-7-121 href=#__codelineno-7-121></a>
</span><span id=__span-7-122><a id=__codelineno-7-122 name=__codelineno-7-122 href=#__codelineno-7-122></a>    <span class=k>def</span><span class=w> </span><span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-7-123><a id=__codelineno-7-123 name=__codelineno-7-123 href=#__codelineno-7-123></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Forward pass with next-token prediction&quot;&quot;&quot;</span>
</span><span id=__span-7-124><a id=__codelineno-7-124 name=__codelineno-7-124 href=#__codelineno-7-124></a>        <span class=n>input_ids</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span>
</span><span id=__span-7-125><a id=__codelineno-7-125 name=__codelineno-7-125 href=#__codelineno-7-125></a>
</span><span id=__span-7-126><a id=__codelineno-7-126 name=__codelineno-7-126 href=#__codelineno-7-126></a>        <span class=c1># Forward pass</span>
</span><span id=__span-7-127><a id=__codelineno-7-127 name=__codelineno-7-127 href=#__codelineno-7-127></a>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=p>)</span>
</span><span id=__span-7-128><a id=__codelineno-7-128 name=__codelineno-7-128 href=#__codelineno-7-128></a>
</span><span id=__span-7-129><a id=__codelineno-7-129 name=__codelineno-7-129 href=#__codelineno-7-129></a>        <span class=c1># Shift for next-token prediction</span>
</span><span id=__span-7-130><a id=__codelineno-7-130 name=__codelineno-7-130 href=#__codelineno-7-130></a>        <span class=n>shift_logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span><span id=__span-7-131><a id=__codelineno-7-131 name=__codelineno-7-131 href=#__codelineno-7-131></a>        <span class=n>shift_labels</span> <span class=o>=</span> <span class=n>input_ids</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>1</span><span class=p>:]</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span><span id=__span-7-132><a id=__codelineno-7-132 name=__codelineno-7-132 href=#__codelineno-7-132></a>
</span><span id=__span-7-133><a id=__codelineno-7-133 name=__codelineno-7-133 href=#__codelineno-7-133></a>        <span class=c1># Loss computation with optional loss parallelism</span>
</span><span id=__span-7-134><a id=__codelineno-7-134 name=__codelineno-7-134 href=#__codelineno-7-134></a>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>loss_parallel</span><span class=p>():</span>
</span><span id=__span-7-135><a id=__codelineno-7-135 name=__codelineno-7-135 href=#__codelineno-7-135></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span>
</span><span id=__span-7-136><a id=__codelineno-7-136 name=__codelineno-7-136 href=#__codelineno-7-136></a>                <span class=n>shift_logits</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>shift_logits</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)),</span>
</span><span id=__span-7-137><a id=__codelineno-7-137 name=__codelineno-7-137 href=#__codelineno-7-137></a>                <span class=n>shift_labels</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-7-138><a id=__codelineno-7-138 name=__codelineno-7-138 href=#__codelineno-7-138></a>            <span class=p>)</span>
</span><span id=__span-7-139><a id=__codelineno-7-139 name=__codelineno-7-139 href=#__codelineno-7-139></a>
</span><span id=__span-7-140><a id=__codelineno-7-140 name=__codelineno-7-140 href=#__codelineno-7-140></a>        <span class=c1># Backward handles gradient accumulation automatically</span>
</span><span id=__span-7-141><a id=__codelineno-7-141 name=__codelineno-7-141 href=#__codelineno-7-141></a>        <span class=bp>self</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span><span id=__span-7-142><a id=__codelineno-7-142 name=__codelineno-7-142 href=#__codelineno-7-142></a>
</span><span id=__span-7-143><a id=__codelineno-7-143 name=__codelineno-7-143 href=#__codelineno-7-143></a>        <span class=c1># Step optimizer only when not accumulating</span>
</span><span id=__span-7-144><a id=__codelineno-7-144 name=__codelineno-7-144 href=#__codelineno-7-144></a>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>is_accumulating_gradients</span><span class=p>:</span>
</span><span id=__span-7-145><a id=__codelineno-7-145 name=__codelineno-7-145 href=#__codelineno-7-145></a>            <span class=n>grad_norm</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=p>)</span>
</span><span id=__span-7-146><a id=__codelineno-7-146 name=__codelineno-7-146 href=#__codelineno-7-146></a>
</span><span id=__span-7-147><a id=__codelineno-7-147 name=__codelineno-7-147 href=#__codelineno-7-147></a>            <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-7-148><a id=__codelineno-7-148 name=__codelineno-7-148 href=#__codelineno-7-148></a>                <span class=s2>&quot;loss&quot;</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span>
</span><span id=__span-7-149><a id=__codelineno-7-149 name=__codelineno-7-149 href=#__codelineno-7-149></a>                <span class=s2>&quot;grad_norm&quot;</span><span class=p>:</span> <span class=n>grad_norm</span><span class=p>,</span>
</span><span id=__span-7-150><a id=__codelineno-7-150 name=__codelineno-7-150 href=#__codelineno-7-150></a>                <span class=s2>&quot;learning_rate&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;lr&#39;</span><span class=p>],</span>
</span><span id=__span-7-151><a id=__codelineno-7-151 name=__codelineno-7-151 href=#__codelineno-7-151></a>            <span class=p>}</span>
</span><span id=__span-7-152><a id=__codelineno-7-152 name=__codelineno-7-152 href=#__codelineno-7-152></a>
</span><span id=__span-7-153><a id=__codelineno-7-153 name=__codelineno-7-153 href=#__codelineno-7-153></a>        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;loss&quot;</span><span class=p>:</span> <span class=n>loss</span><span class=p>}</span>
</span><span id=__span-7-154><a id=__codelineno-7-154 name=__codelineno-7-154 href=#__codelineno-7-154></a>
</span><span id=__span-7-155><a id=__codelineno-7-155 name=__codelineno-7-155 href=#__codelineno-7-155></a>    <span class=k>def</span><span class=w> </span><span class=nf>validation_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-7-156><a id=__codelineno-7-156 name=__codelineno-7-156 href=#__codelineno-7-156></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute validation perplexity&quot;&quot;&quot;</span>
</span><span id=__span-7-157><a id=__codelineno-7-157 name=__codelineno-7-157 href=#__codelineno-7-157></a>        <span class=n>input_ids</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span>
</span><span id=__span-7-158><a id=__codelineno-7-158 name=__codelineno-7-158 href=#__codelineno-7-158></a>
</span><span id=__span-7-159><a id=__codelineno-7-159 name=__codelineno-7-159 href=#__codelineno-7-159></a>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-7-160><a id=__codelineno-7-160 name=__codelineno-7-160 href=#__codelineno-7-160></a>            <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=p>)</span>
</span><span id=__span-7-161><a id=__codelineno-7-161 name=__codelineno-7-161 href=#__codelineno-7-161></a>
</span><span id=__span-7-162><a id=__codelineno-7-162 name=__codelineno-7-162 href=#__codelineno-7-162></a>            <span class=n>shift_logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span><span id=__span-7-163><a id=__codelineno-7-163 name=__codelineno-7-163 href=#__codelineno-7-163></a>            <span class=n>shift_labels</span> <span class=o>=</span> <span class=n>input_ids</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>1</span><span class=p>:]</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span><span id=__span-7-164><a id=__codelineno-7-164 name=__codelineno-7-164 href=#__codelineno-7-164></a>
</span><span id=__span-7-165><a id=__codelineno-7-165 name=__codelineno-7-165 href=#__codelineno-7-165></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span>
</span><span id=__span-7-166><a id=__codelineno-7-166 name=__codelineno-7-166 href=#__codelineno-7-166></a>                <span class=n>shift_logits</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>shift_logits</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)),</span>
</span><span id=__span-7-167><a id=__codelineno-7-167 name=__codelineno-7-167 href=#__codelineno-7-167></a>                <span class=n>shift_labels</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-7-168><a id=__codelineno-7-168 name=__codelineno-7-168 href=#__codelineno-7-168></a>            <span class=p>)</span>
</span><span id=__span-7-169><a id=__codelineno-7-169 name=__codelineno-7-169 href=#__codelineno-7-169></a>
</span><span id=__span-7-170><a id=__codelineno-7-170 name=__codelineno-7-170 href=#__codelineno-7-170></a>            <span class=n>perplexity</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span><span id=__span-7-171><a id=__codelineno-7-171 name=__codelineno-7-171 href=#__codelineno-7-171></a>
</span><span id=__span-7-172><a id=__codelineno-7-172 name=__codelineno-7-172 href=#__codelineno-7-172></a>        <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-7-173><a id=__codelineno-7-173 name=__codelineno-7-173 href=#__codelineno-7-173></a>            <span class=s2>&quot;val_loss&quot;</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span>
</span><span id=__span-7-174><a id=__codelineno-7-174 name=__codelineno-7-174 href=#__codelineno-7-174></a>            <span class=s2>&quot;val_perplexity&quot;</span><span class=p>:</span> <span class=n>perplexity</span><span class=p>,</span>
</span><span id=__span-7-175><a id=__codelineno-7-175 name=__codelineno-7-175 href=#__codelineno-7-175></a>        <span class=p>}</span>
</span><span id=__span-7-176><a id=__codelineno-7-176 name=__codelineno-7-176 href=#__codelineno-7-176></a>
</span><span id=__span-7-177><a id=__codelineno-7-177 name=__codelineno-7-177 href=#__codelineno-7-177></a>    <span class=k>def</span><span class=w> </span><span class=nf>apply_tensor_parallel</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tp_mesh</span><span class=p>):</span>
</span><span id=__span-7-178><a id=__codelineno-7-178 name=__codelineno-7-178 href=#__codelineno-7-178></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Apply tensor parallelism to transformer layers&quot;&quot;&quot;</span>
</span><span id=__span-7-179><a id=__codelineno-7-179 name=__codelineno-7-179 href=#__codelineno-7-179></a>        <span class=kn>from</span><span class=w> </span><span class=nn>torch.distributed.tensor.parallel</span><span class=w> </span><span class=kn>import</span> <span class=p>(</span>
</span><span id=__span-7-180><a id=__codelineno-7-180 name=__codelineno-7-180 href=#__codelineno-7-180></a>            <span class=n>ColwiseParallel</span><span class=p>,</span> 
</span><span id=__span-7-181><a id=__codelineno-7-181 name=__codelineno-7-181 href=#__codelineno-7-181></a>            <span class=n>RowwiseParallel</span><span class=p>,</span>
</span><span id=__span-7-182><a id=__codelineno-7-182 name=__codelineno-7-182 href=#__codelineno-7-182></a>            <span class=n>PrepareModuleInput</span><span class=p>,</span>
</span><span id=__span-7-183><a id=__codelineno-7-183 name=__codelineno-7-183 href=#__codelineno-7-183></a>            <span class=n>parallelize_module</span>
</span><span id=__span-7-184><a id=__codelineno-7-184 name=__codelineno-7-184 href=#__codelineno-7-184></a>        <span class=p>)</span>
</span><span id=__span-7-185><a id=__codelineno-7-185 name=__codelineno-7-185 href=#__codelineno-7-185></a>
</span><span id=__span-7-186><a id=__codelineno-7-186 name=__codelineno-7-186 href=#__codelineno-7-186></a>        <span class=c1># Parallelize each transformer block</span>
</span><span id=__span-7-187><a id=__codelineno-7-187 name=__codelineno-7-187 href=#__codelineno-7-187></a>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>block</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>blocks</span><span class=p>):</span>
</span><span id=__span-7-188><a id=__codelineno-7-188 name=__codelineno-7-188 href=#__codelineno-7-188></a>            <span class=n>layer_plan</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-7-189><a id=__codelineno-7-189 name=__codelineno-7-189 href=#__codelineno-7-189></a>                <span class=c1># Attention</span>
</span><span id=__span-7-190><a id=__codelineno-7-190 name=__codelineno-7-190 href=#__codelineno-7-190></a>                <span class=s2>&quot;attn.q_proj&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span>
</span><span id=__span-7-191><a id=__codelineno-7-191 name=__codelineno-7-191 href=#__codelineno-7-191></a>                <span class=s2>&quot;attn.k_proj&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span> 
</span><span id=__span-7-192><a id=__codelineno-7-192 name=__codelineno-7-192 href=#__codelineno-7-192></a>                <span class=s2>&quot;attn.v_proj&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span>
</span><span id=__span-7-193><a id=__codelineno-7-193 name=__codelineno-7-193 href=#__codelineno-7-193></a>                <span class=s2>&quot;attn.out_proj&quot;</span><span class=p>:</span> <span class=n>RowwiseParallel</span><span class=p>(),</span>
</span><span id=__span-7-194><a id=__codelineno-7-194 name=__codelineno-7-194 href=#__codelineno-7-194></a>
</span><span id=__span-7-195><a id=__codelineno-7-195 name=__codelineno-7-195 href=#__codelineno-7-195></a>                <span class=c1># MLP</span>
</span><span id=__span-7-196><a id=__codelineno-7-196 name=__codelineno-7-196 href=#__codelineno-7-196></a>                <span class=s2>&quot;mlp.up_proj&quot;</span><span class=p>:</span> <span class=n>ColwiseParallel</span><span class=p>(),</span>
</span><span id=__span-7-197><a id=__codelineno-7-197 name=__codelineno-7-197 href=#__codelineno-7-197></a>                <span class=s2>&quot;mlp.down_proj&quot;</span><span class=p>:</span> <span class=n>RowwiseParallel</span><span class=p>(),</span>
</span><span id=__span-7-198><a id=__codelineno-7-198 name=__codelineno-7-198 href=#__codelineno-7-198></a>            <span class=p>}</span>
</span><span id=__span-7-199><a id=__codelineno-7-199 name=__codelineno-7-199 href=#__codelineno-7-199></a>
</span><span id=__span-7-200><a id=__codelineno-7-200 name=__codelineno-7-200 href=#__codelineno-7-200></a>            <span class=n>parallelize_module</span><span class=p>(</span>
</span><span id=__span-7-201><a id=__codelineno-7-201 name=__codelineno-7-201 href=#__codelineno-7-201></a>                <span class=n>block</span><span class=p>,</span>
</span><span id=__span-7-202><a id=__codelineno-7-202 name=__codelineno-7-202 href=#__codelineno-7-202></a>                <span class=n>tp_mesh</span><span class=p>,</span>
</span><span id=__span-7-203><a id=__codelineno-7-203 name=__codelineno-7-203 href=#__codelineno-7-203></a>                <span class=n>layer_plan</span><span class=p>,</span>
</span><span id=__span-7-204><a id=__codelineno-7-204 name=__codelineno-7-204 href=#__codelineno-7-204></a>                <span class=n>input_fn</span><span class=o>=</span><span class=n>PrepareModuleInput</span><span class=p>(),</span>
</span><span id=__span-7-205><a id=__codelineno-7-205 name=__codelineno-7-205 href=#__codelineno-7-205></a>            <span class=p>)</span>
</span><span id=__span-7-206><a id=__codelineno-7-206 name=__codelineno-7-206 href=#__codelineno-7-206></a>
</span><span id=__span-7-207><a id=__codelineno-7-207 name=__codelineno-7-207 href=#__codelineno-7-207></a><span class=c1># Create configuration with advanced features</span>
</span><span id=__span-7-208><a id=__codelineno-7-208 name=__codelineno-7-208 href=#__codelineno-7-208></a><span class=n>config</span> <span class=o>=</span> <span class=n>LMConfig</span><span class=p>(</span>
</span><span id=__span-7-209><a id=__codelineno-7-209 name=__codelineno-7-209 href=#__codelineno-7-209></a>    <span class=c1># Distributed settings</span>
</span><span id=__span-7-210><a id=__codelineno-7-210 name=__codelineno-7-210 href=#__codelineno-7-210></a>    <span class=n>device_parameters</span><span class=o>=</span><span class=n>DeviceParameters</span><span class=p>(</span>
</span><span id=__span-7-211><a id=__codelineno-7-211 name=__codelineno-7-211 href=#__codelineno-7-211></a>        <span class=n>dp_shard</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>              <span class=c1># 4-way FSDP2</span>
</span><span id=__span-7-212><a id=__codelineno-7-212 name=__codelineno-7-212 href=#__codelineno-7-212></a>        <span class=n>tensor_parallel</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>       <span class=c1># 2-way tensor parallelism</span>
</span><span id=__span-7-213><a id=__codelineno-7-213 name=__codelineno-7-213 href=#__codelineno-7-213></a>        <span class=n>compile_model</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>      <span class=c1># torch.compile</span>
</span><span id=__span-7-214><a id=__codelineno-7-214 name=__codelineno-7-214 href=#__codelineno-7-214></a>        <span class=n>enable_compiled_autograd</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-7-215><a id=__codelineno-7-215 name=__codelineno-7-215 href=#__codelineno-7-215></a>        <span class=n>loss_parallel</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>      <span class=c1># Parallel loss computation</span>
</span><span id=__span-7-216><a id=__codelineno-7-216 name=__codelineno-7-216 href=#__codelineno-7-216></a>    <span class=p>),</span>
</span><span id=__span-7-217><a id=__codelineno-7-217 name=__codelineno-7-217 href=#__codelineno-7-217></a>
</span><span id=__span-7-218><a id=__codelineno-7-218 name=__codelineno-7-218 href=#__codelineno-7-218></a>    <span class=c1># Training settings</span>
</span><span id=__span-7-219><a id=__codelineno-7-219 name=__codelineno-7-219 href=#__codelineno-7-219></a>    <span class=n>training_parameters</span><span class=o>=</span><span class=n>TrainingParameters</span><span class=p>(</span>
</span><span id=__span-7-220><a id=__codelineno-7-220 name=__codelineno-7-220 href=#__codelineno-7-220></a>        <span class=n>n_epochs</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span><span id=__span-7-221><a id=__codelineno-7-221 name=__codelineno-7-221 href=#__codelineno-7-221></a>        <span class=n>train_batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-7-222><a id=__codelineno-7-222 name=__codelineno-7-222 href=#__codelineno-7-222></a>        <span class=n>gradient_accumulation_steps</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>  <span class=c1># Effective batch = 32</span>
</span><span id=__span-7-223><a id=__codelineno-7-223 name=__codelineno-7-223 href=#__codelineno-7-223></a>        <span class=n>gradient_clip_val</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
</span><span id=__span-7-224><a id=__codelineno-7-224 name=__codelineno-7-224 href=#__codelineno-7-224></a>        <span class=n>val_frequency</span><span class=o>=</span><span class=mf>0.25</span><span class=p>,</span>  <span class=c1># Validate 4x per epoch</span>
</span><span id=__span-7-225><a id=__codelineno-7-225 name=__codelineno-7-225 href=#__codelineno-7-225></a>    <span class=p>),</span>
</span><span id=__span-7-226><a id=__codelineno-7-226 name=__codelineno-7-226 href=#__codelineno-7-226></a>
</span><span id=__span-7-227><a id=__codelineno-7-227 name=__codelineno-7-227 href=#__codelineno-7-227></a>    <span class=c1># Callbacks for production features</span>
</span><span id=__span-7-228><a id=__codelineno-7-228 name=__codelineno-7-228 href=#__codelineno-7-228></a>    <span class=n>callbacks</span><span class=o>=</span><span class=n>CallbackCollection</span><span class=p>([</span>
</span><span id=__span-7-229><a id=__codelineno-7-229 name=__codelineno-7-229 href=#__codelineno-7-229></a>        <span class=n>LoggerCallback</span><span class=p>(</span><span class=n>log_every_n_train_batches</span><span class=o>=</span><span class=mi>10</span><span class=p>),</span>
</span><span id=__span-7-230><a id=__codelineno-7-230 name=__codelineno-7-230 href=#__codelineno-7-230></a>        <span class=n>CheckpointCallback</span><span class=p>(</span>
</span><span id=__span-7-231><a id=__codelineno-7-231 name=__codelineno-7-231 href=#__codelineno-7-231></a>            <span class=n>CheckpointParameters</span><span class=p>(</span>
</span><span id=__span-7-232><a id=__codelineno-7-232 name=__codelineno-7-232 href=#__codelineno-7-232></a>                <span class=n>checkpoint_every_n_epochs</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-7-233><a id=__codelineno-7-233 name=__codelineno-7-233 href=#__codelineno-7-233></a>                <span class=n>keep_top_k</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span><span id=__span-7-234><a id=__codelineno-7-234 name=__codelineno-7-234 href=#__codelineno-7-234></a>                <span class=n>monitor</span><span class=o>=</span><span class=s2>&quot;val_perplexity&quot;</span><span class=p>,</span>
</span><span id=__span-7-235><a id=__codelineno-7-235 name=__codelineno-7-235 href=#__codelineno-7-235></a>            <span class=p>)</span>
</span><span id=__span-7-236><a id=__codelineno-7-236 name=__codelineno-7-236 href=#__codelineno-7-236></a>        <span class=p>),</span>
</span><span id=__span-7-237><a id=__codelineno-7-237 name=__codelineno-7-237 href=#__codelineno-7-237></a>        <span class=n>OptimizeFSDP</span><span class=p>(</span><span class=n>prefetch</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>  <span class=c1># Intelligent FSDP prefetching</span>
</span><span id=__span-7-238><a id=__codelineno-7-238 name=__codelineno-7-238 href=#__codelineno-7-238></a>    <span class=p>])</span>
</span><span id=__span-7-239><a id=__codelineno-7-239 name=__codelineno-7-239 href=#__codelineno-7-239></a><span class=p>)</span>
</span><span id=__span-7-240><a id=__codelineno-7-240 name=__codelineno-7-240 href=#__codelineno-7-240></a>
</span><span id=__span-7-241><a id=__codelineno-7-241 name=__codelineno-7-241 href=#__codelineno-7-241></a><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
</span><span id=__span-7-242><a id=__codelineno-7-242 name=__codelineno-7-242 href=#__codelineno-7-242></a>    <span class=c1># Dream Trainer handles distributed launch automatically</span>
</span><span id=__span-7-243><a id=__codelineno-7-243 name=__codelineno-7-243 href=#__codelineno-7-243></a>    <span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>distributed_launch</span>
</span><span id=__span-7-244><a id=__codelineno-7-244 name=__codelineno-7-244 href=#__codelineno-7-244></a>
</span><span id=__span-7-245><a id=__codelineno-7-245 name=__codelineno-7-245 href=#__codelineno-7-245></a>    <span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-7-246><a id=__codelineno-7-246 name=__codelineno-7-246 href=#__codelineno-7-246></a>        <span class=n>trainer</span> <span class=o>=</span> <span class=n>LanguageModelTrainer</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span><span id=__span-7-247><a id=__codelineno-7-247 name=__codelineno-7-247 href=#__codelineno-7-247></a>        <span class=n>trainer</span><span class=o>.</span><span class=n>fit</span><span class=p>()</span>
</span><span id=__span-7-248><a id=__codelineno-7-248 name=__codelineno-7-248 href=#__codelineno-7-248></a>
</span><span id=__span-7-249><a id=__codelineno-7-249 name=__codelineno-7-249 href=#__codelineno-7-249></a>    <span class=n>distributed_launch</span><span class=p>(</span><span class=n>main</span><span class=p>)</span>
</span></code></pre></div> <h2 id=launch-training>Launch Training<a class=headerlink href=#launch-training title="Permanent link">&para;</a></h2> <h3 id=single-gpu>Single GPU<a class=headerlink href=#single-gpu title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a>python<span class=w> </span>train.py
</span></code></pre></div> <h3 id=multiple-gpus-single-node>Multiple GPUs (Single Node)<a class=headerlink href=#multiple-gpus-single-node title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># Dream Trainer auto-detects available GPUs</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>python<span class=w> </span>train.py
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=c1># Or explicitly with torchrun</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>torchrun<span class=w> </span>--nproc_per_node<span class=o>=</span><span class=m>8</span><span class=w> </span>train.py
</span></code></pre></div> <h3 id=multiple-nodes>Multiple Nodes<a class=headerlink href=#multiple-nodes title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Node 0</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>torchrun<span class=w> </span>--nproc_per_node<span class=o>=</span><span class=m>8</span><span class=w> </span>--nnodes<span class=o>=</span><span class=m>2</span><span class=w> </span>--node_rank<span class=o>=</span><span class=m>0</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=w>    </span>--master_addr<span class=o>=</span><span class=nv>$MASTER_ADDR</span><span class=w> </span>--master_port<span class=o>=</span><span class=m>29500</span><span class=w> </span>train.py
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=c1># Node 1  </span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>torchrun<span class=w> </span>--nproc_per_node<span class=o>=</span><span class=m>8</span><span class=w> </span>--nnodes<span class=o>=</span><span class=m>2</span><span class=w> </span>--node_rank<span class=o>=</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a><span class=w>    </span>--master_addr<span class=o>=</span><span class=nv>$MASTER_ADDR</span><span class=w> </span>--master_port<span class=o>=</span><span class=m>29500</span><span class=w> </span>train.py
</span></code></pre></div> <h2 id=understanding-dream-trainers-advantages>Understanding Dream Trainer's Advantages<a class=headerlink href=#understanding-dream-trainers-advantages title="Permanent link">&para;</a></h2> <h3 id=1-clean-parallelism-abstractions>1. <strong>Clean Parallelism Abstractions</strong><a class=headerlink href=#1-clean-parallelism-abstractions title="Permanent link">&para;</a></h3> <p>Dream Trainer makes complex parallelism approachable:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># Bad (Raw PyTorch)</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=k>if</span> <span class=n>rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>    <span class=c1># Complex manual sharding...</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=c1># Good (Dream Trainer)</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=k>def</span><span class=w> </span><span class=nf>apply_tensor_parallel</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tp_mesh</span><span class=p>):</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>    <span class=c1># Clean, reusable parallelism logic</span>
</span></code></pre></div> <h3 id=2-automatic-mixed-precision>2. <strong>Automatic Mixed Precision</strong><a class=headerlink href=#2-automatic-mixed-precision title="Permanent link">&para;</a></h3> <p>Dream Trainer wraps forward methods intelligently:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Automatic - Dream Trainer handles autocast placement</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=k>def</span><span class=w> </span><span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>  <span class=c1># Autocast applied automatically</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=c1># No need for manual autocast contexts!</span>
</span></code></pre></div> <h3 id=3-gradient-accumulation-that-just-works>3. <strong>Gradient Accumulation That Just Works</strong><a class=headerlink href=#3-gradient-accumulation-that-just-works title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># Dream Trainer handles the complexity</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=bp>self</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>  <span class=c1># Scales by accumulation steps</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>is_accumulating_gradients</span><span class=p>:</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>    <span class=c1># Only step when ready</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>    <span class=bp>self</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=p>)</span>
</span></code></pre></div> <h3 id=4-composable-features>4. <strong>Composable Features</strong><a class=headerlink href=#4-composable-features title="Permanent link">&para;</a></h3> <p>Add features without modifying your core trainer:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># Start simple</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=k>class</span><span class=w> </span><span class=nc>V1Trainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>):</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>    <span class=k>pass</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=c1># Add metrics later</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a><span class=k>class</span><span class=w> </span><span class=nc>V2Trainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>,</span> <span class=n>EvalMetricMixin</span><span class=p>):</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>configure_metrics</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>        <span class=bp>self</span><span class=o>.</span><span class=n>accuracy</span> <span class=o>=</span> <span class=n>Accuracy</span><span class=p>()</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a><span class=c1># Add logging even later</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a><span class=k>class</span><span class=w> </span><span class=nc>V3Trainer</span><span class=p>(</span><span class=n>BaseTrainer</span><span class=p>,</span> <span class=n>SetupMixin</span><span class=p>,</span> <span class=n>EvalMetricMixin</span><span class=p>,</span> <span class=n>WandBLoggerMixin</span><span class=p>):</span>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>    <span class=k>pass</span>  <span class=c1># No changes to existing code!</span>
</span></code></pre></div> <h2 id=common-patterns>Common Patterns<a class=headerlink href=#common-patterns title="Permanent link">&para;</a></h2> <h3 id=adding-custom-callbacks>Adding Custom Callbacks<a class=headerlink href=#adding-custom-callbacks title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.callbacks</span><span class=w> </span><span class=kn>import</span> <span class=n>Callback</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=k>class</span><span class=w> </span><span class=nc>LearningRateWarmup</span><span class=p>(</span><span class=n>Callback</span><span class=p>[</span><span class=n>SetupMixin</span><span class=p>]):</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>warmup_steps</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span> <span class=o>=</span> <span class=n>warmup_steps</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>post_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>result</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>global_step</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span><span class=p>:</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a>            <span class=c1># Linear warmup</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>            <span class=n>lr_scale</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>global_step</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_steps</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>            <span class=k>for</span> <span class=n>param_group</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>:</span>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a>                <span class=n>param_group</span><span class=p>[</span><span class=s1>&#39;lr&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>param_group</span><span class=p>[</span><span class=s1>&#39;initial_lr&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>lr_scale</span>
</span></code></pre></div> <h3 id=debugging-distributed-training>Debugging Distributed Training<a class=headerlink href=#debugging-distributed-training title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># Dream Trainer provides utilities for distributed debugging</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=kn>from</span><span class=w> </span><span class=nn>dream_trainer.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>rank_zero_print</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a><span class=k>class</span><span class=w> </span><span class=nc>MyTrainer</span><span class=p>(</span><span class=n>DreamTrainer</span><span class=p>):</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=k>def</span><span class=w> </span><span class=nf>training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>batch_idx</span><span class=p>):</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>        <span class=c1># Only prints from rank 0</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>        <span class=n>rank_zero_print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Batch shape: </span><span class=si>{</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>        <span class=c1># Check DTensor sharding</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>        <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=s1>&#39;placements&#39;</span><span class=p>):</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>            <span class=n>rank_zero_print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Weight sharding: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>placements</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=next-steps>Next Steps<a class=headerlink href=#next-steps title="Permanent link">&para;</a></h2> <p>Now that you understand Dream Trainer's core concepts:</p> <ol> <li><strong>Explore Mixins</strong>: Check out the <a href=../trainer-guide/ >Trainer Guide</a> to see all available mixins</li> <li><strong>Master Parallelism</strong>: Read the <a href=../parallelism/ >Parallelism Guide</a> for advanced distributed training</li> <li><strong>Extend with Callbacks</strong>: Learn to create custom callbacks in the <a href=../callbacks/ >Callbacks Guide</a></li> <li><strong>Optimize Performance</strong>: See <a href=best-practices.md>Best Practices</a> for performance tips</li> </ol> <h2 id=troubleshooting>Troubleshooting<a class=headerlink href=#troubleshooting title="Permanent link">&para;</a></h2> <h3 id=installation-issues>Installation Issues<a class=headerlink href=#installation-issues title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=c1># Check CUDA compatibility</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>python<span class=w> </span>-c<span class=w> </span><span class=s2>&quot;import torch; print(torch.cuda.is_available())&quot;</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=c1># Verify Dream Trainer features</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>python<span class=w> </span>-c<span class=w> </span><span class=s2>&quot;from dream_trainer.utils import check_features; check_features()&quot;</span>
</span></code></pre></div> <h3 id=common-issues>Common Issues<a class=headerlink href=#common-issues title="Permanent link">&para;</a></h3> <ol> <li><strong>OOM with Large Models</strong>: Enable CPU offloading or use gradient checkpointing</li> <li><strong>Slow Data Loading</strong>: Increase <code>num_workers</code> and use <code>pin_memory=True</code></li> <li><strong>Debugging Distributed</strong>: Set <code>TORCH_CPP_LOG_LEVEL=INFO</code> for detailed logs</li> </ol> <h2 id=getting-help>Getting Help<a class=headerlink href=#getting-help title="Permanent link">&para;</a></h2> <ul> <li>📚 <a href=../ >Full Documentation</a></li> <li>💬 <a href=https://github.com/dream-trainer/dream-trainer/discussions>GitHub Discussions</a></li> <li>🐛 <a href=https://github.com/dream-trainer/dream-trainer/issues>Issue Tracker</a></li> <li>💡 <a href=https://github.com/dream-trainer/dream-trainer/tree/main/examples>Examples Repository</a></li> </ul> <hr> <p><strong>Ready to train with Dream Trainer?</strong> You now understand what makes it unique. Happy training! 🚀</p> <p>*[API]: Application Programming Interface *[CPU]: Central Processing Unit *[GPU]: Graphics Processing Unit *[TPU]: Tensor Processing Unit *[CUDA]: Compute Unified Device Architecture *[PyTorch]: Python-based open source machine learning framework *[DTensor]: Distributed Tensor *[FSDP]: Fully Sharded Data Parallel *[FSDP2]: Fully Sharded Data Parallel version 2 *[DDP]: Distributed Data Parallel *[HSDP]: Hybrid Sharded Data Parallel *[TP]: Tensor Parallel *[PP]: Pipeline Parallel *[NCCL]: NVIDIA Collective Communication Library *[MPI]: Message Passing Interface *[ML]: Machine Learning *[AI]: Artificial Intelligence *[OOM]: Out of Memory *[RDMA]: Remote Direct Memory Access *[JIT]: Just-In-Time compilation *[QoS]: Quality of Service *[NVMe]: Non-Volatile Memory Express *[JSON]: JavaScript Object Notation *[YAML]: YAML Ain't Markup Language *[CSV]: Comma-Separated Values *[SDK]: Software Development Kit *[CLI]: Command Line Interface *[GUI]: Graphical User Interface *[SSH]: Secure Shell *[URL]: Uniform Resource Locator *[RAM]: Random Access Memory *[VRAM]: Video Random Access Memory *[FP8]: 8-bit Floating Point *[FP16]: 16-bit Floating Point (Half Precision) *[FP32]: 32-bit Floating Point (Single Precision) *[BF16]: Brain Floating Point 16 *[AMP]: Automatic Mixed Precision *[TF]: TensorFlow *[HF]: HuggingFace *[LLM]: Large Language Model *[NLP]: Natural Language Processing *[CV]: Computer Vision *[RL]: Reinforcement Learning *[GAN]: Generative Adversarial Network *[CNN]: Convolutional Neural Network *[RNN]: Recurrent Neural Network *[LSTM]: Long Short-Term Memory *[GRU]: Gated Recurrent Unit *[SGD]: Stochastic Gradient Descent *[Adam]: Adaptive Moment Estimation optimizer *[AdamW]: Adam with decoupled Weight decay *[LR]: Learning Rate *[BS]: Batch Size *[WD]: Weight Decay *[KV]: Key-Value *[MHA]: Multi-Head Attention *[FFN]: Feed-Forward Network *[MSE]: Mean Squared Error *[MAE]: Mean Absolute Error *[BCE]: Binary Cross-Entropy *[CE]: Cross-Entropy *[BERT]: Bidirectional Encoder Representations from Transformers *[GPT]: Generative Pre-trained Transformer *[CLIP]: Contrastive Language-Image Pre-training *[ONNX]: Open Neural Network Exchange *[TorchScript]: PyTorch's graph representation format *[W&amp;B]: Weights &amp; Biases *[TB]: TensorBoard *[MLOps]: Machine Learning Operations *[CI/CD]: Continuous Integration/Continuous Deployment *[REST]: Representational State Transfer *[gRPC]: Google Remote Procedure Call *[IPC]: Inter-Process Communication *[P2P]: Peer-to-Peer *[AllReduce]: Collective communication operation that combines values from all processes *[AllGather]: Collective communication operation that g </p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="July 16, 2025 02:20:00 UTC"><span class=timeago datetime=2025-07-16T02:20:00+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="July 16, 2025 02:20:00 UTC">2025-07-16</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../installation/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Installation"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Installation </div> </div> </a> <a href=../core-concepts/ class="md-footer__link md-footer__link--next" aria-label="Next: Core Concepts"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Core Concepts </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dream3d/dream-trainer target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://discord.gg/dream-trainer target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> <a href=https://twitter.com/dream3d_ai target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.prune", "navigation.indexes", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.action.edit", "content.action.view", "content.tooltips", "toc.follow", "toc.integrate"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "stable", "provider": "mike"}}</script> <script src=../assets/javascripts/bundle.56ea9cef.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> <script src=../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>